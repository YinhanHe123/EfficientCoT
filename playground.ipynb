{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the dataset which chatgpt 4o mini selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 gap: 36908.96875\n",
      "epoch 1 gap: 29977.525390625\n",
      "epoch 2 gap: 25434.9296875\n",
      "epoch 3 gap: 21600.6796875\n",
      "epoch 4 gap: 18427.546875\n",
      "epoch 5 gap: 15698.2431640625\n",
      "epoch 6 gap: 13269.2626953125\n",
      "epoch 7 gap: 11078.9365234375\n",
      "epoch 8 gap: 9217.1162109375\n",
      "epoch 9 gap: 7469.4755859375\n",
      "epoch 10 gap: 5863.73291015625\n",
      "epoch 11 gap: 4344.67333984375\n",
      "epoch 12 gap: 2882.39306640625\n",
      "epoch 13 gap: 1436.8564453125\n",
      "epoch 14 gap: 0.6747385859489441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pdb\n",
    "model_a = '/data/nee7ne/effi_cot/saved_models/effi_cot/old_vanilla/sentence_transformer/model.pt'\n",
    "model_b_dir = '/data/nee7ne/effi_cot/saved_models/effi_cot/vanilla/gsm8k/sentence_transformer_ckpts/'\n",
    "def compare_model_parameters(model_a, model_b_dir):\n",
    "    \"\"\"Compares the parameters of two PyTorch models.\"\"\"\n",
    "    # Check if the models have the same parameters\n",
    "    # Load the models\n",
    "    model_a = torch.load(model_a)\n",
    "    for epoch in range(15):\n",
    "        model_b = model_b_dir + f\"model_epoch_{epoch}.pt\"\n",
    "        model_b = torch.load(model_b)\n",
    "\n",
    "        if set(model_a.keys()) != set(model_b.keys()):\n",
    "            return False\n",
    "\n",
    "        # Iterate through the parameters and compare them\n",
    "        gap = 0\n",
    "        for param_name in model_a.keys():\n",
    "            param_a = model_a[param_name]\n",
    "            param_b = model_b[param_name]\n",
    "\n",
    "            # Check if the parameters are equal\n",
    "            # print(\"model_a device\", param_a.device)\n",
    "            # print(\"model_b device\", param_b.device)\n",
    "            param_a = param_a.cpu()\n",
    "            param_b = param_b.cpu()\n",
    "            gap += torch.abs(param_a - param_b).sum()\n",
    "        print(f\"epoch {epoch} gap: {gap}\")\n",
    "            # if not torch.equal(param_a, param_b):\n",
    "            #     # print where the parameters are not equal\n",
    "            #     print(f\"Parameters are not equal at {param_name}\")\n",
    "            #     print(f\"Difference: {torch.abs(param_a - param_b).sum()}\")\n",
    "                # return False\n",
    "    return True\n",
    "\n",
    "compare_model_parameters(model_a, model_b_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_reasoning(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate detailed reasoning for a given query.\n",
    "\n",
    "        Args:\n",
    "            query: The mathematical problem to solve\n",
    "\n",
    "        Returns:\n",
    "            Detailed step-by-step reasoning\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a math tutor who provides detailed step-by-step solutions to math problems.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Problem: {query}\\n\\nPlease solve this step-by-step, showing all your work.\"}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.api_url,\n",
    "                headers=self.headers,\n",
    "                json={\n",
    "                    \"model\": self.model,\n",
    "                    \"messages\": messages,\n",
    "                    \"temperature\": 0.2,\n",
    "                }\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            reasoning = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return reasoning\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating detailed reasoning: {e}\")\n",
    "            if 'response' in locals() and hasattr(response, 'text'):\n",
    "                print(f\"API response: {response.text}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nee7ne/EfficientCoT/results/codi/mistral/gsm8k\n",
      "/home/nee7ne/EfficientCoT/results/pause/mistral/gsm8k\n",
      "/home/nee7ne/EfficientCoT/results/ccot/mistral/gsm8k\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "time_name_map = {\"ccot\": \"generation_time\", \"softcot\": \"total_time\", \"pause\": \"generation_time\", \"icot_si\": \"generation_time\", \"codi\": \"generation_time\"}\n",
    "\n",
    "res_folder = \"/home/nee7ne/EfficientCoT/results\"\n",
    "models = ['mistral', 'small']\n",
    "datasets = ['gsm8k', 'multiarith', 'svamp']\n",
    "res = {}\n",
    "for method in os.listdir(res_folder):\n",
    "    if method == \"effi_cot\":\n",
    "        method = \"effi_cot/vanilla\"\n",
    "    if not os.path.exists(f\"{res_folder}/{method}/{models[0]}/{datasets[0]}\") or len(os.listdir(f\"{res_folder}/{method}/{models[0]}/{datasets[0]}\")) == 0:\n",
    "        print(f\"{res_folder}/{method}/{models[0]}/{datasets[0]}\")\n",
    "        continue\n",
    "    res[method] = {}\n",
    "    for m in models:\n",
    "        res[method][m] = {}\n",
    "        for d in datasets:\n",
    "            res[method][m][d] = {}\n",
    "            if not os.path.exists(f\"{res_folder}/{method}/{m}/{d}\"):\n",
    "                print(\"2\")\n",
    "                continue\n",
    "            folder_name = [path for path in os.listdir(f\"{res_folder}/{method}/{m}/{d}\") if os.path.isdir(f\"{res_folder}/{method}/{m}/{d}/{path}\")]\n",
    "            if len(folder_name) == 0 or not os.path.exists(f\"{res_folder}/{method}/{m}/{d}/{folder_name[0]}/inference_results.json\"):\n",
    "                print(\"3\")\n",
    "                continue\n",
    "            with open(f\"{res_folder}/{method}/{m}/{d}/{folder_name[0]}/inference_results.json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                if len(data) < 10:\n",
    "                    data = data['results']\n",
    "            if \"sample_time\" not in data[0]:\n",
    "                continue\n",
    "            res[method][m][d]['time'] = [sample[\"sample_time\"] for sample in data]\n",
    "            with open(f\"{res_folder}/{method}/{m}/{d}/evaluation_results.jsonl\", \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                data = json.loads(lines[-1])\n",
    "                res[method][m][d]['acc'] = data['summary_acc'] if \"summary_acc\" in data else data['numerical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\t15.0\t\n",
      "1.70 ± 0.23\t2.30 ± 0.20\t\n",
      "16.0\t3.0\t\n",
      "1.42 ± 0.20\t2.41 ± 0.04\t\n",
      "42.0\t61.0\t\n",
      "1.71 ± 0.27\t2.11 ± 0.24\t\n",
      "6.0\t8.0\t\n",
      "1.37 ± 0.15\t2.24 ± 0.13\t\n",
      "28.000000000000004\t3.0\t\n",
      "1.28 ± 0.17\t2.49 ± 0.14\t\n",
      "28.999999999999996\t51.0\t\n",
      "1.22 ± 0.33\t2.00 ± 0.19\t\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(models):\n",
    "    for d in sorted(datasets):\n",
    "        acc_line = \"\"\n",
    "        time_line = \"\"\n",
    "        for method in sorted(res):\n",
    "\n",
    "            if len(res[method][m][d]) == 0:\n",
    "                continue\n",
    "            if isinstance(res[method][m][d]['acc'], str):\n",
    "                acc_line += f\"{float(res[method][m][d]['acc'].split('±')[0]) * 100}\\t\"\n",
    "            else:\n",
    "                acc_line += f\"{float(res[method][m][d]['acc']) * 100}\\t\"\n",
    "            time_line += f\"{np.mean(res[method][m][d]['time']):.2f} ± {np.std(res[method][m][d]['time']):.2f}\\t\"\n",
    "        print(acc_line)\n",
    "        print(time_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\t15.0\t\n",
      "1.70 ± 0.23\t2.30 ± 0.20\t\n",
      "3.0\t\n",
      "2.41 ± 0.04\t\n",
      "42.0\t61.0\t\n",
      "1.71 ± 0.27\t2.11 ± 0.24\t\n",
      "6.0\t8.0\t\n",
      "1.37 ± 0.15\t2.24 ± 0.13\t\n",
      "28.000000000000004\t3.0\t\n",
      "1.28 ± 0.17\t2.49 ± 0.14\t\n",
      "28.999999999999996\t51.0\t\n",
      "1.22 ± 0.33\t2.00 ± 0.19\t\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(models):\n",
    "    for d in sorted(datasets):\n",
    "        acc_line = \"\"\n",
    "        time_line = \"\"\n",
    "        for method in sorted(res):\n",
    "\n",
    "            if len(res[method][m][d]) == 0:\n",
    "                continue\n",
    "            if isinstance(res[method][m][d]['acc'], str):\n",
    "                acc_line += f\"{float(res[method][m][d]['acc'].split('±')[0]) * 100}\\t\"\n",
    "            else:\n",
    "                acc_line += f\"{float(res[method][m][d]['acc']) * 100}\\t\"\n",
    "            time_line += f\"{np.mean(res[method][m][d]['time']):.2f} ± {np.std(res[method][m][d]['time']):.2f}\\t\"\n",
    "        print(acc_line)\n",
    "        print(time_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effi_cot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
