{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the dataset which chatgpt 4o mini selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 gap: 36908.96875\n",
      "epoch 1 gap: 29977.525390625\n",
      "epoch 2 gap: 25434.9296875\n",
      "epoch 3 gap: 21600.6796875\n",
      "epoch 4 gap: 18427.546875\n",
      "epoch 5 gap: 15698.2431640625\n",
      "epoch 6 gap: 13269.2626953125\n",
      "epoch 7 gap: 11078.9365234375\n",
      "epoch 8 gap: 9217.1162109375\n",
      "epoch 9 gap: 7469.4755859375\n",
      "epoch 10 gap: 5863.73291015625\n",
      "epoch 11 gap: 4344.67333984375\n",
      "epoch 12 gap: 2882.39306640625\n",
      "epoch 13 gap: 1436.8564453125\n",
      "epoch 14 gap: 0.6747385859489441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pdb\n",
    "model_a = '/data/nee7ne/effi_cot/saved_models/effi_cot/old_vanilla/sentence_transformer/model.pt'\n",
    "model_b_dir = '/data/nee7ne/effi_cot/saved_models/effi_cot/vanilla/gsm8k/sentence_transformer_ckpts/'\n",
    "def compare_model_parameters(model_a, model_b_dir):\n",
    "    \"\"\"Compares the parameters of two PyTorch models.\"\"\"\n",
    "    # Check if the models have the same parameters\n",
    "    # Load the models\n",
    "    model_a = torch.load(model_a)\n",
    "    for epoch in range(15):\n",
    "        model_b = model_b_dir + f\"model_epoch_{epoch}.pt\"\n",
    "        model_b = torch.load(model_b)\n",
    "\n",
    "        if set(model_a.keys()) != set(model_b.keys()):\n",
    "            return False\n",
    "\n",
    "        # Iterate through the parameters and compare them\n",
    "        gap = 0\n",
    "        for param_name in model_a.keys():\n",
    "            param_a = model_a[param_name]\n",
    "            param_b = model_b[param_name]\n",
    "\n",
    "            # Check if the parameters are equal\n",
    "            # print(\"model_a device\", param_a.device)\n",
    "            # print(\"model_b device\", param_b.device)\n",
    "            param_a = param_a.cpu()\n",
    "            param_b = param_b.cpu()\n",
    "            gap += torch.abs(param_a - param_b).sum()\n",
    "        print(f\"epoch {epoch} gap: {gap}\")\n",
    "            # if not torch.equal(param_a, param_b):\n",
    "            #     # print where the parameters are not equal\n",
    "            #     print(f\"Parameters are not equal at {param_name}\")\n",
    "            #     print(f\"Difference: {torch.abs(param_a - param_b).sum()}\")\n",
    "                # return False\n",
    "    return True\n",
    "\n",
    "compare_model_parameters(model_a, model_b_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
