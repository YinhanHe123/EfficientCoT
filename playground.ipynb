{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the dataset which chatgpt 4o mini selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nee7ne/.conda/envs/effi_cot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices extraction on GSM8K dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 316830.42 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 385955.56 examples/s]\n",
      "Testing GPT-4o mini indices:   5%|▌         | 1/20 [00:01<00:35,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  10%|█         | 2/20 [00:03<00:36,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  15%|█▌        | 3/20 [00:04<00:24,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  20%|██        | 4/20 [00:05<00:19,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  25%|██▌       | 5/20 [00:06<00:16,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  30%|███       | 6/20 [00:07<00:15,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  35%|███▌      | 7/20 [00:08<00:14,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  40%|████      | 8/20 [00:09<00:12,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  45%|████▌     | 9/20 [00:10<00:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  50%|█████     | 10/20 [00:11<00:09,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  55%|█████▌    | 11/20 [00:12<00:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 11/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  60%|██████    | 12/20 [00:12<00:06,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 12/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  65%|██████▌   | 13/20 [00:13<00:05,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 13/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  70%|███████   | 14/20 [00:16<00:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 14/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  75%|███████▌  | 15/20 [00:16<00:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 15/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  80%|████████  | 16/20 [00:17<00:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 16/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  85%|████████▌ | 17/20 [00:19<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 17/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  90%|█████████ | 18/20 [00:19<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 18/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices:  95%|█████████▌| 19/20 [00:20<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 19/20: ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing GPT-4o mini indices: 100%|██████████| 20/20 [00:21<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 20/20: ✓\n",
      "\n",
      "==== GPT-4o Mini Indices Test Results ====\n",
      "Success Rate: 100.00%\n",
      "Total Samples: 20\n",
      "Successful Samples: 20\n",
      "Failed Samples: 0\n",
      "\n",
      "Sample Successful Output:\n",
      "Raw output: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
      "Extracted indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n",
      "Selected words: ['Janet', 'sells', '16', '-', '3', '-', '4', '=', '<<16-3-4=9>>9', 'duck']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def test_gpt4o_mini_indices(num_samples=10, compression_ratio=0.1, max_length=120):\n",
    "    \"\"\"\n",
    "    Test GPT-4o mini's ability to output indices correctly using raw data\n",
    "\n",
    "    Args:\n",
    "        num_samples: Number of examples to test\n",
    "        compression_ratio: Ratio of tokens to select\n",
    "        max_length: Maximum context length\n",
    "\n",
    "    Returns:\n",
    "        success_rate: Percentage of successful index extractions\n",
    "        all_results: Detailed results for each test case\n",
    "    \"\"\"\n",
    "    # Load raw dataset\n",
    "    raw = load_dataset(\"raw\", \"main\", split=\"test\")\n",
    "\n",
    "    # Select a subset of samples for testing\n",
    "    samples = raw.select(range(min(num_samples, len(raw))))\n",
    "\n",
    "    # Set up OpenAI API key - using environment variable for security\n",
    "    openai.api_key = \"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\"\n",
    "    if not openai.api_key:\n",
    "        raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "    all_results = []\n",
    "    success_count = 0\n",
    "\n",
    "    for i, sample in enumerate(tqdm(samples, desc=\"Testing GPT-4o mini indices\")):\n",
    "        query = sample[\"question\"]\n",
    "        reasoning = sample[\"answer\"]\n",
    "\n",
    "        # Calculate expected number of tokens\n",
    "        num_of_compressed_tokens = int(max_length * compression_ratio)\n",
    "\n",
    "        # Test GPT-4o mini index generation\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\",\n",
    "                     \"content\": f\"You should select {num_of_compressed_tokens} important words from the following text. \"\n",
    "                                f\"I need you to only output the words' indices increasingly, DO NOT OUTPUT ANYTHING ELSE. \"\n",
    "                                f\"For example, for text 'Where is my pencil?', the important words are 'Where' and 'pencil' \"\n",
    "                                f\"at position 0 and 4, so the output is '0, 4'. Now, do it for the following text: {reasoning}\"}\n",
    "                ],\n",
    "                temperature=0.0,  # Use deterministic output for testing\n",
    "                max_tokens=200\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "            # Extract and validate indices\n",
    "            try:\n",
    "                # Clean the output - extract only numbers and commas\n",
    "                cleaned_output = re.sub(r'[^0-9,\\s]', '', output)\n",
    "                indices = [int(idx.strip()) for idx in cleaned_output.split(',') if idx.strip()]\n",
    "\n",
    "                # Validate the indices\n",
    "                indices = sorted(indices)  # Ensure indices are sorted\n",
    "                indices = [idx for idx in indices if idx < len(reasoning.split())]  # Remove out-of-bounds indices\n",
    "                indices = indices[:num_of_compressed_tokens]  # Limit to expected count\n",
    "\n",
    "                # Check if we have enough valid indices\n",
    "                if len(indices) >= num_of_compressed_tokens * 0.8:  # Allow 80% success threshold\n",
    "                    success = True\n",
    "                    success_count += 1\n",
    "                else:\n",
    "                    success = False\n",
    "\n",
    "                # Show selected words for manual verification\n",
    "                words = reasoning.split()\n",
    "                selected_words = [words[idx] if idx < len(words) else f\"[OUT_OF_RANGE_{idx}]\" for idx in indices]\n",
    "\n",
    "            except Exception as e:\n",
    "                indices = []\n",
    "                selected_words = []\n",
    "                success = False\n",
    "                error_msg = str(e)\n",
    "\n",
    "        except Exception as e:\n",
    "            indices = []\n",
    "            selected_words = []\n",
    "            success = False\n",
    "            error_msg = str(e)\n",
    "\n",
    "        # Record results\n",
    "        result = {\n",
    "            \"sample_id\": i,\n",
    "            \"query\": query,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"expected_token_count\": num_of_compressed_tokens,\n",
    "            \"raw_model_output\": output,\n",
    "            \"extracted_indices\": indices,\n",
    "            \"selected_words\": selected_words,\n",
    "            \"success\": success\n",
    "        }\n",
    "\n",
    "        if not success and 'error_msg' in locals():\n",
    "            result[\"error\"] = error_msg\n",
    "\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Sample {i+1}/{num_samples}: {'✓' if success else '✗'}\")\n",
    "        if not success:\n",
    "            print(f\"  Raw output: {output}\")\n",
    "            if indices:\n",
    "                print(f\"  Extracted {len(indices)} indices, expected {num_of_compressed_tokens}\")\n",
    "\n",
    "    # Calculate success rate\n",
    "    success_rate = (success_count / len(samples)) * 100\n",
    "\n",
    "    # Save detailed results to file\n",
    "    with open(\"gpt4o_mini_indices_test_results.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "\n",
    "    return success_rate, all_results\n",
    "\n",
    "def analyze_results(success_rate, all_results):\n",
    "    \"\"\"Analyze the test results and print summary statistics\"\"\"\n",
    "    print(\"\\n==== GPT-4o Mini Indices Test Results ====\")\n",
    "    print(f\"Success Rate: {success_rate:.2f}%\")\n",
    "\n",
    "    # Calculate statistics\n",
    "    total_samples = len(all_results)\n",
    "    successful_samples = sum(1 for r in all_results if r[\"success\"])\n",
    "    failed_samples = total_samples - successful_samples\n",
    "\n",
    "    print(f\"Total Samples: {total_samples}\")\n",
    "    print(f\"Successful Samples: {successful_samples}\")\n",
    "    print(f\"Failed Samples: {failed_samples}\")\n",
    "\n",
    "    # Common failure patterns\n",
    "    if failed_samples > 0:\n",
    "        print(\"\\nCommon Failure Patterns:\")\n",
    "\n",
    "        # Check for non-numeric outputs\n",
    "        non_numeric = sum(1 for r in all_results if not r[\"success\"] and not r[\"extracted_indices\"])\n",
    "        if non_numeric > 0:\n",
    "            print(f\"- Non-numeric outputs: {non_numeric} samples\")\n",
    "\n",
    "        # Check for insufficient indices\n",
    "        insufficient = sum(1 for r in all_results if not r[\"success\"] and r[\"extracted_indices\"] and\n",
    "                         len(r[\"extracted_indices\"]) < r[\"expected_token_count\"] * 0.8)\n",
    "        if insufficient > 0:\n",
    "            print(f\"- Insufficient indices count: {insufficient} samples\")\n",
    "\n",
    "        # Check for out-of-range indices\n",
    "        original_outputs = [r for r in all_results if not r[\"success\"] and \"raw_model_output\" in r]\n",
    "        out_of_range = sum(1 for r in original_outputs if any(\n",
    "            idx >= len(r[\"reasoning\"].split()) for idx in r.get(\"extracted_indices\", []) if idx\n",
    "        ))\n",
    "        if out_of_range > 0:\n",
    "            print(f\"- Out-of-range indices: {out_of_range} samples\")\n",
    "\n",
    "    # Sample successful and failed outputs\n",
    "    if successful_samples > 0:\n",
    "        print(\"\\nSample Successful Output:\")\n",
    "        successful = next((r for r in all_results if r[\"success\"]), None)\n",
    "        if successful:\n",
    "            print(f\"Raw output: {successful['raw_model_output']}\")\n",
    "            print(f\"Extracted indices: {successful['extracted_indices'][:10]}...\")\n",
    "            print(f\"Selected words: {successful['selected_words'][:10]}...\")\n",
    "\n",
    "    if failed_samples > 0:\n",
    "        print(\"\\nSample Failed Output:\")\n",
    "        failed = next((r for r in all_results if not r[\"success\"]), None)\n",
    "        if failed:\n",
    "            print(f\"Raw output: {failed['raw_model_output']}\")\n",
    "            print(f\"Reasoning: {failed['reasoning'][:100]}...\")\n",
    "            if failed.get(\"extracted_indices\"):\n",
    "                print(f\"Extracted indices: {failed['extracted_indices']}\")\n",
    "            if \"error\" in failed:\n",
    "                print(f\"Error: {failed['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the test\n",
    "    print(\"Testing GPT-4o mini indices extraction on raw dataset...\")\n",
    "    success_rate, all_results = test_gpt4o_mini_indices(num_samples=20)\n",
    "\n",
    "    # Analyze the results\n",
    "    analyze_results(success_rate, all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
