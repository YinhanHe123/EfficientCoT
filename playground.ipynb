{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the dataset which chatgpt 4o mini selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at norm.weight\n",
      "Difference: 1.5616649761795998e-05\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.self_attn.q_proj.weight\n",
      "Difference: 0.011075451038777828\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.self_attn.k_proj.weight\n",
      "Difference: 0.011102092452347279\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.self_attn.v_proj.weight\n",
      "Difference: 0.008046792820096016\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.self_attn.o_proj.weight\n",
      "Difference: 0.007584538776427507\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.mlp.gate_proj.weight\n",
      "Difference: 0.026672109961509705\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.mlp.up_proj.weight\n",
      "Difference: 0.02593364380300045\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.mlp.down_proj.weight\n",
      "Difference: 0.026021044701337814\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.input_layernorm.weight\n",
      "Difference: 4.202127456665039e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.0.post_attention_layernorm.weight\n",
      "Difference: 3.814697265625e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.self_attn.q_proj.weight\n",
      "Difference: 0.012416820973157883\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.self_attn.k_proj.weight\n",
      "Difference: 0.012583304196596146\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.self_attn.v_proj.weight\n",
      "Difference: 0.010032536461949348\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.self_attn.o_proj.weight\n",
      "Difference: 0.009953047148883343\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.mlp.gate_proj.weight\n",
      "Difference: 0.026389114558696747\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.mlp.up_proj.weight\n",
      "Difference: 0.027999933809041977\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.mlp.down_proj.weight\n",
      "Difference: 0.028269488364458084\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.input_layernorm.weight\n",
      "Difference: 4.210858605802059e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.1.post_attention_layernorm.weight\n",
      "Difference: 4.43682074546814e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.self_attn.q_proj.weight\n",
      "Difference: 0.013006306253373623\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.self_attn.k_proj.weight\n",
      "Difference: 0.013329408131539822\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.self_attn.v_proj.weight\n",
      "Difference: 0.01225681509822607\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.self_attn.o_proj.weight\n",
      "Difference: 0.0123673090711236\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.mlp.gate_proj.weight\n",
      "Difference: 0.02501579374074936\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.mlp.up_proj.weight\n",
      "Difference: 0.02850203588604927\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.mlp.down_proj.weight\n",
      "Difference: 0.028367215767502785\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.input_layernorm.weight\n",
      "Difference: 6.2587205320596695e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n",
      "Parameters are not equal at layers.2.post_attention_layernorm.weight\n",
      "Difference: 5.885958671569824e-06\n",
      "model_a device cuda:0\n",
      "model_b device cuda:2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;66;03m# return False\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mcompare_model_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mcompare_model_parameters\u001b[0;34m(model_a, model_b)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_a device\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_a\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_b device\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_b\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 24\u001b[0m param_a \u001b[38;5;241m=\u001b[39m \u001b[43mparam_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m param_b \u001b[38;5;241m=\u001b[39m param_b\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(param_a, param_b):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print where the parameters are not equal\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pdb\n",
    "model_a = '/data/nee7ne/effi_cot/saved_models/effi_cot/old_vanilla/sentence_transformer/model.pt'\n",
    "model_b = '/data/nee7ne/effi_cot/saved_models/effi_cot/vanilla/gsm8k/sentence_transformer/model.pt'\n",
    "def compare_model_parameters(model_a, model_b):\n",
    "    \"\"\"Compares the parameters of two PyTorch models.\"\"\"\n",
    "\n",
    "    # Check if the models have the same parameters\n",
    "    # Load the models\n",
    "    model_a = torch.load(model_a)\n",
    "    model_b = torch.load(model_b)\n",
    "\n",
    "    if set(model_a.keys()) != set(model_b.keys()):\n",
    "        return False\n",
    "\n",
    "    # Iterate through the parameters and compare them\n",
    "    for param_name in model_a.keys():\n",
    "        param_a = model_a[param_name]\n",
    "        param_b = model_b[param_name]\n",
    "\n",
    "        # Check if the parameters are equal\n",
    "        print(\"model_a device\", param_a.device)\n",
    "        print(\"model_b device\", param_b.device)\n",
    "        param_a = param_a.cpu()\n",
    "        param_b = param_b.cpu()\n",
    "        if not torch.equal(param_a, param_b):\n",
    "            # print where the parameters are not equal\n",
    "            print(f\"Parameters are not equal at {param_name}\")\n",
    "            print(f\"Difference: {torch.abs(param_a - param_b).sum()}\")\n",
    "            # return False\n",
    "\n",
    "    return True\n",
    "\n",
    "compare_model_parameters(model_a, model_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
