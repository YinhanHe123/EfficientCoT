Training Implicit CoT model...
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.53s/it]
Epoch 1/10 - Removing 0 tokens
Training (remove=0):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=0):   0%|          | 1/700 [00:00<06:46,  1.72it/s]Training (remove=0):   0%|          | 2/700 [00:00<04:57,  2.35it/s]Training (remove=0):   0%|          | 3/700 [00:01<04:19,  2.69it/s]Training (remove=0):   1%|          | 4/700 [00:01<04:02,  2.87it/s]Training (remove=0):   1%|          | 5/700 [00:01<03:52,  2.99it/s]Training (remove=0):   1%|          | 6/700 [00:02<03:46,  3.06it/s]Training (remove=0):   1%|          | 7/700 [00:02<03:42,  3.11it/s]Training (remove=0):   1%|          | 8/700 [00:02<03:39,  3.15it/s]Training (remove=0):   1%|▏         | 9/700 [00:03<03:37,  3.17it/s]Training (remove=0):   1%|▏         | 10/700 [00:03<03:36,  3.19it/s]Training (remove=0):   2%|▏         | 11/700 [00:03<03:35,  3.20it/s]Training (remove=0):   2%|▏         | 12/700 [00:03<03:34,  3.21it/s]Training (remove=0):   2%|▏         | 13/700 [00:04<03:33,  3.22it/s]Training (remove=0):   2%|▏         | 14/700 [00:04<03:32,  3.22it/s]Training (remove=0):   2%|▏         | 15/700 [00:04<03:32,  3.22it/s]Training (remove=0):   2%|▏         | 16/700 [00:05<03:32,  3.22it/s]Training (remove=0):   2%|▏         | 17/700 [00:05<03:31,  3.22it/s]Training (remove=0):   3%|▎         | 18/700 [00:05<03:31,  3.22it/s]Training (remove=0):   3%|▎         | 19/700 [00:06<03:31,  3.22it/s]Training (remove=0):   3%|▎         | 20/700 [00:06<03:30,  3.22it/s]Training (remove=0):   3%|▎         | 21/700 [00:06<03:30,  3.23it/s]Training (remove=0):   3%|▎         | 22/700 [00:07<03:29,  3.23it/s]Training (remove=0):   3%|▎         | 23/700 [00:07<03:29,  3.22it/s]Training (remove=0):   3%|▎         | 24/700 [00:07<03:29,  3.23it/s]Training (remove=0):   4%|▎         | 25/700 [00:08<03:31,  3.20it/s]Training (remove=0):   4%|▎         | 26/700 [00:08<03:30,  3.21it/s]Training (remove=0):   4%|▍         | 27/700 [00:08<03:29,  3.22it/s]Training (remove=0):   4%|▍         | 28/700 [00:08<03:28,  3.22it/s]Training (remove=0):   4%|▍         | 29/700 [00:09<03:28,  3.22it/s]Training (remove=0):   4%|▍         | 30/700 [00:09<03:28,  3.22it/s]Training (remove=0):   4%|▍         | 31/700 [00:09<03:27,  3.22it/s]Training (remove=0):   5%|▍         | 32/700 [00:10<03:27,  3.22it/s]Training (remove=0):   5%|▍         | 33/700 [00:10<03:26,  3.23it/s]Training (remove=0):   5%|▍         | 34/700 [00:10<03:26,  3.22it/s]Training (remove=0):   5%|▌         | 35/700 [00:11<03:26,  3.23it/s]Training (remove=0):   5%|▌         | 36/700 [00:11<03:25,  3.23it/s]Training (remove=0):   5%|▌         | 37/700 [00:11<03:25,  3.23it/s]Training (remove=0):   5%|▌         | 38/700 [00:12<03:25,  3.23it/s]Training (remove=0):   6%|▌         | 39/700 [00:12<03:24,  3.23it/s]Training (remove=0):   6%|▌         | 40/700 [00:12<03:24,  3.23it/s]Training (remove=0):   6%|▌         | 41/700 [00:12<03:23,  3.23it/s]Training (remove=0):   6%|▌         | 42/700 [00:13<03:23,  3.23it/s]Training (remove=0):   6%|▌         | 43/700 [00:13<03:23,  3.23it/s]Training (remove=0):   6%|▋         | 44/700 [00:13<03:22,  3.23it/s]Training (remove=0):   6%|▋         | 45/700 [00:14<03:22,  3.23it/s]Training (remove=0):   7%|▋         | 46/700 [00:14<03:22,  3.22it/s]Training (remove=0):   7%|▋         | 47/700 [00:14<03:22,  3.22it/s]Training (remove=0):   7%|▋         | 48/700 [00:15<03:22,  3.23it/s]Training (remove=0):   7%|▋         | 49/700 [00:15<03:21,  3.23it/s]Training (remove=0):   7%|▋         | 50/700 [00:15<03:21,  3.23it/s]Training (remove=0):   7%|▋         | 51/700 [00:16<03:20,  3.23it/s]Training (remove=0):   7%|▋         | 52/700 [00:16<03:20,  3.23it/s]Training (remove=0):   8%|▊         | 53/700 [00:16<03:20,  3.23it/s]Training (remove=0):   8%|▊         | 54/700 [00:17<03:19,  3.23it/s]Training (remove=0):   8%|▊         | 55/700 [00:17<03:19,  3.23it/s]Training (remove=0):   8%|▊         | 56/700 [00:17<03:19,  3.23it/s]Training (remove=0):   8%|▊         | 57/700 [00:17<03:19,  3.23it/s]Training (remove=0):   8%|▊         | 58/700 [00:18<03:18,  3.23it/s]Training (remove=0):   8%|▊         | 59/700 [00:18<03:19,  3.21it/s]Training (remove=0):   9%|▊         | 60/700 [00:18<03:19,  3.21it/s]Training (remove=0):   9%|▊         | 61/700 [00:19<03:18,  3.22it/s]Training (remove=0):   9%|▉         | 62/700 [00:19<03:18,  3.22it/s]Training (remove=0):   9%|▉         | 63/700 [00:19<03:17,  3.22it/s]Training (remove=0):   9%|▉         | 64/700 [00:20<03:17,  3.22it/s]Training (remove=0):   9%|▉         | 65/700 [00:20<03:16,  3.23it/s]Training (remove=0):   9%|▉         | 66/700 [00:20<03:16,  3.23it/s]Training (remove=0):  10%|▉         | 67/700 [00:21<03:16,  3.23it/s]Training (remove=0):  10%|▉         | 68/700 [00:21<03:15,  3.23it/s]Training (remove=0):  10%|▉         | 69/700 [00:21<03:15,  3.23it/s]Training (remove=0):  10%|█         | 70/700 [00:21<03:15,  3.23it/s]Training (remove=0):  10%|█         | 71/700 [00:22<03:14,  3.23it/s]Training (remove=0):  10%|█         | 72/700 [00:22<03:14,  3.23it/s]Training (remove=0):  10%|█         | 73/700 [00:22<03:14,  3.23it/s]Training (remove=0):  11%|█         | 74/700 [00:23<03:13,  3.23it/s]Training (remove=0):  11%|█         | 75/700 [00:23<03:13,  3.23it/s]Training (remove=0):  11%|█         | 76/700 [00:23<03:13,  3.23it/s]Training (remove=0):  11%|█         | 77/700 [00:24<03:12,  3.23it/s]Training (remove=0):  11%|█         | 78/700 [00:24<03:12,  3.23it/s]Training (remove=0):  11%|█▏        | 79/700 [00:24<03:12,  3.23it/s]Training (remove=0):  11%|█▏        | 80/700 [00:25<03:11,  3.23it/s]Training (remove=0):  12%|█▏        | 81/700 [00:25<03:11,  3.23it/s]Training (remove=0):  12%|█▏        | 82/700 [00:25<03:11,  3.23it/s]Training (remove=0):  12%|█▏        | 83/700 [00:26<03:11,  3.22it/s]Training (remove=0):  12%|█▏        | 84/700 [00:26<03:10,  3.23it/s]Training (remove=0):  12%|█▏        | 85/700 [00:26<03:10,  3.23it/s]Training (remove=0):  12%|█▏        | 86/700 [00:26<03:10,  3.22it/s]Training (remove=0):  12%|█▏        | 87/700 [00:27<03:10,  3.22it/s]Training (remove=0):  13%|█▎        | 88/700 [00:27<03:09,  3.23it/s]Training (remove=0):  13%|█▎        | 89/700 [00:27<03:09,  3.23it/s]Training (remove=0):  13%|█▎        | 90/700 [00:28<03:09,  3.23it/s]Training (remove=0):  13%|█▎        | 91/700 [00:28<03:08,  3.22it/s]Training (remove=0):  13%|█▎        | 92/700 [00:28<03:08,  3.23it/s]Training (remove=0):  13%|█▎        | 93/700 [00:29<03:08,  3.23it/s]Training (remove=0):  13%|█▎        | 94/700 [00:29<03:07,  3.23it/s]Training (remove=0):  14%|█▎        | 95/700 [00:29<03:07,  3.23it/s]Training (remove=0):  14%|█▎        | 96/700 [00:30<03:07,  3.23it/s]Training (remove=0):  14%|█▍        | 97/700 [00:30<03:06,  3.23it/s]Training (remove=0):  14%|█▍        | 98/700 [00:30<03:06,  3.23it/s]Training (remove=0):  14%|█▍        | 99/700 [00:30<03:06,  3.23it/s]Training (remove=0):  14%|█▍        | 100/700 [00:31<03:05,  3.23it/s]Training (remove=0):  14%|█▍        | 101/700 [00:31<03:05,  3.23it/s]Training (remove=0):  15%|█▍        | 102/700 [00:31<03:05,  3.23it/s]Training (remove=0):  15%|█▍        | 103/700 [00:32<03:04,  3.23it/s]Training (remove=0):  15%|█▍        | 104/700 [00:32<03:10,  3.13it/s]Training (remove=0):  15%|█▌        | 105/700 [00:32<03:08,  3.16it/s]Training (remove=0):  15%|█▌        | 106/700 [00:33<03:06,  3.18it/s]Training (remove=0):  15%|█▌        | 107/700 [00:33<03:05,  3.20it/s]Training (remove=0):  15%|█▌        | 108/700 [00:33<03:04,  3.21it/s]Training (remove=0):  16%|█▌        | 109/700 [00:34<03:04,  3.21it/s]Training (remove=0):  16%|█▌        | 110/700 [00:34<03:03,  3.22it/s]Training (remove=0):  16%|█▌        | 111/700 [00:34<03:02,  3.22it/s]Training (remove=0):  16%|█▌        | 112/700 [00:35<03:02,  3.22it/s]Training (remove=0):  16%|█▌        | 113/700 [00:35<03:02,  3.22it/s]Training (remove=0):  16%|█▋        | 114/700 [00:35<03:01,  3.22it/s]Training (remove=0):  16%|█▋        | 115/700 [00:35<03:01,  3.23it/s]Training (remove=0):  17%|█▋        | 116/700 [00:36<03:00,  3.23it/s]Training (remove=0):  17%|█▋        | 117/700 [00:36<03:00,  3.23it/s]Training (remove=0):  17%|█▋        | 118/700 [00:36<03:00,  3.23it/s]Training (remove=0):  17%|█▋        | 119/700 [00:37<02:59,  3.23it/s]Training (remove=0):  17%|█▋        | 120/700 [00:37<02:59,  3.23it/s]Training (remove=0):  17%|█▋        | 121/700 [00:37<02:59,  3.23it/s]Training (remove=0):  17%|█▋        | 122/700 [00:38<02:58,  3.23it/s]Training (remove=0):  18%|█▊        | 123/700 [00:38<02:58,  3.23it/s]Training (remove=0):  18%|█▊        | 124/700 [00:38<02:58,  3.23it/s]Training (remove=0):  18%|█▊        | 125/700 [00:39<02:58,  3.23it/s]Training (remove=0):  18%|█▊        | 126/700 [00:39<02:57,  3.23it/s]Training (remove=0):  18%|█▊        | 127/700 [00:39<02:57,  3.23it/s]Training (remove=0):  18%|█▊        | 128/700 [00:39<02:56,  3.23it/s]Training (remove=0):  18%|█▊        | 129/700 [00:40<02:56,  3.23it/s]Training (remove=0):  19%|█▊        | 130/700 [00:40<02:56,  3.23it/s]Training (remove=0):  19%|█▊        | 131/700 [00:40<02:56,  3.23it/s]Training (remove=0):  19%|█▉        | 132/700 [00:41<02:55,  3.23it/s]Training (remove=0):  19%|█▉        | 133/700 [00:41<02:55,  3.23it/s]Training (remove=0):  19%|█▉        | 134/700 [00:41<02:55,  3.23it/s]Training (remove=0):  19%|█▉        | 135/700 [00:42<02:55,  3.23it/s]Training (remove=0):  19%|█▉        | 136/700 [00:42<02:54,  3.23it/s]Training (remove=0):  20%|█▉        | 137/700 [00:42<02:54,  3.23it/s]Training (remove=0):  20%|█▉        | 138/700 [00:43<02:54,  3.23it/s]Training (remove=0):  20%|█▉        | 139/700 [00:43<02:53,  3.23it/s]Training (remove=0):  20%|██        | 140/700 [00:43<02:53,  3.23it/s]Training (remove=0):  20%|██        | 141/700 [00:44<02:53,  3.23it/s]Training (remove=0):  20%|██        | 142/700 [00:44<02:52,  3.23it/s]Training (remove=0):  20%|██        | 143/700 [00:44<02:52,  3.23it/s]Training (remove=0):  21%|██        | 144/700 [00:44<02:52,  3.23it/s]Training (remove=0):  21%|██        | 145/700 [00:45<02:52,  3.22it/s]Training (remove=0):  21%|██        | 146/700 [00:45<02:51,  3.23it/s]Training (remove=0):  21%|██        | 147/700 [00:45<02:51,  3.23it/s]Training (remove=0):  21%|██        | 148/700 [00:46<02:51,  3.22it/s]Training (remove=0):  21%|██▏       | 149/700 [00:46<02:50,  3.22it/s]Training (remove=0):  21%|██▏       | 150/700 [00:46<02:50,  3.23it/s]Training (remove=0):  22%|██▏       | 151/700 [00:47<02:49,  3.23it/s]Training (remove=0):  22%|██▏       | 152/700 [00:47<02:49,  3.23it/s]Training (remove=0):  22%|██▏       | 153/700 [00:47<02:49,  3.23it/s]Training (remove=0):  22%|██▏       | 154/700 [00:48<02:49,  3.23it/s]Training (remove=0):  22%|██▏       | 155/700 [00:48<02:48,  3.23it/s]Training (remove=0):  22%|██▏       | 156/700 [00:48<02:48,  3.23it/s]Training (remove=0):  22%|██▏       | 157/700 [00:48<02:48,  3.23it/s]Training (remove=0):  23%|██▎       | 158/700 [00:49<02:47,  3.23it/s]Training (remove=0):  23%|██▎       | 159/700 [00:49<02:47,  3.23it/s]Training (remove=0):  23%|██▎       | 160/700 [00:49<02:47,  3.23it/s]Training (remove=0):  23%|██▎       | 161/700 [00:50<02:47,  3.22it/s]Training (remove=0):  23%|██▎       | 162/700 [00:50<02:47,  3.22it/s]Training (remove=0):  23%|██▎       | 163/700 [00:50<02:46,  3.22it/s]Training (remove=0):  23%|██▎       | 164/700 [00:51<02:46,  3.22it/s]Training (remove=0):  24%|██▎       | 165/700 [00:51<02:45,  3.23it/s]Training (remove=0):  24%|██▎       | 166/700 [00:51<02:45,  3.23it/s]Training (remove=0):  24%|██▍       | 167/700 [00:52<02:44,  3.23it/s]Training (remove=0):  24%|██▍       | 168/700 [00:52<02:44,  3.23it/s]Training (remove=0):  24%|██▍       | 169/700 [00:52<02:44,  3.23it/s]Training (remove=0):  24%|██▍       | 170/700 [00:52<02:43,  3.23it/s]Training (remove=0):  24%|██▍       | 171/700 [00:53<02:43,  3.23it/s]Training (remove=0):  25%|██▍       | 172/700 [00:53<02:43,  3.23it/s]Training (remove=0):  25%|██▍       | 173/700 [00:53<02:43,  3.23it/s]Training (remove=0):  25%|██▍       | 174/700 [00:54<02:42,  3.23it/s]Training (remove=0):  25%|██▌       | 175/700 [00:54<02:42,  3.23it/s]Training (remove=0):  25%|██▌       | 176/700 [00:54<02:42,  3.22it/s]Training (remove=0):  25%|██▌       | 177/700 [00:55<02:42,  3.22it/s]Training (remove=0):  25%|██▌       | 178/700 [00:55<02:41,  3.22it/s]Training (remove=0):  26%|██▌       | 179/700 [00:55<02:41,  3.22it/s]Training (remove=0):  26%|██▌       | 180/700 [00:56<02:41,  3.23it/s]Training (remove=0):  26%|██▌       | 181/700 [00:56<02:40,  3.23it/s]Training (remove=0):  26%|██▌       | 182/700 [00:56<02:40,  3.23it/s]Training (remove=0):  26%|██▌       | 183/700 [00:57<02:40,  3.23it/s]Training (remove=0):  26%|██▋       | 184/700 [00:57<02:39,  3.23it/s]Training (remove=0):  26%|██▋       | 185/700 [00:57<02:39,  3.23it/s]Training (remove=0):  27%|██▋       | 186/700 [00:57<02:38,  3.23it/s]Training (remove=0):  27%|██▋       | 187/700 [00:58<02:38,  3.23it/s]Training (remove=0):  27%|██▋       | 188/700 [00:58<02:38,  3.23it/s]Training (remove=0):  27%|██▋       | 189/700 [00:58<02:38,  3.23it/s]Training (remove=0):  27%|██▋       | 190/700 [00:59<02:38,  3.22it/s]Training (remove=0):  27%|██▋       | 191/700 [00:59<02:37,  3.23it/s]Training (remove=0):  27%|██▋       | 192/700 [00:59<02:37,  3.22it/s]Training (remove=0):  28%|██▊       | 193/700 [01:00<02:37,  3.23it/s]Training (remove=0):  28%|██▊       | 194/700 [01:00<02:36,  3.23it/s]Training (remove=0):  28%|██▊       | 195/700 [01:00<02:36,  3.23it/s]Training (remove=0):  28%|██▊       | 196/700 [01:01<02:36,  3.23it/s]Training (remove=0):  28%|██▊       | 197/700 [01:01<02:35,  3.23it/s]Training (remove=0):  28%|██▊       | 198/700 [01:01<02:35,  3.23it/s]Training (remove=0):  28%|██▊       | 199/700 [01:01<02:35,  3.23it/s]Training (remove=0):  29%|██▊       | 200/700 [01:02<02:34,  3.23it/s]Training (remove=0):  29%|██▊       | 201/700 [01:02<02:34,  3.23it/s]Training (remove=0):  29%|██▉       | 202/700 [01:02<02:34,  3.23it/s]Training (remove=0):  29%|██▉       | 203/700 [01:03<02:33,  3.23it/s]Training (remove=0):  29%|██▉       | 204/700 [01:03<02:33,  3.23it/s]Training (remove=0):  29%|██▉       | 205/700 [01:03<02:33,  3.23it/s]Training (remove=0):  29%|██▉       | 206/700 [01:04<02:33,  3.22it/s]Training (remove=0):  30%|██▉       | 207/700 [01:04<02:33,  3.22it/s]Training (remove=0):  30%|██▉       | 208/700 [01:04<02:32,  3.22it/s]Training (remove=0):  30%|██▉       | 209/700 [01:05<02:32,  3.22it/s]Training (remove=0):  30%|███       | 210/700 [01:05<02:31,  3.22it/s]Training (remove=0):  30%|███       | 211/700 [01:05<02:31,  3.23it/s]Training (remove=0):  30%|███       | 212/700 [01:06<02:31,  3.23it/s]Training (remove=0):  30%|███       | 213/700 [01:06<02:30,  3.23it/s]Training (remove=0):  31%|███       | 214/700 [01:06<02:30,  3.23it/s]Training (remove=0):  31%|███       | 215/700 [01:06<02:30,  3.23it/s]Training (remove=0):  31%|███       | 216/700 [01:07<02:29,  3.23it/s]Training (remove=0):  31%|███       | 217/700 [01:07<02:29,  3.23it/s]Training (remove=0):  31%|███       | 218/700 [01:07<02:29,  3.23it/s]Training (remove=0):  31%|███▏      | 219/700 [01:08<02:29,  3.23it/s]Training (remove=0):  31%|███▏      | 220/700 [01:08<02:28,  3.23it/s]Training (remove=0):  32%|███▏      | 221/700 [01:08<02:28,  3.23it/s]Training (remove=0):  32%|███▏      | 222/700 [01:09<02:28,  3.22it/s]Training (remove=0):  32%|███▏      | 223/700 [01:09<02:28,  3.22it/s]Training (remove=0):  32%|███▏      | 224/700 [01:09<02:27,  3.22it/s]Training (remove=0):  32%|███▏      | 225/700 [01:10<02:27,  3.23it/s]Training (remove=0):  32%|███▏      | 226/700 [01:10<02:27,  3.22it/s]Training (remove=0):  32%|███▏      | 227/700 [01:10<02:26,  3.22it/s]Training (remove=0):  33%|███▎      | 228/700 [01:10<02:26,  3.23it/s]Training (remove=0):  33%|███▎      | 229/700 [01:11<02:25,  3.23it/s]Training (remove=0):  33%|███▎      | 230/700 [01:11<02:25,  3.23it/s]Training (remove=0):  33%|███▎      | 231/700 [01:11<02:25,  3.23it/s]Training (remove=0):  33%|███▎      | 232/700 [01:12<02:24,  3.23it/s]Training (remove=0):  33%|███▎      | 233/700 [01:12<02:24,  3.23it/s]Training (remove=0):  33%|███▎      | 234/700 [01:12<02:24,  3.23it/s]Training (remove=0):  34%|███▎      | 235/700 [01:13<02:24,  3.23it/s]Training (remove=0):  34%|███▎      | 236/700 [01:13<02:23,  3.23it/s]Training (remove=0):  34%|███▍      | 237/700 [01:13<02:23,  3.22it/s]Training (remove=0):  34%|███▍      | 238/700 [01:14<02:23,  3.22it/s]Training (remove=0):  34%|███▍      | 239/700 [01:14<02:22,  3.23it/s]Training (remove=0):  34%|███▍      | 240/700 [01:14<02:22,  3.23it/s]Training (remove=0):  34%|███▍      | 241/700 [01:14<02:22,  3.23it/s]Training (remove=0):  35%|███▍      | 242/700 [01:15<02:22,  3.23it/s]Training (remove=0):  35%|███▍      | 243/700 [01:15<02:21,  3.23it/s]Training (remove=0):  35%|███▍      | 244/700 [01:15<02:21,  3.23it/s]Training (remove=0):  35%|███▌      | 245/700 [01:16<02:20,  3.23it/s]Training (remove=0):  35%|███▌      | 246/700 [01:16<02:20,  3.23it/s]Training (remove=0):  35%|███▌      | 247/700 [01:16<02:20,  3.23it/s]Training (remove=0):  35%|███▌      | 248/700 [01:17<02:19,  3.23it/s]Training (remove=0):  36%|███▌      | 249/700 [01:17<02:19,  3.23it/s]Training (remove=0):  36%|███▌      | 250/700 [01:17<02:19,  3.23it/s]Training (remove=0):  36%|███▌      | 251/700 [01:18<02:19,  3.23it/s]Training (remove=0):  36%|███▌      | 252/700 [01:18<02:18,  3.23it/s]Training (remove=0):  36%|███▌      | 253/700 [01:18<02:18,  3.23it/s]Training (remove=0):  36%|███▋      | 254/700 [01:19<02:18,  3.23it/s]Training (remove=0):  36%|███▋      | 255/700 [01:19<02:17,  3.23it/s]Training (remove=0):  37%|███▋      | 256/700 [01:19<02:17,  3.22it/s]Training (remove=0):  37%|███▋      | 257/700 [01:19<02:17,  3.22it/s]Training (remove=0):  37%|███▋      | 258/700 [01:20<02:17,  3.22it/s]Training (remove=0):  37%|███▋      | 259/700 [01:20<02:16,  3.22it/s]Training (remove=0):  37%|███▋      | 260/700 [01:20<02:16,  3.23it/s]Training (remove=0):  37%|███▋      | 261/700 [01:21<02:16,  3.23it/s]Training (remove=0):  37%|███▋      | 262/700 [01:21<02:15,  3.22it/s]Training (remove=0):  38%|███▊      | 263/700 [01:21<02:15,  3.22it/s]Training (remove=0):  38%|███▊      | 264/700 [01:22<02:33,  2.84it/s]Training (remove=0):  38%|███▊      | 265/700 [01:22<02:27,  2.94it/s]Training (remove=0):  38%|███▊      | 266/700 [01:22<02:23,  3.02it/s]Training (remove=0):  38%|███▊      | 267/700 [01:23<02:20,  3.07it/s]Training (remove=0):  38%|███▊      | 268/700 [01:23<02:18,  3.12it/s]Training (remove=0):  38%|███▊      | 269/700 [01:23<02:17,  3.14it/s]Training (remove=0):  39%|███▊      | 270/700 [01:24<02:16,  3.16it/s]Training (remove=0):  39%|███▊      | 271/700 [01:24<02:15,  3.17it/s]Training (remove=0):  39%|███▉      | 272/700 [01:24<02:14,  3.19it/s]Training (remove=0):  39%|███▉      | 273/700 [01:25<02:13,  3.20it/s]Training (remove=0):  39%|███▉      | 274/700 [01:25<02:12,  3.21it/s]Training (remove=0):  39%|███▉      | 275/700 [01:25<02:12,  3.22it/s]Training (remove=0):  39%|███▉      | 276/700 [01:25<02:11,  3.22it/s]Training (remove=0):  40%|███▉      | 277/700 [01:26<02:11,  3.22it/s]Training (remove=0):  40%|███▉      | 278/700 [01:26<02:10,  3.22it/s]Training (remove=0):  40%|███▉      | 279/700 [01:26<02:10,  3.22it/s]Training (remove=0):  40%|████      | 280/700 [01:27<02:10,  3.22it/s]Training (remove=0):  40%|████      | 281/700 [01:27<02:10,  3.22it/s]Training (remove=0):  40%|████      | 282/700 [01:27<02:09,  3.22it/s]Training (remove=0):  40%|████      | 283/700 [01:28<02:09,  3.22it/s]Training (remove=0):  41%|████      | 284/700 [01:28<02:08,  3.23it/s]Training (remove=0):  41%|████      | 285/700 [01:28<02:08,  3.23it/s]Training (remove=0):  41%|████      | 286/700 [01:29<02:08,  3.22it/s]Training (remove=0):  41%|████      | 287/700 [01:29<02:08,  3.22it/s]Training (remove=0):  41%|████      | 288/700 [01:29<02:07,  3.22it/s]Training (remove=0):  41%|████▏     | 289/700 [01:30<02:07,  3.22it/s]Training (remove=0):  41%|████▏     | 290/700 [01:30<02:07,  3.23it/s]Training (remove=0):  42%|████▏     | 291/700 [01:30<02:06,  3.23it/s]Training (remove=0):  42%|████▏     | 292/700 [01:30<02:06,  3.22it/s]Training (remove=0):  42%|████▏     | 293/700 [01:31<02:06,  3.23it/s]Training (remove=0):  42%|████▏     | 294/700 [01:31<02:05,  3.23it/s]Training (remove=0):  42%|████▏     | 295/700 [01:31<02:05,  3.22it/s]Training (remove=0):  42%|████▏     | 296/700 [01:32<02:05,  3.22it/s]Training (remove=0):  42%|████▏     | 297/700 [01:32<02:04,  3.23it/s]Training (remove=0):  43%|████▎     | 298/700 [01:32<02:04,  3.23it/s]Training (remove=0):  43%|████▎     | 299/700 [01:33<02:04,  3.23it/s]Training (remove=0):  43%|████▎     | 300/700 [01:33<02:03,  3.23it/s]Training (remove=0):  43%|████▎     | 301/700 [01:33<02:03,  3.22it/s]Training (remove=0):  43%|████▎     | 302/700 [01:34<02:03,  3.22it/s]Training (remove=0):  43%|████▎     | 303/700 [01:34<02:03,  3.22it/s]Training (remove=0):  43%|████▎     | 304/700 [01:34<02:02,  3.23it/s]Training (remove=0):  44%|████▎     | 305/700 [01:34<02:02,  3.23it/s]Training (remove=0):  44%|████▎     | 306/700 [01:35<02:02,  3.22it/s]Training (remove=0):  44%|████▍     | 307/700 [01:35<02:01,  3.22it/s]Training (remove=0):  44%|████▍     | 308/700 [01:35<02:01,  3.22it/s]Training (remove=0):  44%|████▍     | 309/700 [01:36<02:01,  3.23it/s]Training (remove=0):  44%|████▍     | 310/700 [01:36<02:00,  3.23it/s]Training (remove=0):  44%|████▍     | 311/700 [01:36<02:00,  3.23it/s]Training (remove=0):  45%|████▍     | 312/700 [01:37<02:00,  3.23it/s]Training (remove=0):  45%|████▍     | 313/700 [01:37<01:59,  3.23it/s]Training (remove=0):  45%|████▍     | 314/700 [01:37<01:59,  3.23it/s]Training (remove=0):  45%|████▌     | 315/700 [01:38<01:59,  3.22it/s]Training (remove=0):  45%|████▌     | 316/700 [01:38<01:59,  3.23it/s]Training (remove=0):  45%|████▌     | 317/700 [01:38<01:58,  3.23it/s]Training (remove=0):  45%|████▌     | 318/700 [01:39<01:58,  3.23it/s]Training (remove=0):  46%|████▌     | 319/700 [01:39<01:58,  3.23it/s]Training (remove=0):  46%|████▌     | 320/700 [01:39<01:57,  3.23it/s]Training (remove=0):  46%|████▌     | 321/700 [01:39<01:57,  3.23it/s]Training (remove=0):  46%|████▌     | 322/700 [01:40<01:57,  3.23it/s]Training (remove=0):  46%|████▌     | 323/700 [01:40<01:56,  3.23it/s]Training (remove=0):  46%|████▋     | 324/700 [01:40<01:56,  3.23it/s]Training (remove=0):  46%|████▋     | 325/700 [01:41<01:56,  3.23it/s]Training (remove=0):  47%|████▋     | 326/700 [01:41<01:55,  3.23it/s]Training (remove=0):  47%|████▋     | 327/700 [01:41<01:55,  3.23it/s]Training (remove=0):  47%|████▋     | 328/700 [01:42<01:55,  3.23it/s]Training (remove=0):  47%|████▋     | 329/700 [01:42<01:54,  3.23it/s]Training (remove=0):  47%|████▋     | 330/700 [01:42<01:54,  3.23it/s]Training (remove=0):  47%|████▋     | 331/700 [01:43<01:54,  3.23it/s]Training (remove=0):  47%|████▋     | 332/700 [01:43<01:54,  3.23it/s]Training (remove=0):  48%|████▊     | 333/700 [01:43<01:53,  3.23it/s]Training (remove=0):  48%|████▊     | 334/700 [01:43<01:53,  3.23it/s]Training (remove=0):  48%|████▊     | 335/700 [01:44<01:52,  3.23it/s]Training (remove=0):  48%|████▊     | 336/700 [01:44<01:52,  3.23it/s]Training (remove=0):  48%|████▊     | 337/700 [01:44<01:52,  3.23it/s]Training (remove=0):  48%|████▊     | 338/700 [01:45<01:52,  3.23it/s]Training (remove=0):  48%|████▊     | 339/700 [01:45<01:51,  3.23it/s]Training (remove=0):  49%|████▊     | 340/700 [01:45<01:51,  3.23it/s]Training (remove=0):  49%|████▊     | 341/700 [01:46<01:51,  3.23it/s]Training (remove=0):  49%|████▉     | 342/700 [01:46<01:50,  3.23it/s]Training (remove=0):  49%|████▉     | 343/700 [01:46<01:50,  3.23it/s]Training (remove=0):  49%|████▉     | 344/700 [01:47<01:50,  3.23it/s]Training (remove=0):  49%|████▉     | 345/700 [01:47<01:49,  3.23it/s]Training (remove=0):  49%|████▉     | 346/700 [01:47<01:49,  3.23it/s]Training (remove=0):  50%|████▉     | 347/700 [01:47<01:49,  3.23it/s]Training (remove=0):  50%|████▉     | 348/700 [01:48<01:48,  3.24it/s]Training (remove=0):  50%|████▉     | 349/700 [01:48<01:48,  3.24it/s]Training (remove=0):  50%|█████     | 350/700 [01:48<01:48,  3.24it/s]Training (remove=0):  50%|█████     | 351/700 [01:49<01:48,  3.23it/s]Training (remove=0):  50%|█████     | 352/700 [01:49<01:47,  3.23it/s]Training (remove=0):  50%|█████     | 353/700 [01:49<01:47,  3.23it/s]Training (remove=0):  51%|█████     | 354/700 [01:50<01:47,  3.23it/s]Training (remove=0):  51%|█████     | 355/700 [01:50<01:46,  3.23it/s]Training (remove=0):  51%|█████     | 356/700 [01:50<01:46,  3.23it/s]Training (remove=0):  51%|█████     | 357/700 [01:51<01:46,  3.23it/s]Training (remove=0):  51%|█████     | 358/700 [01:51<01:45,  3.23it/s]Training (remove=0):  51%|█████▏    | 359/700 [01:51<01:45,  3.24it/s]Training (remove=0):  51%|█████▏    | 360/700 [01:52<01:45,  3.24it/s]Training (remove=0):  52%|█████▏    | 361/700 [01:52<01:44,  3.24it/s]Training (remove=0):  52%|█████▏    | 362/700 [01:52<01:44,  3.24it/s]Training (remove=0):  52%|█████▏    | 363/700 [01:52<01:44,  3.23it/s]Training (remove=0):  52%|█████▏    | 364/700 [01:53<01:43,  3.23it/s]Training (remove=0):  52%|█████▏    | 365/700 [01:53<01:43,  3.23it/s]Training (remove=0):  52%|█████▏    | 366/700 [01:53<01:43,  3.23it/s]Training (remove=0):  52%|█████▏    | 367/700 [01:54<01:42,  3.23it/s]Training (remove=0):  53%|█████▎    | 368/700 [01:54<01:42,  3.24it/s]Training (remove=0):  53%|█████▎    | 369/700 [01:54<01:42,  3.24it/s]Training (remove=0):  53%|█████▎    | 370/700 [01:55<01:41,  3.24it/s]Training (remove=0):  53%|█████▎    | 371/700 [01:55<01:41,  3.24it/s]Training (remove=0):  53%|█████▎    | 372/700 [01:55<01:41,  3.24it/s]Training (remove=0):  53%|█████▎    | 373/700 [01:56<01:41,  3.24it/s]Training (remove=0):  53%|█████▎    | 374/700 [01:56<01:40,  3.23it/s]Training (remove=0):  54%|█████▎    | 375/700 [01:56<01:40,  3.23it/s]Training (remove=0):  54%|█████▎    | 376/700 [01:56<01:40,  3.23it/s]Training (remove=0):  54%|█████▍    | 377/700 [01:57<01:39,  3.24it/s]Training (remove=0):  54%|█████▍    | 378/700 [01:57<01:39,  3.24it/s]Training (remove=0):  54%|█████▍    | 379/700 [01:57<01:39,  3.24it/s]Training (remove=0):  54%|█████▍    | 380/700 [01:58<01:38,  3.24it/s]Training (remove=0):  54%|█████▍    | 381/700 [01:58<01:38,  3.24it/s]Training (remove=0):  55%|█████▍    | 382/700 [01:58<01:38,  3.24it/s]Training (remove=0):  55%|█████▍    | 383/700 [01:59<01:37,  3.24it/s]Training (remove=0):  55%|█████▍    | 384/700 [01:59<01:37,  3.24it/s]Training (remove=0):  55%|█████▌    | 385/700 [01:59<01:37,  3.23it/s]Training (remove=0):  55%|█████▌    | 386/700 [02:00<01:37,  3.24it/s]Training (remove=0):  55%|█████▌    | 387/700 [02:00<01:36,  3.24it/s]Training (remove=0):  55%|█████▌    | 388/700 [02:00<01:36,  3.23it/s]Training (remove=0):  56%|█████▌    | 389/700 [02:00<01:36,  3.23it/s]Training (remove=0):  56%|█████▌    | 390/700 [02:01<01:35,  3.24it/s]Training (remove=0):  56%|█████▌    | 391/700 [02:01<01:35,  3.23it/s]Training (remove=0):  56%|█████▌    | 392/700 [02:01<01:35,  3.23it/s]Training (remove=0):  56%|█████▌    | 393/700 [02:02<01:34,  3.24it/s]Training (remove=0):  56%|█████▋    | 394/700 [02:02<01:34,  3.24it/s]Training (remove=0):  56%|█████▋    | 395/700 [02:02<01:34,  3.24it/s]Training (remove=0):  57%|█████▋    | 396/700 [02:03<01:33,  3.24it/s]Training (remove=0):  57%|█████▋    | 397/700 [02:03<01:33,  3.24it/s]Training (remove=0):  57%|█████▋    | 398/700 [02:03<01:33,  3.24it/s]Training (remove=0):  57%|█████▋    | 399/700 [02:04<01:33,  3.23it/s]Training (remove=0):  57%|█████▋    | 400/700 [02:04<01:32,  3.23it/s]Training (remove=0):  57%|█████▋    | 401/700 [02:04<01:32,  3.23it/s]Training (remove=0):  57%|█████▋    | 402/700 [02:04<01:32,  3.23it/s]Training (remove=0):  58%|█████▊    | 403/700 [02:05<01:31,  3.24it/s]Training (remove=0):  58%|█████▊    | 404/700 [02:05<01:31,  3.24it/s]Training (remove=0):  58%|█████▊    | 405/700 [02:05<01:31,  3.24it/s]Training (remove=0):  58%|█████▊    | 406/700 [02:06<01:30,  3.24it/s]Training (remove=0):  58%|█████▊    | 407/700 [02:06<01:30,  3.24it/s]Training (remove=0):  58%|█████▊    | 408/700 [02:06<01:30,  3.24it/s]Training (remove=0):  58%|█████▊    | 409/700 [02:07<01:29,  3.24it/s]Training (remove=0):  59%|█████▊    | 410/700 [02:07<01:29,  3.24it/s]Training (remove=0):  59%|█████▊    | 411/700 [02:07<01:29,  3.24it/s]Training (remove=0):  59%|█████▉    | 412/700 [02:08<01:28,  3.24it/s]Training (remove=0):  59%|█████▉    | 413/700 [02:08<01:28,  3.24it/s]Training (remove=0):  59%|█████▉    | 414/700 [02:08<01:28,  3.24it/s]Training (remove=0):  59%|█████▉    | 415/700 [02:09<01:28,  3.24it/s]Training (remove=0):  59%|█████▉    | 416/700 [02:09<01:27,  3.23it/s]Training (remove=0):  60%|█████▉    | 417/700 [02:09<01:27,  3.23it/s]Training (remove=0):  60%|█████▉    | 418/700 [02:09<01:27,  3.24it/s]Training (remove=0):  60%|█████▉    | 419/700 [02:10<01:26,  3.24it/s]Training (remove=0):  60%|██████    | 420/700 [02:10<01:26,  3.23it/s]Training (remove=0):  60%|██████    | 421/700 [02:10<01:26,  3.23it/s]Training (remove=0):  60%|██████    | 422/700 [02:11<01:26,  3.23it/s]Training (remove=0):  60%|██████    | 423/700 [02:11<01:25,  3.23it/s]Training (remove=0):  61%|██████    | 424/700 [02:11<01:25,  3.22it/s]Training (remove=0):  61%|██████    | 425/700 [02:12<01:25,  3.23it/s]Training (remove=0):  61%|██████    | 426/700 [02:12<01:24,  3.23it/s]Training (remove=0):  61%|██████    | 427/700 [02:12<01:24,  3.23it/s]Training (remove=0):  61%|██████    | 428/700 [02:13<01:24,  3.24it/s]Training (remove=0):  61%|██████▏   | 429/700 [02:13<01:23,  3.24it/s]Training (remove=0):  61%|██████▏   | 430/700 [02:13<01:23,  3.24it/s]Training (remove=0):  62%|██████▏   | 431/700 [02:13<01:23,  3.23it/s]Training (remove=0):  62%|██████▏   | 432/700 [02:14<01:23,  3.22it/s]Training (remove=0):  62%|██████▏   | 433/700 [02:14<01:23,  3.19it/s]Training (remove=0):  62%|██████▏   | 434/700 [02:14<01:24,  3.17it/s]Training (remove=0):  62%|██████▏   | 435/700 [02:15<01:23,  3.16it/s]Training (remove=0):  62%|██████▏   | 436/700 [02:15<01:23,  3.15it/s]Training (remove=0):  62%|██████▏   | 437/700 [02:15<01:23,  3.14it/s]Training (remove=0):  63%|██████▎   | 438/700 [02:16<01:23,  3.14it/s]Training (remove=0):  63%|██████▎   | 439/700 [02:16<01:23,  3.14it/s]Training (remove=0):  63%|██████▎   | 440/700 [02:16<01:22,  3.14it/s]Training (remove=0):  63%|██████▎   | 441/700 [02:17<01:21,  3.18it/s]Training (remove=0):  63%|██████▎   | 442/700 [02:17<01:20,  3.20it/s]Training (remove=0):  63%|██████▎   | 443/700 [02:17<01:20,  3.20it/s]Training (remove=0):  63%|██████▎   | 444/700 [02:18<01:19,  3.21it/s]Training (remove=0):  64%|██████▎   | 445/700 [02:18<01:19,  3.21it/s]Training (remove=0):  64%|██████▎   | 446/700 [02:18<01:19,  3.21it/s]Training (remove=0):  64%|██████▍   | 447/700 [02:18<01:18,  3.21it/s]Training (remove=0):  64%|██████▍   | 448/700 [02:19<01:18,  3.21it/s]Training (remove=0):  64%|██████▍   | 449/700 [02:19<01:17,  3.22it/s]Training (remove=0):  64%|██████▍   | 450/700 [02:19<01:17,  3.22it/s]Training (remove=0):  64%|██████▍   | 451/700 [02:20<01:17,  3.22it/s]Training (remove=0):  65%|██████▍   | 452/700 [02:20<01:16,  3.23it/s]Training (remove=0):  65%|██████▍   | 453/700 [02:20<01:16,  3.23it/s]Training (remove=0):  65%|██████▍   | 454/700 [02:21<01:16,  3.23it/s]Training (remove=0):  65%|██████▌   | 455/700 [02:21<01:15,  3.23it/s]Training (remove=0):  65%|██████▌   | 456/700 [02:21<01:15,  3.23it/s]Training (remove=0):  65%|██████▌   | 457/700 [02:22<01:15,  3.22it/s]Training (remove=0):  65%|██████▌   | 458/700 [02:22<01:14,  3.23it/s]Training (remove=0):  66%|██████▌   | 459/700 [02:22<01:14,  3.23it/s]Training (remove=0):  66%|██████▌   | 460/700 [02:23<01:14,  3.23it/s]Training (remove=0):  66%|██████▌   | 461/700 [02:23<01:14,  3.23it/s]Training (remove=0):  66%|██████▌   | 462/700 [02:23<01:13,  3.23it/s]Training (remove=0):  66%|██████▌   | 463/700 [02:23<01:13,  3.23it/s]Training (remove=0):  66%|██████▋   | 464/700 [02:24<01:13,  3.22it/s]Training (remove=0):  66%|██████▋   | 465/700 [02:24<01:12,  3.23it/s]Training (remove=0):  67%|██████▋   | 466/700 [02:24<01:12,  3.23it/s]Training (remove=0):  67%|██████▋   | 467/700 [02:25<01:12,  3.23it/s]Training (remove=0):  67%|██████▋   | 468/700 [02:25<01:11,  3.23it/s]Training (remove=0):  67%|██████▋   | 469/700 [02:25<01:11,  3.23it/s]Training (remove=0):  67%|██████▋   | 470/700 [02:26<01:11,  3.23it/s]Training (remove=0):  67%|██████▋   | 471/700 [02:26<01:10,  3.23it/s]Training (remove=0):  67%|██████▋   | 472/700 [02:26<01:10,  3.23it/s]Training (remove=0):  68%|██████▊   | 473/700 [02:27<01:10,  3.23it/s]Training (remove=0):  68%|██████▊   | 474/700 [02:27<01:09,  3.23it/s]Training (remove=0):  68%|██████▊   | 475/700 [02:27<01:09,  3.23it/s]Training (remove=0):  68%|██████▊   | 476/700 [02:27<01:09,  3.23it/s]Training (remove=0):  68%|██████▊   | 477/700 [02:28<01:09,  3.23it/s]Training (remove=0):  68%|██████▊   | 478/700 [02:28<01:08,  3.23it/s]Training (remove=0):  68%|██████▊   | 479/700 [02:28<01:08,  3.23it/s]Training (remove=0):  69%|██████▊   | 480/700 [02:29<01:08,  3.23it/s]Training (remove=0):  69%|██████▊   | 481/700 [02:29<01:07,  3.23it/s]Training (remove=0):  69%|██████▉   | 482/700 [02:29<01:07,  3.23it/s]Training (remove=0):  69%|██████▉   | 483/700 [02:30<01:07,  3.22it/s]Training (remove=0):  69%|██████▉   | 484/700 [02:30<01:06,  3.23it/s]Training (remove=0):  69%|██████▉   | 485/700 [02:30<01:06,  3.23it/s]Training (remove=0):  69%|██████▉   | 486/700 [02:31<01:06,  3.23it/s]Training (remove=0):  70%|██████▉   | 487/700 [02:31<01:06,  3.22it/s]Training (remove=0):  70%|██████▉   | 488/700 [02:31<01:05,  3.22it/s]Training (remove=0):  70%|██████▉   | 489/700 [02:31<01:05,  3.22it/s]Training (remove=0):  70%|███████   | 490/700 [02:32<01:05,  3.22it/s]Training (remove=0):  70%|███████   | 491/700 [02:32<01:04,  3.23it/s]Training (remove=0):  70%|███████   | 492/700 [02:32<01:04,  3.23it/s]Training (remove=0):  70%|███████   | 493/700 [02:33<01:04,  3.22it/s]Training (remove=0):  71%|███████   | 494/700 [02:33<01:03,  3.23it/s]Training (remove=0):  71%|███████   | 495/700 [02:33<01:03,  3.23it/s]Training (remove=0):  71%|███████   | 496/700 [02:34<01:03,  3.23it/s]Training (remove=0):  71%|███████   | 497/700 [02:34<01:02,  3.23it/s]Training (remove=0):  71%|███████   | 498/700 [02:34<01:02,  3.23it/s]Training (remove=0):  71%|███████▏  | 499/700 [02:35<01:02,  3.23it/s]Training (remove=0):  71%|███████▏  | 500/700 [02:35<01:02,  3.22it/s]Training (remove=0):  72%|███████▏  | 501/700 [02:35<01:01,  3.22it/s]Training (remove=0):  72%|███████▏  | 502/700 [02:36<01:01,  3.22it/s]Training (remove=0):  72%|███████▏  | 503/700 [02:36<01:01,  3.23it/s]Training (remove=0):  72%|███████▏  | 504/700 [02:36<01:00,  3.23it/s]Training (remove=0):  72%|███████▏  | 505/700 [02:36<01:00,  3.23it/s]Training (remove=0):  72%|███████▏  | 506/700 [02:37<01:00,  3.23it/s]Training (remove=0):  72%|███████▏  | 507/700 [02:37<00:59,  3.23it/s]Training (remove=0):  73%|███████▎  | 508/700 [02:37<00:59,  3.23it/s]Training (remove=0):  73%|███████▎  | 509/700 [02:38<00:59,  3.23it/s]Training (remove=0):  73%|███████▎  | 510/700 [02:38<00:58,  3.23it/s]Training (remove=0):  73%|███████▎  | 511/700 [02:38<00:58,  3.23it/s]Training (remove=0):  73%|███████▎  | 512/700 [02:39<00:58,  3.23it/s]Training (remove=0):  73%|███████▎  | 513/700 [02:39<00:57,  3.23it/s]Training (remove=0):  73%|███████▎  | 514/700 [02:39<00:57,  3.23it/s]Training (remove=0):  74%|███████▎  | 515/700 [02:40<00:57,  3.23it/s]Training (remove=0):  74%|███████▎  | 516/700 [02:40<00:56,  3.23it/s]Training (remove=0):  74%|███████▍  | 517/700 [02:40<00:56,  3.23it/s]Training (remove=0):  74%|███████▍  | 518/700 [02:40<00:56,  3.23it/s]Training (remove=0):  74%|███████▍  | 519/700 [02:41<00:56,  3.23it/s]Training (remove=0):  74%|███████▍  | 520/700 [02:41<00:55,  3.23it/s]Training (remove=0):  74%|███████▍  | 521/700 [02:41<00:55,  3.23it/s]Training (remove=0):  75%|███████▍  | 522/700 [02:42<00:55,  3.23it/s]Training (remove=0):  75%|███████▍  | 523/700 [02:42<00:54,  3.22it/s]Training (remove=0):  75%|███████▍  | 524/700 [02:42<00:54,  3.22it/s]Training (remove=0):  75%|███████▌  | 525/700 [02:43<00:54,  3.23it/s]Training (remove=0):  75%|███████▌  | 526/700 [02:43<00:53,  3.23it/s]Training (remove=0):  75%|███████▌  | 527/700 [02:43<00:53,  3.23it/s]Training (remove=0):  75%|███████▌  | 528/700 [02:44<00:53,  3.23it/s]Training (remove=0):  76%|███████▌  | 529/700 [02:44<00:52,  3.23it/s]Training (remove=0):  76%|███████▌  | 530/700 [02:44<00:52,  3.23it/s]Training (remove=0):  76%|███████▌  | 531/700 [02:45<00:52,  3.23it/s]Training (remove=0):  76%|███████▌  | 532/700 [02:45<00:52,  3.23it/s]Training (remove=0):  76%|███████▌  | 533/700 [02:45<00:51,  3.23it/s]Training (remove=0):  76%|███████▋  | 534/700 [02:45<00:51,  3.23it/s]Training (remove=0):  76%|███████▋  | 535/700 [02:46<00:51,  3.23it/s]Training (remove=0):  77%|███████▋  | 536/700 [02:46<00:50,  3.23it/s]Training (remove=0):  77%|███████▋  | 537/700 [02:46<00:50,  3.23it/s]Training (remove=0):  77%|███████▋  | 538/700 [02:47<00:50,  3.23it/s]Training (remove=0):  77%|███████▋  | 539/700 [02:47<00:49,  3.23it/s]Training (remove=0):  77%|███████▋  | 540/700 [02:47<00:49,  3.23it/s]Training (remove=0):  77%|███████▋  | 541/700 [02:48<00:49,  3.23it/s]Training (remove=0):  77%|███████▋  | 542/700 [02:48<00:48,  3.23it/s]Training (remove=0):  78%|███████▊  | 543/700 [02:48<00:48,  3.23it/s]Training (remove=0):  78%|███████▊  | 544/700 [02:49<00:48,  3.23it/s]Training (remove=0):  78%|███████▊  | 545/700 [02:49<00:48,  3.23it/s]Training (remove=0):  78%|███████▊  | 546/700 [02:49<00:47,  3.22it/s]Training (remove=0):  78%|███████▊  | 547/700 [02:49<00:47,  3.22it/s]Training (remove=0):  78%|███████▊  | 548/700 [02:50<00:47,  3.22it/s]Training (remove=0):  78%|███████▊  | 549/700 [02:50<00:46,  3.22it/s]Training (remove=0):  79%|███████▊  | 550/700 [02:50<00:46,  3.22it/s]Training (remove=0):  79%|███████▊  | 551/700 [02:51<00:46,  3.22it/s]Training (remove=0):  79%|███████▉  | 552/700 [02:51<00:45,  3.23it/s]Training (remove=0):  79%|███████▉  | 553/700 [02:51<00:45,  3.23it/s]Training (remove=0):  79%|███████▉  | 554/700 [02:52<00:45,  3.23it/s]Training (remove=0):  79%|███████▉  | 555/700 [02:52<00:44,  3.23it/s]Training (remove=0):  79%|███████▉  | 556/700 [02:52<00:44,  3.23it/s]Training (remove=0):  80%|███████▉  | 557/700 [02:53<00:44,  3.23it/s]Training (remove=0):  80%|███████▉  | 558/700 [02:53<00:44,  3.22it/s]Training (remove=0):  80%|███████▉  | 559/700 [02:53<00:43,  3.23it/s]Training (remove=0):  80%|████████  | 560/700 [02:53<00:43,  3.23it/s]Training (remove=0):  80%|████████  | 561/700 [02:54<00:43,  3.23it/s]Training (remove=0):  80%|████████  | 562/700 [02:54<00:42,  3.23it/s]Training (remove=0):  80%|████████  | 563/700 [02:54<00:42,  3.23it/s]Training (remove=0):  81%|████████  | 564/700 [02:55<00:42,  3.23it/s]Training (remove=0):  81%|████████  | 565/700 [02:55<00:41,  3.23it/s]Training (remove=0):  81%|████████  | 566/700 [02:55<00:41,  3.23it/s]Training (remove=0):  81%|████████  | 567/700 [02:56<00:41,  3.23it/s]Training (remove=0):  81%|████████  | 568/700 [02:56<00:40,  3.23it/s]Training (remove=0):  81%|████████▏ | 569/700 [02:56<00:40,  3.23it/s]Training (remove=0):  81%|████████▏ | 570/700 [02:57<00:40,  3.23it/s]Training (remove=0):  82%|████████▏ | 571/700 [02:57<00:39,  3.23it/s]Training (remove=0):  82%|████████▏ | 572/700 [02:57<00:39,  3.23it/s]Training (remove=0):  82%|████████▏ | 573/700 [02:58<00:39,  3.23it/s]Training (remove=0):  82%|████████▏ | 574/700 [02:58<00:38,  3.23it/s]Training (remove=0):  82%|████████▏ | 575/700 [02:58<00:38,  3.23it/s]Training (remove=0):  82%|████████▏ | 576/700 [02:58<00:38,  3.23it/s]Training (remove=0):  82%|████████▏ | 577/700 [02:59<00:38,  3.23it/s]Training (remove=0):  83%|████████▎ | 578/700 [02:59<00:37,  3.23it/s]Training (remove=0):  83%|████████▎ | 579/700 [02:59<00:37,  3.23it/s]Training (remove=0):  83%|████████▎ | 580/700 [03:00<00:37,  3.23it/s]Training (remove=0):  83%|████████▎ | 581/700 [03:00<00:36,  3.23it/s]Training (remove=0):  83%|████████▎ | 582/700 [03:00<00:36,  3.23it/s]Training (remove=0):  83%|████████▎ | 583/700 [03:01<00:36,  3.23it/s]Training (remove=0):  83%|████████▎ | 584/700 [03:01<00:35,  3.22it/s]Training (remove=0):  84%|████████▎ | 585/700 [03:01<00:35,  3.23it/s]Training (remove=0):  84%|████████▎ | 586/700 [03:02<00:35,  3.23it/s]Training (remove=0):  84%|████████▍ | 587/700 [03:02<00:34,  3.23it/s]Training (remove=0):  84%|████████▍ | 588/700 [03:02<00:34,  3.23it/s]Training (remove=0):  84%|████████▍ | 589/700 [03:02<00:34,  3.23it/s]Training (remove=0):  84%|████████▍ | 590/700 [03:03<00:34,  3.23it/s]Training (remove=0):  84%|████████▍ | 591/700 [03:03<00:33,  3.23it/s]Training (remove=0):  85%|████████▍ | 592/700 [03:03<00:33,  3.23it/s]Training (remove=0):  85%|████████▍ | 593/700 [03:04<00:33,  3.23it/s]Training (remove=0):  85%|████████▍ | 594/700 [03:04<00:32,  3.23it/s]Training (remove=0):  85%|████████▌ | 595/700 [03:04<00:32,  3.22it/s]Training (remove=0):  85%|████████▌ | 596/700 [03:05<00:32,  3.23it/s]Training (remove=0):  85%|████████▌ | 597/700 [03:05<00:31,  3.23it/s]Training (remove=0):  85%|████████▌ | 598/700 [03:05<00:31,  3.23it/s]Training (remove=0):  86%|████████▌ | 599/700 [03:06<00:31,  3.23it/s]Training (remove=0):  86%|████████▌ | 600/700 [03:06<00:30,  3.23it/s]Training (remove=0):  86%|████████▌ | 601/700 [03:06<00:30,  3.23it/s]Training (remove=0):  86%|████████▌ | 602/700 [03:07<00:30,  3.23it/s]Training (remove=0):  86%|████████▌ | 603/700 [03:07<00:30,  3.23it/s]Training (remove=0):  86%|████████▋ | 604/700 [03:07<00:29,  3.23it/s]Training (remove=0):  86%|████████▋ | 605/700 [03:07<00:29,  3.23it/s]Training (remove=0):  87%|████████▋ | 606/700 [03:08<00:29,  3.23it/s]Training (remove=0):  87%|████████▋ | 607/700 [03:08<00:28,  3.22it/s]Training (remove=0):  87%|████████▋ | 608/700 [03:08<00:28,  3.22it/s]Training (remove=0):  87%|████████▋ | 609/700 [03:09<00:28,  3.22it/s]Training (remove=0):  87%|████████▋ | 610/700 [03:09<00:27,  3.23it/s]Training (remove=0):  87%|████████▋ | 611/700 [03:09<00:27,  3.23it/s]Training (remove=0):  87%|████████▋ | 612/700 [03:10<00:27,  3.23it/s]Training (remove=0):  88%|████████▊ | 613/700 [03:10<00:26,  3.23it/s]Training (remove=0):  88%|████████▊ | 614/700 [03:10<00:26,  3.23it/s]Training (remove=0):  88%|████████▊ | 615/700 [03:11<00:26,  3.23it/s]Training (remove=0):  88%|████████▊ | 616/700 [03:11<00:26,  3.23it/s]Training (remove=0):  88%|████████▊ | 617/700 [03:11<00:25,  3.23it/s]Training (remove=0):  88%|████████▊ | 618/700 [03:11<00:25,  3.23it/s]Training (remove=0):  88%|████████▊ | 619/700 [03:12<00:25,  3.23it/s]Training (remove=0):  89%|████████▊ | 620/700 [03:12<00:24,  3.23it/s]Training (remove=0):  89%|████████▊ | 621/700 [03:12<00:24,  3.23it/s]Training (remove=0):  89%|████████▉ | 622/700 [03:13<00:24,  3.23it/s]Training (remove=0):  89%|████████▉ | 623/700 [03:13<00:23,  3.23it/s]Training (remove=0):  89%|████████▉ | 624/700 [03:13<00:23,  3.23it/s]Training (remove=0):  89%|████████▉ | 625/700 [03:14<00:23,  3.23it/s]Training (remove=0):  89%|████████▉ | 626/700 [03:14<00:22,  3.23it/s]Training (remove=0):  90%|████████▉ | 627/700 [03:14<00:22,  3.23it/s]Training (remove=0):  90%|████████▉ | 628/700 [03:15<00:22,  3.22it/s]Training (remove=0):  90%|████████▉ | 629/700 [03:15<00:22,  3.22it/s]Training (remove=0):  90%|█████████ | 630/700 [03:15<00:21,  3.22it/s]Training (remove=0):  90%|█████████ | 631/700 [03:15<00:21,  3.23it/s]Training (remove=0):  90%|█████████ | 632/700 [03:16<00:21,  3.23it/s]Training (remove=0):  90%|█████████ | 633/700 [03:16<00:20,  3.23it/s]Training (remove=0):  91%|█████████ | 634/700 [03:16<00:20,  3.23it/s]Training (remove=0):  91%|█████████ | 635/700 [03:17<00:20,  3.23it/s]Training (remove=0):  91%|█████████ | 636/700 [03:17<00:19,  3.23it/s]Training (remove=0):  91%|█████████ | 637/700 [03:17<00:19,  3.23it/s]Training (remove=0):  91%|█████████ | 638/700 [03:18<00:19,  3.23it/s]Training (remove=0):  91%|█████████▏| 639/700 [03:18<00:18,  3.23it/s]Training (remove=0):  91%|█████████▏| 640/700 [03:18<00:18,  3.24it/s]Training (remove=0):  92%|█████████▏| 641/700 [03:19<00:18,  3.23it/s]Training (remove=0):  92%|█████████▏| 642/700 [03:19<00:17,  3.23it/s]Training (remove=0):  92%|█████████▏| 643/700 [03:19<00:17,  3.22it/s]Training (remove=0):  92%|█████████▏| 644/700 [03:20<00:17,  3.22it/s]Training (remove=0):  92%|█████████▏| 645/700 [03:20<00:17,  3.22it/s]Training (remove=0):  92%|█████████▏| 646/700 [03:20<00:16,  3.23it/s]Training (remove=0):  92%|█████████▏| 647/700 [03:20<00:16,  3.23it/s]Training (remove=0):  93%|█████████▎| 648/700 [03:21<00:16,  3.23it/s]Training (remove=0):  93%|█████████▎| 649/700 [03:21<00:15,  3.23it/s]Training (remove=0):  93%|█████████▎| 650/700 [03:21<00:15,  3.23it/s]Training (remove=0):  93%|█████████▎| 651/700 [03:22<00:15,  3.23it/s]Training (remove=0):  93%|█████████▎| 652/700 [03:22<00:14,  3.23it/s]Training (remove=0):  93%|█████████▎| 653/700 [03:22<00:14,  3.23it/s]Training (remove=0):  93%|█████████▎| 654/700 [03:23<00:14,  3.23it/s]Training (remove=0):  94%|█████████▎| 655/700 [03:23<00:13,  3.23it/s]Training (remove=0):  94%|█████████▎| 656/700 [03:23<00:13,  3.23it/s]Training (remove=0):  94%|█████████▍| 657/700 [03:24<00:13,  3.23it/s]Training (remove=0):  94%|█████████▍| 658/700 [03:24<00:12,  3.23it/s]Training (remove=0):  94%|█████████▍| 659/700 [03:24<00:12,  3.23it/s]Training (remove=0):  94%|█████████▍| 660/700 [03:24<00:12,  3.23it/s]Training (remove=0):  94%|█████████▍| 661/700 [03:25<00:12,  3.23it/s]Training (remove=0):  95%|█████████▍| 662/700 [03:25<00:11,  3.23it/s]Training (remove=0):  95%|█████████▍| 663/700 [03:25<00:11,  3.23it/s]Training (remove=0):  95%|█████████▍| 664/700 [03:26<00:11,  3.23it/s]Training (remove=0):  95%|█████████▌| 665/700 [03:26<00:10,  3.23it/s]Training (remove=0):  95%|█████████▌| 666/700 [03:26<00:10,  3.23it/s]Training (remove=0):  95%|█████████▌| 667/700 [03:27<00:10,  3.23it/s]Training (remove=0):  95%|█████████▌| 668/700 [03:27<00:09,  3.23it/s]Training (remove=0):  96%|█████████▌| 669/700 [03:27<00:09,  3.23it/s]Training (remove=0):  96%|█████████▌| 670/700 [03:28<00:09,  3.23it/s]Training (remove=0):  96%|█████████▌| 671/700 [03:28<00:08,  3.23it/s]Training (remove=0):  96%|█████████▌| 672/700 [03:28<00:08,  3.23it/s]Training (remove=0):  96%|█████████▌| 673/700 [03:28<00:08,  3.23it/s]Training (remove=0):  96%|█████████▋| 674/700 [03:29<00:08,  3.23it/s]Training (remove=0):  96%|█████████▋| 675/700 [03:29<00:07,  3.23it/s]Training (remove=0):  97%|█████████▋| 676/700 [03:29<00:07,  3.23it/s]Training (remove=0):  97%|█████████▋| 677/700 [03:30<00:07,  3.23it/s]Training (remove=0):  97%|█████████▋| 678/700 [03:30<00:06,  3.22it/s]Training (remove=0):  97%|█████████▋| 679/700 [03:30<00:06,  3.23it/s]Training (remove=0):  97%|█████████▋| 680/700 [03:31<00:06,  3.23it/s]Training (remove=0):  97%|█████████▋| 681/700 [03:31<00:05,  3.23it/s]Training (remove=0):  97%|█████████▋| 682/700 [03:31<00:05,  3.23it/s]Training (remove=0):  98%|█████████▊| 683/700 [03:32<00:05,  3.23it/s]Training (remove=0):  98%|█████████▊| 684/700 [03:32<00:04,  3.23it/s]Training (remove=0):  98%|█████████▊| 685/700 [03:32<00:04,  3.22it/s]Training (remove=0):  98%|█████████▊| 686/700 [03:33<00:04,  3.23it/s]Training (remove=0):  98%|█████████▊| 687/700 [03:33<00:04,  3.23it/s]Training (remove=0):  98%|█████████▊| 688/700 [03:33<00:03,  3.23it/s]Training (remove=0):  98%|█████████▊| 689/700 [03:33<00:03,  3.23it/s]Training (remove=0):  99%|█████████▊| 690/700 [03:34<00:03,  3.22it/s]Training (remove=0):  99%|█████████▊| 691/700 [03:34<00:02,  3.23it/s]Training (remove=0):  99%|█████████▉| 692/700 [03:34<00:02,  3.23it/s]Training (remove=0):  99%|█████████▉| 693/700 [03:35<00:02,  3.23it/s]Training (remove=0):  99%|█████████▉| 694/700 [03:35<00:01,  3.22it/s]Training (remove=0):  99%|█████████▉| 695/700 [03:35<00:01,  3.23it/s]Training (remove=0):  99%|█████████▉| 696/700 [03:36<00:01,  3.23it/s]Training (remove=0): 100%|█████████▉| 697/700 [03:36<00:00,  3.23it/s]Training (remove=0): 100%|█████████▉| 698/700 [03:36<00:00,  3.23it/s]Training (remove=0): 100%|█████████▉| 699/700 [03:37<00:00,  3.23it/s]Training (remove=0): 100%|██████████| 700/700 [03:37<00:00,  3.23it/s]Training (remove=0): 100%|██████████| 700/700 [03:37<00:00,  3.22it/s]
Step 100 - Loss: 0.2144
Step 200 - Loss: 0.2060
Step 300 - Loss: 0.0378
Step 400 - Loss: 0.1642
Step 500 - Loss: 0.0579
Step 600 - Loss: 0.0176
Step 700 - Loss: 0.0059
Epoch 1 - Average Loss: 0.3746
Evaluating (remove=0):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   0%|          | 1/200 [00:01<04:41,  1.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   1%|          | 2/200 [00:02<04:02,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   2%|▏         | 3/200 [00:03<03:20,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   2%|▏         | 4/200 [00:04<03:00,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   2%|▎         | 5/200 [00:04<02:48,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   3%|▎         | 6/200 [00:05<02:48,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   4%|▎         | 7/200 [00:06<02:41,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   4%|▍         | 8/200 [00:07<02:36,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   4%|▍         | 9/200 [00:08<02:39,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   5%|▌         | 10/200 [00:10<03:43,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   6%|▌         | 11/200 [00:10<03:13,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   6%|▌         | 12/200 [00:11<03:03,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   6%|▋         | 13/200 [00:12<02:44,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   7%|▋         | 14/200 [00:13<02:36,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   8%|▊         | 15/200 [00:13<02:37,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   8%|▊         | 16/200 [00:14<02:37,  1.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   8%|▊         | 17/200 [00:15<02:37,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):   9%|▉         | 18/200 [00:16<02:31,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  10%|▉         | 19/200 [00:17<02:26,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  10%|█         | 20/200 [00:17<02:23,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  10%|█         | 21/200 [00:18<02:15,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  11%|█         | 22/200 [00:19<02:32,  1.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  12%|█▏        | 23/200 [00:20<02:21,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  12%|█▏        | 24/200 [00:21<02:23,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  12%|█▎        | 25/200 [00:21<02:19,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  13%|█▎        | 26/200 [00:22<02:11,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  14%|█▎        | 27/200 [00:23<02:05,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  14%|█▍        | 28/200 [00:24<02:29,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  14%|█▍        | 29/200 [00:25<02:23,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  15%|█▌        | 30/200 [00:25<02:13,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  16%|█▌        | 31/200 [00:26<02:17,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  16%|█▌        | 32/200 [00:27<02:13,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  16%|█▋        | 33/200 [00:28<02:16,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  17%|█▋        | 34/200 [00:29<02:13,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  18%|█▊        | 35/200 [00:29<02:05,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  18%|█▊        | 36/200 [00:30<02:04,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  18%|█▊        | 37/200 [00:31<01:58,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  19%|█▉        | 38/200 [00:32<02:26,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  20%|█▉        | 39/200 [00:33<02:18,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  20%|██        | 40/200 [00:33<02:08,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  20%|██        | 41/200 [00:34<02:00,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  21%|██        | 42/200 [00:35<02:00,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  22%|██▏       | 43/200 [00:36<01:54,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  22%|██▏       | 44/200 [00:36<01:55,  1.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  22%|██▎       | 45/200 [00:37<01:56,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  23%|██▎       | 46/200 [00:38<01:56,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  24%|██▎       | 47/200 [00:39<01:56,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  24%|██▍       | 48/200 [00:39<01:55,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  24%|██▍       | 49/200 [00:40<02:09,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  25%|██▌       | 50/200 [00:41<02:04,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  26%|██▌       | 51/200 [00:42<02:01,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  26%|██▌       | 52/200 [00:43<01:58,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  26%|██▋       | 53/200 [00:44<01:56,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  27%|██▋       | 54/200 [00:44<01:49,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  28%|██▊       | 55/200 [00:45<01:44,  1.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  28%|██▊       | 56/200 [00:46<01:45,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  28%|██▊       | 57/200 [00:46<01:41,  1.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  29%|██▉       | 58/200 [00:47<01:38,  1.44it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  30%|██▉       | 59/200 [00:48<01:49,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  30%|███       | 60/200 [00:49<01:53,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  30%|███       | 61/200 [00:50<01:55,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  31%|███       | 62/200 [00:50<01:51,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  32%|███▏      | 63/200 [00:51<01:53,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  32%|███▏      | 64/200 [00:52<01:50,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  32%|███▎      | 65/200 [00:53<01:47,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  33%|███▎      | 66/200 [00:54<01:45,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  34%|███▎      | 67/200 [00:54<01:43,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  34%|███▍      | 68/200 [00:55<01:42,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  34%|███▍      | 69/200 [00:56<01:41,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  35%|███▌      | 70/200 [00:57<01:52,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  36%|███▌      | 71/200 [00:58<01:43,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  36%|███▌      | 72/200 [00:58<01:41,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  36%|███▋      | 73/200 [00:59<01:39,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  37%|███▋      | 74/200 [01:00<01:42,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  38%|███▊      | 75/200 [01:01<01:44,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  38%|███▊      | 76/200 [01:02<02:00,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  38%|███▊      | 77/200 [01:03<01:48,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  39%|███▉      | 78/200 [01:04<01:47,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  40%|███▉      | 79/200 [01:05<01:46,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  40%|████      | 80/200 [01:06<02:07,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  40%|████      | 81/200 [01:07<01:59,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  41%|████      | 82/200 [01:08<01:50,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  42%|████▏     | 83/200 [01:09<01:43,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  42%|████▏     | 84/200 [01:09<01:38,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  42%|████▎     | 85/200 [01:10<01:45,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  43%|████▎     | 86/200 [01:11<01:35,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  44%|████▎     | 87/200 [01:12<01:28,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  44%|████▍     | 88/200 [01:13<01:38,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  44%|████▍     | 89/200 [01:14<01:37,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  45%|████▌     | 90/200 [01:14<01:32,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  46%|████▌     | 91/200 [01:15<01:29,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  46%|████▌     | 92/200 [01:16<01:23,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  46%|████▋     | 93/200 [01:17<01:19,  1.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  47%|████▋     | 94/200 [01:17<01:19,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  48%|████▊     | 95/200 [01:18<01:15,  1.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  48%|████▊     | 96/200 [01:19<01:16,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  48%|████▊     | 97/200 [01:19<01:16,  1.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  49%|████▉     | 98/200 [01:20<01:16,  1.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  50%|████▉     | 99/200 [01:21<01:16,  1.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  50%|█████     | 100/200 [01:22<01:15,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  50%|█████     | 101/200 [01:22<01:11,  1.38it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  51%|█████     | 102/200 [01:23<01:12,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  52%|█████▏    | 103/200 [01:24<01:12,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  52%|█████▏    | 104/200 [01:25<01:27,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  52%|█████▎    | 105/200 [01:26<01:19,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  53%|█████▎    | 106/200 [01:27<01:25,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  54%|█████▎    | 107/200 [01:28<01:20,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  54%|█████▍    | 108/200 [01:29<01:16,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  55%|█████▍    | 109/200 [01:30<01:25,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  55%|█████▌    | 110/200 [01:31<01:23,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  56%|█████▌    | 111/200 [01:31<01:15,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  56%|█████▌    | 112/200 [01:32<01:12,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  56%|█████▋    | 113/200 [01:33<01:06,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  57%|█████▋    | 114/200 [01:34<01:08,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  57%|█████▊    | 115/200 [01:34<01:06,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  58%|█████▊    | 116/200 [01:35<01:02,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  58%|█████▊    | 117/200 [01:36<00:59,  1.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  59%|█████▉    | 118/200 [01:36<01:02,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  60%|█████▉    | 119/200 [01:37<01:02,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  60%|██████    | 120/200 [01:38<01:03,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  60%|██████    | 121/200 [01:39<00:59,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  61%|██████    | 122/200 [01:39<00:56,  1.38it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  62%|██████▏   | 123/200 [01:40<00:59,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  62%|██████▏   | 124/200 [01:41<00:55,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  62%|██████▎   | 125/200 [01:42<00:53,  1.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  63%|██████▎   | 126/200 [01:42<00:51,  1.44it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  64%|██████▎   | 127/200 [01:43<00:49,  1.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  64%|██████▍   | 128/200 [01:44<00:48,  1.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  64%|██████▍   | 129/200 [01:44<00:47,  1.49it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  65%|██████▌   | 130/200 [01:45<00:48,  1.43it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  66%|██████▌   | 131/200 [01:46<00:47,  1.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  66%|██████▌   | 132/200 [01:46<00:45,  1.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  66%|██████▋   | 133/200 [01:47<00:49,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  67%|██████▋   | 134/200 [01:48<00:46,  1.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  68%|██████▊   | 135/200 [01:49<00:49,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  68%|██████▊   | 136/200 [01:49<00:46,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  68%|██████▊   | 137/200 [01:50<00:46,  1.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  69%|██████▉   | 138/200 [01:51<00:48,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  70%|██████▉   | 139/200 [01:52<00:49,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  70%|███████   | 140/200 [01:53<00:49,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  70%|███████   | 141/200 [01:53<00:45,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  71%|███████   | 142/200 [01:54<00:44,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  72%|███████▏  | 143/200 [01:55<00:43,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  72%|███████▏  | 144/200 [01:56<00:43,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  72%|███████▎  | 145/200 [01:56<00:40,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  73%|███████▎  | 146/200 [01:57<00:40,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  74%|███████▎  | 147/200 [01:58<00:39,  1.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  74%|███████▍  | 148/200 [01:59<00:42,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  74%|███████▍  | 149/200 [02:00<00:42,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  75%|███████▌  | 150/200 [02:01<00:40,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  76%|███████▌  | 151/200 [02:01<00:37,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  76%|███████▌  | 152/200 [02:02<00:42,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  76%|███████▋  | 153/200 [02:03<00:38,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  77%|███████▋  | 154/200 [02:04<00:35,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  78%|███████▊  | 155/200 [02:04<00:34,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  78%|███████▊  | 156/200 [02:05<00:35,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  78%|███████▊  | 157/200 [02:06<00:34,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  79%|███████▉  | 158/200 [02:08<00:42,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  80%|███████▉  | 159/200 [02:08<00:37,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  80%|████████  | 160/200 [02:09<00:37,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  80%|████████  | 161/200 [02:10<00:34,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  81%|████████  | 162/200 [02:11<00:31,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  82%|████████▏ | 163/200 [02:11<00:29,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  82%|████████▏ | 164/200 [02:12<00:27,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  82%|████████▎ | 165/200 [02:14<00:38,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  83%|████████▎ | 166/200 [02:15<00:35,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  84%|████████▎ | 167/200 [02:16<00:33,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  84%|████████▍ | 168/200 [02:17<00:29,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  84%|████████▍ | 169/200 [02:17<00:26,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  85%|████████▌ | 170/200 [02:18<00:23,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  86%|████████▌ | 171/200 [02:20<00:31,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  86%|████████▌ | 172/200 [02:20<00:26,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  86%|████████▋ | 173/200 [02:21<00:23,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  87%|████████▋ | 174/200 [02:22<00:21,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  88%|████████▊ | 175/200 [02:23<00:21,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  88%|████████▊ | 176/200 [02:23<00:18,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  88%|████████▊ | 177/200 [02:24<00:18,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  89%|████████▉ | 178/200 [02:25<00:17,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  90%|████████▉ | 179/200 [02:26<00:16,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  90%|█████████ | 180/200 [02:27<00:17,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  90%|█████████ | 181/200 [02:27<00:15,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  91%|█████████ | 182/200 [02:28<00:15,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  92%|█████████▏| 183/200 [02:29<00:13,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  92%|█████████▏| 184/200 [02:30<00:12,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  92%|█████████▎| 185/200 [02:31<00:11,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  93%|█████████▎| 186/200 [02:31<00:10,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  94%|█████████▎| 187/200 [02:32<00:09,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  94%|█████████▍| 188/200 [02:33<00:08,  1.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  94%|█████████▍| 189/200 [02:33<00:08,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  95%|█████████▌| 190/200 [02:34<00:07,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  96%|█████████▌| 191/200 [02:35<00:07,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  96%|█████████▌| 192/200 [02:36<00:06,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  96%|█████████▋| 193/200 [02:37<00:05,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  97%|█████████▋| 194/200 [02:38<00:04,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  98%|█████████▊| 195/200 [02:38<00:04,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  98%|█████████▊| 196/200 [02:39<00:03,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  98%|█████████▊| 197/200 [02:40<00:02,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0):  99%|█████████▉| 198/200 [02:41<00:01,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0): 100%|█████████▉| 199/200 [02:41<00:00,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=0): 100%|██████████| 200/200 [02:42<00:00,  1.27it/s]Evaluating (remove=0): 100%|██████████| 200/200 [02:42<00:00,  1.23it/s]
Epoch 1 - Accuracy: 0.7950
New best accuracy: 0.7950
Epoch 2/10 - Removing 8 tokens
Training (remove=8):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=8):   0%|          | 1/700 [00:00<04:26,  2.62it/s]Training (remove=8):   0%|          | 2/700 [00:00<03:56,  2.95it/s]Training (remove=8):   0%|          | 3/700 [00:00<03:46,  3.07it/s]Training (remove=8):   1%|          | 4/700 [00:01<03:42,  3.13it/s]Training (remove=8):   1%|          | 5/700 [00:01<03:40,  3.15it/s]Training (remove=8):   1%|          | 6/700 [00:01<03:38,  3.18it/s]Training (remove=8):   1%|          | 7/700 [00:02<03:37,  3.19it/s]Training (remove=8):   1%|          | 8/700 [00:02<03:36,  3.20it/s]Training (remove=8):   1%|▏         | 9/700 [00:02<03:35,  3.21it/s]Training (remove=8):   1%|▏         | 10/700 [00:03<03:34,  3.22it/s]Training (remove=8):   2%|▏         | 11/700 [00:03<03:34,  3.22it/s]Training (remove=8):   2%|▏         | 12/700 [00:03<03:33,  3.22it/s]Training (remove=8):   2%|▏         | 13/700 [00:04<03:33,  3.21it/s]Training (remove=8):   2%|▏         | 14/700 [00:04<03:33,  3.22it/s]Training (remove=8):   2%|▏         | 15/700 [00:04<03:33,  3.21it/s]Training (remove=8):   2%|▏         | 16/700 [00:05<03:32,  3.22it/s]Training (remove=8):   2%|▏         | 17/700 [00:05<03:32,  3.22it/s]Training (remove=8):   3%|▎         | 18/700 [00:05<03:31,  3.22it/s]Training (remove=8):   3%|▎         | 19/700 [00:05<03:31,  3.22it/s]Training (remove=8):   3%|▎         | 20/700 [00:06<03:31,  3.21it/s]Training (remove=8):   3%|▎         | 21/700 [00:06<03:31,  3.22it/s]Training (remove=8):   3%|▎         | 22/700 [00:06<03:30,  3.22it/s]Training (remove=8):   3%|▎         | 23/700 [00:07<03:30,  3.22it/s]Training (remove=8):   3%|▎         | 24/700 [00:07<03:29,  3.22it/s]Training (remove=8):   4%|▎         | 25/700 [00:07<03:29,  3.22it/s]Training (remove=8):   4%|▎         | 26/700 [00:08<03:29,  3.21it/s]Training (remove=8):   4%|▍         | 27/700 [00:08<03:29,  3.21it/s]Training (remove=8):   4%|▍         | 28/700 [00:08<03:28,  3.22it/s]Training (remove=8):   4%|▍         | 29/700 [00:09<03:28,  3.22it/s]Training (remove=8):   4%|▍         | 30/700 [00:09<03:27,  3.22it/s]Training (remove=8):   4%|▍         | 31/700 [00:09<03:27,  3.22it/s]Training (remove=8):   5%|▍         | 32/700 [00:10<03:27,  3.22it/s]Training (remove=8):   5%|▍         | 33/700 [00:10<03:27,  3.22it/s]Training (remove=8):   5%|▍         | 34/700 [00:10<03:26,  3.22it/s]Training (remove=8):   5%|▌         | 35/700 [00:10<03:26,  3.22it/s]Training (remove=8):   5%|▌         | 36/700 [00:11<03:26,  3.22it/s]Training (remove=8):   5%|▌         | 37/700 [00:11<03:26,  3.22it/s]Training (remove=8):   5%|▌         | 38/700 [00:11<03:25,  3.22it/s]Training (remove=8):   6%|▌         | 39/700 [00:12<03:25,  3.21it/s]Training (remove=8):   6%|▌         | 40/700 [00:12<03:25,  3.22it/s]Training (remove=8):   6%|▌         | 41/700 [00:12<03:25,  3.21it/s]Training (remove=8):   6%|▌         | 42/700 [00:13<03:24,  3.21it/s]Training (remove=8):   6%|▌         | 43/700 [00:13<03:24,  3.22it/s]Training (remove=8):   6%|▋         | 44/700 [00:13<03:24,  3.21it/s]Training (remove=8):   6%|▋         | 45/700 [00:14<03:23,  3.21it/s]Training (remove=8):   7%|▋         | 46/700 [00:14<03:23,  3.21it/s]Training (remove=8):   7%|▋         | 47/700 [00:14<03:23,  3.21it/s]Training (remove=8):   7%|▋         | 48/700 [00:14<03:22,  3.22it/s]Training (remove=8):   7%|▋         | 49/700 [00:15<03:22,  3.22it/s]Training (remove=8):   7%|▋         | 50/700 [00:15<03:21,  3.22it/s]Training (remove=8):   7%|▋         | 51/700 [00:15<03:21,  3.22it/s]Training (remove=8):   7%|▋         | 52/700 [00:16<03:21,  3.22it/s]Training (remove=8):   8%|▊         | 53/700 [00:16<03:20,  3.22it/s]Training (remove=8):   8%|▊         | 54/700 [00:16<03:20,  3.22it/s]Training (remove=8):   8%|▊         | 55/700 [00:17<03:20,  3.22it/s]Training (remove=8):   8%|▊         | 56/700 [00:17<03:19,  3.22it/s]Training (remove=8):   8%|▊         | 57/700 [00:17<03:19,  3.22it/s]Training (remove=8):   8%|▊         | 58/700 [00:18<03:19,  3.22it/s]Training (remove=8):   8%|▊         | 59/700 [00:18<03:19,  3.22it/s]Training (remove=8):   9%|▊         | 60/700 [00:18<03:18,  3.22it/s]Training (remove=8):   9%|▊         | 61/700 [00:19<03:18,  3.22it/s]Training (remove=8):   9%|▉         | 62/700 [00:19<03:18,  3.22it/s]Training (remove=8):   9%|▉         | 63/700 [00:19<03:17,  3.22it/s]Training (remove=8):   9%|▉         | 64/700 [00:19<03:17,  3.22it/s]Training (remove=8):   9%|▉         | 65/700 [00:20<03:17,  3.22it/s]Training (remove=8):   9%|▉         | 66/700 [00:20<03:16,  3.22it/s]Training (remove=8):  10%|▉         | 67/700 [00:20<03:16,  3.22it/s]Training (remove=8):  10%|▉         | 68/700 [00:21<03:16,  3.22it/s]Training (remove=8):  10%|▉         | 69/700 [00:21<03:15,  3.22it/s]Training (remove=8):  10%|█         | 70/700 [00:21<03:15,  3.21it/s]Training (remove=8):  10%|█         | 71/700 [00:22<03:15,  3.22it/s]Training (remove=8):  10%|█         | 72/700 [00:22<03:15,  3.21it/s]Training (remove=8):  10%|█         | 73/700 [00:22<03:14,  3.22it/s]Training (remove=8):  11%|█         | 74/700 [00:23<03:14,  3.22it/s]Training (remove=8):  11%|█         | 75/700 [00:23<03:14,  3.22it/s]Training (remove=8):  11%|█         | 76/700 [00:23<03:13,  3.22it/s]Training (remove=8):  11%|█         | 77/700 [00:23<03:13,  3.22it/s]Training (remove=8):  11%|█         | 78/700 [00:24<03:13,  3.22it/s]Training (remove=8):  11%|█▏        | 79/700 [00:24<03:13,  3.21it/s]Training (remove=8):  11%|█▏        | 80/700 [00:24<03:12,  3.22it/s]Training (remove=8):  12%|█▏        | 81/700 [00:25<03:12,  3.22it/s]Training (remove=8):  12%|█▏        | 82/700 [00:25<03:11,  3.22it/s]Training (remove=8):  12%|█▏        | 83/700 [00:25<03:11,  3.22it/s]Training (remove=8):  12%|█▏        | 84/700 [00:26<03:11,  3.22it/s]Training (remove=8):  12%|█▏        | 85/700 [00:26<03:11,  3.22it/s]Training (remove=8):  12%|█▏        | 86/700 [00:26<03:10,  3.22it/s]Training (remove=8):  12%|█▏        | 87/700 [00:27<03:10,  3.22it/s]Training (remove=8):  13%|█▎        | 88/700 [00:27<03:10,  3.22it/s]Training (remove=8):  13%|█▎        | 89/700 [00:27<03:09,  3.22it/s]Training (remove=8):  13%|█▎        | 90/700 [00:28<03:09,  3.22it/s]Training (remove=8):  13%|█▎        | 91/700 [00:28<03:10,  3.20it/s]Training (remove=8):  13%|█▎        | 92/700 [00:28<03:09,  3.21it/s]Training (remove=8):  13%|█▎        | 93/700 [00:28<03:09,  3.21it/s]Training (remove=8):  13%|█▎        | 94/700 [00:29<03:08,  3.21it/s]Training (remove=8):  14%|█▎        | 95/700 [00:29<03:08,  3.22it/s]Training (remove=8):  14%|█▎        | 96/700 [00:29<03:07,  3.22it/s]Training (remove=8):  14%|█▍        | 97/700 [00:30<03:07,  3.22it/s]Training (remove=8):  14%|█▍        | 98/700 [00:30<03:06,  3.22it/s]Training (remove=8):  14%|█▍        | 99/700 [00:30<03:06,  3.22it/s]Training (remove=8):  14%|█▍        | 100/700 [00:31<03:06,  3.22it/s]Training (remove=8):  14%|█▍        | 101/700 [00:31<03:05,  3.22it/s]Training (remove=8):  15%|█▍        | 102/700 [00:31<03:05,  3.22it/s]Training (remove=8):  15%|█▍        | 103/700 [00:32<03:05,  3.22it/s]Training (remove=8):  15%|█▍        | 104/700 [00:32<03:05,  3.21it/s]Training (remove=8):  15%|█▌        | 105/700 [00:32<03:05,  3.21it/s]Training (remove=8):  15%|█▌        | 106/700 [00:33<03:04,  3.22it/s]Training (remove=8):  15%|█▌        | 107/700 [00:33<03:04,  3.22it/s]Training (remove=8):  15%|█▌        | 108/700 [00:33<03:04,  3.21it/s]Training (remove=8):  16%|█▌        | 109/700 [00:33<03:03,  3.22it/s]Training (remove=8):  16%|█▌        | 110/700 [00:34<03:03,  3.22it/s]Training (remove=8):  16%|█▌        | 111/700 [00:34<03:02,  3.22it/s]Training (remove=8):  16%|█▌        | 112/700 [00:34<03:02,  3.23it/s]Training (remove=8):  16%|█▌        | 113/700 [00:35<03:01,  3.23it/s]Training (remove=8):  16%|█▋        | 114/700 [00:35<03:01,  3.23it/s]Training (remove=8):  16%|█▋        | 115/700 [00:35<03:01,  3.23it/s]Training (remove=8):  17%|█▋        | 116/700 [00:36<03:01,  3.22it/s]Training (remove=8):  17%|█▋        | 117/700 [00:36<03:01,  3.22it/s]Training (remove=8):  17%|█▋        | 118/700 [00:36<03:00,  3.22it/s]Training (remove=8):  17%|█▋        | 119/700 [00:37<03:00,  3.22it/s]Training (remove=8):  17%|█▋        | 120/700 [00:37<02:59,  3.22it/s]Training (remove=8):  17%|█▋        | 121/700 [00:37<02:59,  3.22it/s]Training (remove=8):  17%|█▋        | 122/700 [00:37<02:59,  3.23it/s]Training (remove=8):  18%|█▊        | 123/700 [00:38<02:58,  3.22it/s]Training (remove=8):  18%|█▊        | 124/700 [00:38<02:58,  3.23it/s]Training (remove=8):  18%|█▊        | 125/700 [00:38<02:58,  3.23it/s]Training (remove=8):  18%|█▊        | 126/700 [00:39<02:58,  3.22it/s]Training (remove=8):  18%|█▊        | 127/700 [00:39<02:58,  3.21it/s]Training (remove=8):  18%|█▊        | 128/700 [00:39<02:57,  3.22it/s]Training (remove=8):  18%|█▊        | 129/700 [00:40<02:57,  3.22it/s]Training (remove=8):  19%|█▊        | 130/700 [00:40<02:57,  3.22it/s]Training (remove=8):  19%|█▊        | 131/700 [00:40<02:56,  3.22it/s]Training (remove=8):  19%|█▉        | 132/700 [00:41<02:56,  3.22it/s]Training (remove=8):  19%|█▉        | 133/700 [00:41<02:55,  3.22it/s]Training (remove=8):  19%|█▉        | 134/700 [00:41<02:55,  3.22it/s]Training (remove=8):  19%|█▉        | 135/700 [00:42<02:55,  3.22it/s]Training (remove=8):  19%|█▉        | 136/700 [00:42<02:55,  3.21it/s]Training (remove=8):  20%|█▉        | 137/700 [00:42<02:55,  3.21it/s]Training (remove=8):  20%|█▉        | 138/700 [00:42<02:55,  3.21it/s]Training (remove=8):  20%|█▉        | 139/700 [00:43<02:55,  3.20it/s]Training (remove=8):  20%|██        | 140/700 [00:43<02:54,  3.21it/s]Training (remove=8):  20%|██        | 141/700 [00:43<02:53,  3.22it/s]Training (remove=8):  20%|██        | 142/700 [00:44<02:53,  3.22it/s]Training (remove=8):  20%|██        | 143/700 [00:44<02:52,  3.22it/s]Training (remove=8):  21%|██        | 144/700 [00:44<02:52,  3.22it/s]Training (remove=8):  21%|██        | 145/700 [00:45<02:52,  3.22it/s]Training (remove=8):  21%|██        | 146/700 [00:45<02:52,  3.22it/s]Training (remove=8):  21%|██        | 147/700 [00:45<02:51,  3.22it/s]Training (remove=8):  21%|██        | 148/700 [00:46<02:51,  3.21it/s]Training (remove=8):  21%|██▏       | 149/700 [00:46<02:51,  3.22it/s]Training (remove=8):  21%|██▏       | 150/700 [00:46<02:50,  3.22it/s]Training (remove=8):  22%|██▏       | 151/700 [00:46<02:50,  3.22it/s]Training (remove=8):  22%|██▏       | 152/700 [00:47<02:50,  3.22it/s]Training (remove=8):  22%|██▏       | 153/700 [00:47<02:49,  3.22it/s]Training (remove=8):  22%|██▏       | 154/700 [00:47<02:49,  3.22it/s]Training (remove=8):  22%|██▏       | 155/700 [00:48<02:49,  3.22it/s]Training (remove=8):  22%|██▏       | 156/700 [00:48<02:49,  3.22it/s]Training (remove=8):  22%|██▏       | 157/700 [00:48<02:48,  3.22it/s]Training (remove=8):  23%|██▎       | 158/700 [00:49<02:48,  3.22it/s]Training (remove=8):  23%|██▎       | 159/700 [00:49<02:47,  3.22it/s]Training (remove=8):  23%|██▎       | 160/700 [00:49<02:47,  3.23it/s]Training (remove=8):  23%|██▎       | 161/700 [00:50<02:47,  3.22it/s]Training (remove=8):  23%|██▎       | 162/700 [00:50<02:47,  3.22it/s]Training (remove=8):  23%|██▎       | 163/700 [00:50<02:46,  3.22it/s]Training (remove=8):  23%|██▎       | 164/700 [00:51<02:46,  3.22it/s]Training (remove=8):  24%|██▎       | 165/700 [00:51<02:46,  3.21it/s]Training (remove=8):  24%|██▎       | 166/700 [00:51<02:45,  3.22it/s]Training (remove=8):  24%|██▍       | 167/700 [00:51<02:45,  3.22it/s]Training (remove=8):  24%|██▍       | 168/700 [00:52<02:45,  3.22it/s]Training (remove=8):  24%|██▍       | 169/700 [00:52<02:44,  3.22it/s]Training (remove=8):  24%|██▍       | 170/700 [00:52<02:44,  3.22it/s]Training (remove=8):  24%|██▍       | 171/700 [00:53<02:44,  3.22it/s]Training (remove=8):  25%|██▍       | 172/700 [00:53<02:44,  3.22it/s]Training (remove=8):  25%|██▍       | 173/700 [00:53<02:43,  3.22it/s]Training (remove=8):  25%|██▍       | 174/700 [00:54<02:43,  3.22it/s]Training (remove=8):  25%|██▌       | 175/700 [00:54<02:43,  3.22it/s]Training (remove=8):  25%|██▌       | 176/700 [00:54<02:43,  3.21it/s]Training (remove=8):  25%|██▌       | 177/700 [00:55<02:42,  3.21it/s]Training (remove=8):  25%|██▌       | 178/700 [00:55<02:42,  3.22it/s]Training (remove=8):  26%|██▌       | 179/700 [00:55<02:42,  3.21it/s]Training (remove=8):  26%|██▌       | 180/700 [00:55<02:41,  3.21it/s]Training (remove=8):  26%|██▌       | 181/700 [00:56<02:41,  3.21it/s]Training (remove=8):  26%|██▌       | 182/700 [00:56<02:41,  3.21it/s]Training (remove=8):  26%|██▌       | 183/700 [00:56<02:40,  3.22it/s]Training (remove=8):  26%|██▋       | 184/700 [00:57<02:40,  3.22it/s]Training (remove=8):  26%|██▋       | 185/700 [00:57<02:39,  3.22it/s]Training (remove=8):  27%|██▋       | 186/700 [00:57<02:39,  3.22it/s]Training (remove=8):  27%|██▋       | 187/700 [00:58<02:39,  3.22it/s]Training (remove=8):  27%|██▋       | 188/700 [00:58<02:39,  3.22it/s]Training (remove=8):  27%|██▋       | 189/700 [00:58<02:38,  3.22it/s]Training (remove=8):  27%|██▋       | 190/700 [00:59<02:38,  3.22it/s]Training (remove=8):  27%|██▋       | 191/700 [00:59<02:38,  3.22it/s]Training (remove=8):  27%|██▋       | 192/700 [00:59<02:37,  3.22it/s]Training (remove=8):  28%|██▊       | 193/700 [01:00<02:37,  3.22it/s]Training (remove=8):  28%|██▊       | 194/700 [01:00<02:37,  3.22it/s]Training (remove=8):  28%|██▊       | 195/700 [01:00<02:36,  3.22it/s]Training (remove=8):  28%|██▊       | 196/700 [01:00<02:36,  3.22it/s]Training (remove=8):  28%|██▊       | 197/700 [01:01<02:36,  3.22it/s]Training (remove=8):  28%|██▊       | 198/700 [01:01<02:35,  3.22it/s]Training (remove=8):  28%|██▊       | 199/700 [01:01<02:35,  3.22it/s]Training (remove=8):  29%|██▊       | 200/700 [01:02<02:35,  3.22it/s]Training (remove=8):  29%|██▊       | 201/700 [01:02<02:34,  3.22it/s]Training (remove=8):  29%|██▉       | 202/700 [01:02<02:34,  3.22it/s]Training (remove=8):  29%|██▉       | 203/700 [01:03<02:34,  3.22it/s]Training (remove=8):  29%|██▉       | 204/700 [01:03<02:33,  3.22it/s]Training (remove=8):  29%|██▉       | 205/700 [01:03<02:33,  3.22it/s]Training (remove=8):  29%|██▉       | 206/700 [01:04<02:33,  3.22it/s]Training (remove=8):  30%|██▉       | 207/700 [01:04<02:32,  3.22it/s]Training (remove=8):  30%|██▉       | 208/700 [01:04<02:32,  3.22it/s]Training (remove=8):  30%|██▉       | 209/700 [01:04<02:32,  3.22it/s]Training (remove=8):  30%|███       | 210/700 [01:05<02:32,  3.22it/s]Training (remove=8):  30%|███       | 211/700 [01:05<02:31,  3.22it/s]Training (remove=8):  30%|███       | 212/700 [01:05<02:31,  3.22it/s]Training (remove=8):  30%|███       | 213/700 [01:06<02:31,  3.22it/s]Training (remove=8):  31%|███       | 214/700 [01:06<02:30,  3.22it/s]Training (remove=8):  31%|███       | 215/700 [01:06<02:30,  3.22it/s]Training (remove=8):  31%|███       | 216/700 [01:07<02:30,  3.22it/s]Training (remove=8):  31%|███       | 217/700 [01:07<02:30,  3.22it/s]Training (remove=8):  31%|███       | 218/700 [01:07<02:29,  3.22it/s]Training (remove=8):  31%|███▏      | 219/700 [01:08<02:29,  3.22it/s]Training (remove=8):  31%|███▏      | 220/700 [01:08<02:28,  3.22it/s]Training (remove=8):  32%|███▏      | 221/700 [01:08<02:28,  3.22it/s]Training (remove=8):  32%|███▏      | 222/700 [01:09<02:28,  3.22it/s]Training (remove=8):  32%|███▏      | 223/700 [01:09<02:28,  3.22it/s]Training (remove=8):  32%|███▏      | 224/700 [01:09<02:27,  3.22it/s]Training (remove=8):  32%|███▏      | 225/700 [01:09<02:27,  3.22it/s]Training (remove=8):  32%|███▏      | 226/700 [01:10<02:27,  3.22it/s]Training (remove=8):  32%|███▏      | 227/700 [01:10<02:26,  3.22it/s]Training (remove=8):  33%|███▎      | 228/700 [01:10<02:26,  3.22it/s]Training (remove=8):  33%|███▎      | 229/700 [01:11<02:26,  3.22it/s]Training (remove=8):  33%|███▎      | 230/700 [01:11<02:25,  3.22it/s]Training (remove=8):  33%|███▎      | 231/700 [01:11<02:25,  3.22it/s]Training (remove=8):  33%|███▎      | 232/700 [01:12<02:25,  3.22it/s]Training (remove=8):  33%|███▎      | 233/700 [01:12<02:24,  3.22it/s]Training (remove=8):  33%|███▎      | 234/700 [01:12<02:24,  3.22it/s]Training (remove=8):  34%|███▎      | 235/700 [01:13<02:24,  3.21it/s]Training (remove=8):  34%|███▎      | 236/700 [01:13<02:24,  3.21it/s]Training (remove=8):  34%|███▍      | 237/700 [01:13<02:24,  3.21it/s]Training (remove=8):  34%|███▍      | 238/700 [01:14<02:23,  3.21it/s]Training (remove=8):  34%|███▍      | 239/700 [01:14<02:23,  3.22it/s]Training (remove=8):  34%|███▍      | 240/700 [01:14<02:22,  3.22it/s]Training (remove=8):  34%|███▍      | 241/700 [01:14<02:22,  3.22it/s]Training (remove=8):  35%|███▍      | 242/700 [01:15<02:22,  3.22it/s]Training (remove=8):  35%|███▍      | 243/700 [01:15<02:22,  3.21it/s]Training (remove=8):  35%|███▍      | 244/700 [01:15<02:21,  3.22it/s]Training (remove=8):  35%|███▌      | 245/700 [01:16<02:21,  3.22it/s]Training (remove=8):  35%|███▌      | 246/700 [01:16<02:21,  3.22it/s]Training (remove=8):  35%|███▌      | 247/700 [01:16<02:20,  3.22it/s]Training (remove=8):  35%|███▌      | 248/700 [01:17<02:20,  3.22it/s]Training (remove=8):  36%|███▌      | 249/700 [01:17<02:20,  3.22it/s]Training (remove=8):  36%|███▌      | 250/700 [01:17<02:19,  3.22it/s]Training (remove=8):  36%|███▌      | 251/700 [01:18<02:19,  3.22it/s]Training (remove=8):  36%|███▌      | 252/700 [01:18<02:19,  3.22it/s]Training (remove=8):  36%|███▌      | 253/700 [01:18<02:18,  3.22it/s]Training (remove=8):  36%|███▋      | 254/700 [01:18<02:18,  3.22it/s]Training (remove=8):  36%|███▋      | 255/700 [01:19<02:18,  3.22it/s]Training (remove=8):  37%|███▋      | 256/700 [01:19<02:18,  3.22it/s]Training (remove=8):  37%|███▋      | 257/700 [01:19<02:17,  3.22it/s]Training (remove=8):  37%|███▋      | 258/700 [01:20<02:17,  3.22it/s]Training (remove=8):  37%|███▋      | 259/700 [01:20<02:16,  3.22it/s]Training (remove=8):  37%|███▋      | 260/700 [01:20<02:16,  3.22it/s]Training (remove=8):  37%|███▋      | 261/700 [01:21<02:16,  3.22it/s]Training (remove=8):  37%|███▋      | 262/700 [01:21<02:16,  3.22it/s]Training (remove=8):  38%|███▊      | 263/700 [01:21<02:15,  3.22it/s]Training (remove=8):  38%|███▊      | 264/700 [01:22<02:15,  3.22it/s]Training (remove=8):  38%|███▊      | 265/700 [01:22<02:14,  3.22it/s]Training (remove=8):  38%|███▊      | 266/700 [01:22<02:14,  3.22it/s]Training (remove=8):  38%|███▊      | 267/700 [01:23<02:14,  3.22it/s]Training (remove=8):  38%|███▊      | 268/700 [01:23<02:14,  3.21it/s]Training (remove=8):  38%|███▊      | 269/700 [01:23<02:14,  3.21it/s]Training (remove=8):  39%|███▊      | 270/700 [01:23<02:13,  3.21it/s]Training (remove=8):  39%|███▊      | 271/700 [01:24<02:13,  3.22it/s]Training (remove=8):  39%|███▉      | 272/700 [01:24<02:13,  3.22it/s]Training (remove=8):  39%|███▉      | 273/700 [01:24<02:12,  3.22it/s]Training (remove=8):  39%|███▉      | 274/700 [01:25<02:12,  3.22it/s]Training (remove=8):  39%|███▉      | 275/700 [01:25<02:11,  3.22it/s]Training (remove=8):  39%|███▉      | 276/700 [01:25<02:11,  3.22it/s]Training (remove=8):  40%|███▉      | 277/700 [01:26<02:11,  3.22it/s]Training (remove=8):  40%|███▉      | 278/700 [01:26<02:11,  3.22it/s]Training (remove=8):  40%|███▉      | 279/700 [01:26<02:10,  3.22it/s]Training (remove=8):  40%|████      | 280/700 [01:27<02:10,  3.22it/s]Training (remove=8):  40%|████      | 281/700 [01:27<02:10,  3.22it/s]Training (remove=8):  40%|████      | 282/700 [01:27<02:09,  3.22it/s]Training (remove=8):  40%|████      | 283/700 [01:27<02:09,  3.22it/s]Training (remove=8):  41%|████      | 284/700 [01:28<02:09,  3.22it/s]Training (remove=8):  41%|████      | 285/700 [01:28<02:08,  3.22it/s]Training (remove=8):  41%|████      | 286/700 [01:28<02:08,  3.22it/s]Training (remove=8):  41%|████      | 287/700 [01:29<02:08,  3.22it/s]Training (remove=8):  41%|████      | 288/700 [01:29<02:08,  3.21it/s]Training (remove=8):  41%|████▏     | 289/700 [01:29<02:07,  3.22it/s]Training (remove=8):  41%|████▏     | 290/700 [01:30<02:07,  3.22it/s]Training (remove=8):  42%|████▏     | 291/700 [01:30<02:06,  3.22it/s]Training (remove=8):  42%|████▏     | 292/700 [01:30<02:06,  3.22it/s]Training (remove=8):  42%|████▏     | 293/700 [01:31<02:06,  3.21it/s]Training (remove=8):  42%|████▏     | 294/700 [01:31<02:06,  3.22it/s]Training (remove=8):  42%|████▏     | 295/700 [01:31<02:05,  3.22it/s]Training (remove=8):  42%|████▏     | 296/700 [01:32<02:05,  3.22it/s]Training (remove=8):  42%|████▏     | 297/700 [01:32<02:05,  3.22it/s]Training (remove=8):  43%|████▎     | 298/700 [01:32<02:04,  3.22it/s]Training (remove=8):  43%|████▎     | 299/700 [01:32<02:04,  3.22it/s]Training (remove=8):  43%|████▎     | 300/700 [01:33<02:04,  3.22it/s]Training (remove=8):  43%|████▎     | 301/700 [01:33<02:03,  3.22it/s]Training (remove=8):  43%|████▎     | 302/700 [01:33<02:03,  3.22it/s]Training (remove=8):  43%|████▎     | 303/700 [01:34<02:03,  3.22it/s]Training (remove=8):  43%|████▎     | 304/700 [01:34<02:03,  3.21it/s]Training (remove=8):  44%|████▎     | 305/700 [01:34<02:02,  3.22it/s]Training (remove=8):  44%|████▎     | 306/700 [01:35<02:02,  3.22it/s]Training (remove=8):  44%|████▍     | 307/700 [01:35<02:02,  3.22it/s]Training (remove=8):  44%|████▍     | 308/700 [01:35<02:01,  3.22it/s]Training (remove=8):  44%|████▍     | 309/700 [01:36<02:01,  3.22it/s]Training (remove=8):  44%|████▍     | 310/700 [01:36<02:01,  3.22it/s]Training (remove=8):  44%|████▍     | 311/700 [01:36<02:00,  3.22it/s]Training (remove=8):  45%|████▍     | 312/700 [01:36<02:00,  3.21it/s]Training (remove=8):  45%|████▍     | 313/700 [01:37<02:00,  3.22it/s]Training (remove=8):  45%|████▍     | 314/700 [01:37<01:59,  3.22it/s]Training (remove=8):  45%|████▌     | 315/700 [01:37<01:59,  3.22it/s]Training (remove=8):  45%|████▌     | 316/700 [01:38<01:59,  3.22it/s]Training (remove=8):  45%|████▌     | 317/700 [01:38<01:58,  3.22it/s]Training (remove=8):  45%|████▌     | 318/700 [01:38<01:58,  3.22it/s]Training (remove=8):  46%|████▌     | 319/700 [01:39<01:58,  3.22it/s]Training (remove=8):  46%|████▌     | 320/700 [01:39<01:57,  3.22it/s]Training (remove=8):  46%|████▌     | 321/700 [01:39<01:57,  3.21it/s]Training (remove=8):  46%|████▌     | 322/700 [01:40<01:57,  3.21it/s]Training (remove=8):  46%|████▌     | 323/700 [01:40<01:57,  3.22it/s]Training (remove=8):  46%|████▋     | 324/700 [01:40<01:56,  3.22it/s]Training (remove=8):  46%|████▋     | 325/700 [01:41<01:56,  3.22it/s]Training (remove=8):  47%|████▋     | 326/700 [01:41<01:56,  3.22it/s]Training (remove=8):  47%|████▋     | 327/700 [01:41<01:55,  3.22it/s]Training (remove=8):  47%|████▋     | 328/700 [01:41<01:55,  3.21it/s]Training (remove=8):  47%|████▋     | 329/700 [01:42<01:55,  3.22it/s]Training (remove=8):  47%|████▋     | 330/700 [01:42<01:54,  3.22it/s]Training (remove=8):  47%|████▋     | 331/700 [01:42<01:54,  3.22it/s]Training (remove=8):  47%|████▋     | 332/700 [01:43<01:54,  3.22it/s]Training (remove=8):  48%|████▊     | 333/700 [01:43<01:54,  3.22it/s]Training (remove=8):  48%|████▊     | 334/700 [01:43<01:53,  3.22it/s]Training (remove=8):  48%|████▊     | 335/700 [01:44<01:53,  3.22it/s]Training (remove=8):  48%|████▊     | 336/700 [01:44<01:53,  3.22it/s]Training (remove=8):  48%|████▊     | 337/700 [01:44<01:52,  3.22it/s]Training (remove=8):  48%|████▊     | 338/700 [01:45<01:52,  3.22it/s]Training (remove=8):  48%|████▊     | 339/700 [01:45<01:52,  3.22it/s]Training (remove=8):  49%|████▊     | 340/700 [01:45<01:52,  3.21it/s]Training (remove=8):  49%|████▊     | 341/700 [01:46<01:51,  3.22it/s]Training (remove=8):  49%|████▉     | 342/700 [01:46<01:51,  3.22it/s]Training (remove=8):  49%|████▉     | 343/700 [01:46<01:50,  3.22it/s]Training (remove=8):  49%|████▉     | 344/700 [01:46<01:50,  3.22it/s]Training (remove=8):  49%|████▉     | 345/700 [01:47<01:50,  3.22it/s]Training (remove=8):  49%|████▉     | 346/700 [01:47<01:49,  3.22it/s]Training (remove=8):  50%|████▉     | 347/700 [01:47<01:49,  3.22it/s]Training (remove=8):  50%|████▉     | 348/700 [01:48<01:49,  3.21it/s]Training (remove=8):  50%|████▉     | 349/700 [01:48<01:49,  3.22it/s]Training (remove=8):  50%|█████     | 350/700 [01:48<01:48,  3.22it/s]Training (remove=8):  50%|█████     | 351/700 [01:49<01:48,  3.22it/s]Training (remove=8):  50%|█████     | 352/700 [01:49<01:48,  3.22it/s]Training (remove=8):  50%|█████     | 353/700 [01:49<01:47,  3.22it/s]Training (remove=8):  51%|█████     | 354/700 [01:50<01:47,  3.22it/s]Training (remove=8):  51%|█████     | 355/700 [01:50<01:47,  3.22it/s]Training (remove=8):  51%|█████     | 356/700 [01:50<01:46,  3.22it/s]Training (remove=8):  51%|█████     | 357/700 [01:50<01:46,  3.22it/s]Training (remove=8):  51%|█████     | 358/700 [01:51<01:46,  3.22it/s]Training (remove=8):  51%|█████▏    | 359/700 [01:51<01:45,  3.22it/s]Training (remove=8):  51%|█████▏    | 360/700 [01:51<01:45,  3.22it/s]Training (remove=8):  52%|█████▏    | 361/700 [01:52<01:45,  3.22it/s]Training (remove=8):  52%|█████▏    | 362/700 [01:52<01:44,  3.22it/s]Training (remove=8):  52%|█████▏    | 363/700 [01:52<01:44,  3.22it/s]Training (remove=8):  52%|█████▏    | 364/700 [01:53<01:44,  3.22it/s]Training (remove=8):  52%|█████▏    | 365/700 [01:53<01:43,  3.22it/s]Training (remove=8):  52%|█████▏    | 366/700 [01:53<01:43,  3.22it/s]Training (remove=8):  52%|█████▏    | 367/700 [01:54<01:43,  3.22it/s]Training (remove=8):  53%|█████▎    | 368/700 [01:54<01:43,  3.22it/s]Training (remove=8):  53%|█████▎    | 369/700 [01:54<01:42,  3.22it/s]Training (remove=8):  53%|█████▎    | 370/700 [01:55<01:42,  3.21it/s]Training (remove=8):  53%|█████▎    | 371/700 [01:55<01:42,  3.22it/s]Training (remove=8):  53%|█████▎    | 372/700 [01:55<01:41,  3.22it/s]Training (remove=8):  53%|█████▎    | 373/700 [01:55<01:41,  3.22it/s]Training (remove=8):  53%|█████▎    | 374/700 [01:56<01:41,  3.21it/s]Training (remove=8):  54%|█████▎    | 375/700 [01:56<01:41,  3.21it/s]Training (remove=8):  54%|█████▎    | 376/700 [01:56<01:40,  3.22it/s]Training (remove=8):  54%|█████▍    | 377/700 [01:57<01:40,  3.21it/s]Training (remove=8):  54%|█████▍    | 378/700 [01:57<01:40,  3.21it/s]Training (remove=8):  54%|█████▍    | 379/700 [01:57<01:39,  3.21it/s]Training (remove=8):  54%|█████▍    | 380/700 [01:58<01:39,  3.22it/s]Training (remove=8):  54%|█████▍    | 381/700 [01:58<01:39,  3.22it/s]Training (remove=8):  55%|█████▍    | 382/700 [01:58<01:38,  3.21it/s]Training (remove=8):  55%|█████▍    | 383/700 [01:59<01:38,  3.22it/s]Training (remove=8):  55%|█████▍    | 384/700 [01:59<01:38,  3.21it/s]Training (remove=8):  55%|█████▌    | 385/700 [01:59<01:38,  3.21it/s]Training (remove=8):  55%|█████▌    | 386/700 [01:59<01:37,  3.21it/s]Training (remove=8):  55%|█████▌    | 387/700 [02:00<01:37,  3.22it/s]Training (remove=8):  55%|█████▌    | 388/700 [02:00<01:36,  3.22it/s]Training (remove=8):  56%|█████▌    | 389/700 [02:00<01:36,  3.21it/s]Training (remove=8):  56%|█████▌    | 390/700 [02:01<01:36,  3.22it/s]Training (remove=8):  56%|█████▌    | 391/700 [02:01<01:35,  3.22it/s]Training (remove=8):  56%|█████▌    | 392/700 [02:01<01:35,  3.21it/s]Training (remove=8):  56%|█████▌    | 393/700 [02:02<01:35,  3.21it/s]Training (remove=8):  56%|█████▋    | 394/700 [02:02<01:35,  3.21it/s]Training (remove=8):  56%|█████▋    | 395/700 [02:02<01:34,  3.22it/s]Training (remove=8):  57%|█████▋    | 396/700 [02:03<01:34,  3.22it/s]Training (remove=8):  57%|█████▋    | 397/700 [02:03<01:34,  3.22it/s]Training (remove=8):  57%|█████▋    | 398/700 [02:03<01:33,  3.22it/s]Training (remove=8):  57%|█████▋    | 399/700 [02:04<01:33,  3.22it/s]Training (remove=8):  57%|█████▋    | 400/700 [02:04<01:33,  3.22it/s]Training (remove=8):  57%|█████▋    | 401/700 [02:04<01:32,  3.22it/s]Training (remove=8):  57%|█████▋    | 402/700 [02:04<01:32,  3.22it/s]Training (remove=8):  58%|█████▊    | 403/700 [02:05<01:32,  3.21it/s]Training (remove=8):  58%|█████▊    | 404/700 [02:05<01:32,  3.21it/s]Training (remove=8):  58%|█████▊    | 405/700 [02:05<01:31,  3.21it/s]Training (remove=8):  58%|█████▊    | 406/700 [02:06<01:31,  3.21it/s]Training (remove=8):  58%|█████▊    | 407/700 [02:06<01:31,  3.21it/s]Training (remove=8):  58%|█████▊    | 408/700 [02:06<01:30,  3.22it/s]Training (remove=8):  58%|█████▊    | 409/700 [02:07<01:30,  3.22it/s]Training (remove=8):  59%|█████▊    | 410/700 [02:07<01:30,  3.21it/s]Training (remove=8):  59%|█████▊    | 411/700 [02:07<01:29,  3.22it/s]Training (remove=8):  59%|█████▉    | 412/700 [02:08<01:29,  3.22it/s]Training (remove=8):  59%|█████▉    | 413/700 [02:08<01:29,  3.22it/s]Training (remove=8):  59%|█████▉    | 414/700 [02:08<01:28,  3.22it/s]Training (remove=8):  59%|█████▉    | 415/700 [02:09<01:28,  3.22it/s]Training (remove=8):  59%|█████▉    | 416/700 [02:09<01:28,  3.22it/s]Training (remove=8):  60%|█████▉    | 417/700 [02:09<01:27,  3.22it/s]Training (remove=8):  60%|█████▉    | 418/700 [02:09<01:27,  3.22it/s]Training (remove=8):  60%|█████▉    | 419/700 [02:10<01:27,  3.22it/s]Training (remove=8):  60%|██████    | 420/700 [02:10<01:26,  3.22it/s]Training (remove=8):  60%|██████    | 421/700 [02:10<01:26,  3.22it/s]Training (remove=8):  60%|██████    | 422/700 [02:11<01:26,  3.22it/s]Training (remove=8):  60%|██████    | 423/700 [02:11<01:26,  3.22it/s]Training (remove=8):  61%|██████    | 424/700 [02:11<01:25,  3.22it/s]Training (remove=8):  61%|██████    | 425/700 [02:12<01:25,  3.22it/s]Training (remove=8):  61%|██████    | 426/700 [02:12<01:25,  3.22it/s]Training (remove=8):  61%|██████    | 427/700 [02:12<01:24,  3.21it/s]Training (remove=8):  61%|██████    | 428/700 [02:13<01:24,  3.22it/s]Training (remove=8):  61%|██████▏   | 429/700 [02:13<01:24,  3.21it/s]Training (remove=8):  61%|██████▏   | 430/700 [02:13<01:23,  3.22it/s]Training (remove=8):  62%|██████▏   | 431/700 [02:13<01:23,  3.22it/s]Training (remove=8):  62%|██████▏   | 432/700 [02:14<01:23,  3.22it/s]Training (remove=8):  62%|██████▏   | 433/700 [02:14<01:22,  3.22it/s]Training (remove=8):  62%|██████▏   | 434/700 [02:14<01:22,  3.22it/s]Training (remove=8):  62%|██████▏   | 435/700 [02:15<01:22,  3.22it/s]Training (remove=8):  62%|██████▏   | 436/700 [02:15<01:21,  3.22it/s]Training (remove=8):  62%|██████▏   | 437/700 [02:15<01:21,  3.21it/s]Training (remove=8):  63%|██████▎   | 438/700 [02:16<01:21,  3.21it/s]Training (remove=8):  63%|██████▎   | 439/700 [02:16<01:21,  3.22it/s]Training (remove=8):  63%|██████▎   | 440/700 [02:16<01:20,  3.22it/s]Training (remove=8):  63%|██████▎   | 441/700 [02:17<01:20,  3.22it/s]Training (remove=8):  63%|██████▎   | 442/700 [02:17<01:20,  3.22it/s]Training (remove=8):  63%|██████▎   | 443/700 [02:17<01:19,  3.22it/s]Training (remove=8):  63%|██████▎   | 444/700 [02:18<01:19,  3.22it/s]Training (remove=8):  64%|██████▎   | 445/700 [02:18<01:19,  3.22it/s]Training (remove=8):  64%|██████▎   | 446/700 [02:18<01:19,  3.21it/s]Training (remove=8):  64%|██████▍   | 447/700 [02:18<01:18,  3.21it/s]Training (remove=8):  64%|██████▍   | 448/700 [02:19<01:18,  3.21it/s]Training (remove=8):  64%|██████▍   | 449/700 [02:19<01:18,  3.21it/s]Training (remove=8):  64%|██████▍   | 450/700 [02:19<01:17,  3.22it/s]Training (remove=8):  64%|██████▍   | 451/700 [02:20<01:17,  3.22it/s]Training (remove=8):  65%|██████▍   | 452/700 [02:20<01:17,  3.22it/s]Training (remove=8):  65%|██████▍   | 453/700 [02:20<01:16,  3.22it/s]Training (remove=8):  65%|██████▍   | 454/700 [02:21<01:16,  3.21it/s]Training (remove=8):  65%|██████▌   | 455/700 [02:21<01:16,  3.22it/s]Training (remove=8):  65%|██████▌   | 456/700 [02:21<01:15,  3.22it/s]Training (remove=8):  65%|██████▌   | 457/700 [02:22<01:15,  3.22it/s]Training (remove=8):  65%|██████▌   | 458/700 [02:22<01:15,  3.22it/s]Training (remove=8):  66%|██████▌   | 459/700 [02:22<01:14,  3.22it/s]Training (remove=8):  66%|██████▌   | 460/700 [02:22<01:14,  3.22it/s]Training (remove=8):  66%|██████▌   | 461/700 [02:23<01:14,  3.22it/s]Training (remove=8):  66%|██████▌   | 462/700 [02:23<01:13,  3.22it/s]Training (remove=8):  66%|██████▌   | 463/700 [02:23<01:13,  3.22it/s]Training (remove=8):  66%|██████▋   | 464/700 [02:24<01:13,  3.22it/s]Training (remove=8):  66%|██████▋   | 465/700 [02:24<01:12,  3.22it/s]Training (remove=8):  67%|██████▋   | 466/700 [02:24<01:12,  3.22it/s]Training (remove=8):  67%|██████▋   | 467/700 [02:25<01:12,  3.22it/s]Training (remove=8):  67%|██████▋   | 468/700 [02:25<01:12,  3.22it/s]Training (remove=8):  67%|██████▋   | 469/700 [02:25<01:11,  3.22it/s]Training (remove=8):  67%|██████▋   | 470/700 [02:26<01:11,  3.22it/s]Training (remove=8):  67%|██████▋   | 471/700 [02:26<01:11,  3.22it/s]Training (remove=8):  67%|██████▋   | 472/700 [02:26<01:10,  3.22it/s]Training (remove=8):  68%|██████▊   | 473/700 [02:27<01:10,  3.22it/s]Training (remove=8):  68%|██████▊   | 474/700 [02:27<01:10,  3.22it/s]Training (remove=8):  68%|██████▊   | 475/700 [02:27<01:09,  3.22it/s]Training (remove=8):  68%|██████▊   | 476/700 [02:27<01:09,  3.22it/s]Training (remove=8):  68%|██████▊   | 477/700 [02:28<01:09,  3.22it/s]Training (remove=8):  68%|██████▊   | 478/700 [02:28<01:08,  3.22it/s]Training (remove=8):  68%|██████▊   | 479/700 [02:28<01:08,  3.22it/s]Training (remove=8):  69%|██████▊   | 480/700 [02:29<01:08,  3.22it/s]Training (remove=8):  69%|██████▊   | 481/700 [02:29<01:08,  3.21it/s]Training (remove=8):  69%|██████▉   | 482/700 [02:29<01:07,  3.22it/s]Training (remove=8):  69%|██████▉   | 483/700 [02:30<01:07,  3.21it/s]Training (remove=8):  69%|██████▉   | 484/700 [02:30<01:07,  3.22it/s]Training (remove=8):  69%|██████▉   | 485/700 [02:30<01:06,  3.21it/s]Training (remove=8):  69%|██████▉   | 486/700 [02:31<01:06,  3.21it/s]Training (remove=8):  70%|██████▉   | 487/700 [02:31<01:06,  3.21it/s]Training (remove=8):  70%|██████▉   | 488/700 [02:31<01:06,  3.21it/s]Training (remove=8):  70%|██████▉   | 489/700 [02:31<01:05,  3.22it/s]Training (remove=8):  70%|███████   | 490/700 [02:32<01:05,  3.22it/s]Training (remove=8):  70%|███████   | 491/700 [02:32<01:04,  3.22it/s]Training (remove=8):  70%|███████   | 492/700 [02:32<01:04,  3.22it/s]Training (remove=8):  70%|███████   | 493/700 [02:33<01:04,  3.22it/s]Training (remove=8):  71%|███████   | 494/700 [02:33<01:03,  3.22it/s]Training (remove=8):  71%|███████   | 495/700 [02:33<01:03,  3.22it/s]Training (remove=8):  71%|███████   | 496/700 [02:34<01:03,  3.22it/s]Training (remove=8):  71%|███████   | 497/700 [02:34<01:02,  3.22it/s]Training (remove=8):  71%|███████   | 498/700 [02:34<01:02,  3.22it/s]Training (remove=8):  71%|███████▏  | 499/700 [02:35<01:02,  3.22it/s]Training (remove=8):  71%|███████▏  | 500/700 [02:35<01:02,  3.22it/s]Training (remove=8):  72%|███████▏  | 501/700 [02:35<01:01,  3.21it/s]Training (remove=8):  72%|███████▏  | 502/700 [02:36<01:01,  3.22it/s]Training (remove=8):  72%|███████▏  | 503/700 [02:36<01:01,  3.22it/s]Training (remove=8):  72%|███████▏  | 504/700 [02:36<01:00,  3.23it/s]Training (remove=8):  72%|███████▏  | 505/700 [02:36<01:00,  3.23it/s]Training (remove=8):  72%|███████▏  | 506/700 [02:37<00:59,  3.23it/s]Training (remove=8):  72%|███████▏  | 507/700 [02:37<00:59,  3.23it/s]Training (remove=8):  73%|███████▎  | 508/700 [02:37<00:59,  3.23it/s]Training (remove=8):  73%|███████▎  | 509/700 [02:38<00:59,  3.23it/s]Training (remove=8):  73%|███████▎  | 510/700 [02:38<00:58,  3.23it/s]Training (remove=8):  73%|███████▎  | 511/700 [02:38<00:58,  3.22it/s]Training (remove=8):  73%|███████▎  | 512/700 [02:39<00:58,  3.23it/s]Training (remove=8):  73%|███████▎  | 513/700 [02:39<00:57,  3.22it/s]Training (remove=8):  73%|███████▎  | 514/700 [02:39<00:57,  3.22it/s]Training (remove=8):  74%|███████▎  | 515/700 [02:40<00:57,  3.23it/s]Training (remove=8):  74%|███████▎  | 516/700 [02:40<00:57,  3.23it/s]Training (remove=8):  74%|███████▍  | 517/700 [02:40<00:56,  3.23it/s]Training (remove=8):  74%|███████▍  | 518/700 [02:40<00:56,  3.23it/s]Training (remove=8):  74%|███████▍  | 519/700 [02:41<00:56,  3.22it/s]Training (remove=8):  74%|███████▍  | 520/700 [02:41<00:55,  3.23it/s]Training (remove=8):  74%|███████▍  | 521/700 [02:41<00:55,  3.23it/s]Training (remove=8):  75%|███████▍  | 522/700 [02:42<00:55,  3.23it/s]Training (remove=8):  75%|███████▍  | 523/700 [02:42<00:54,  3.23it/s]Training (remove=8):  75%|███████▍  | 524/700 [02:42<00:54,  3.23it/s]Training (remove=8):  75%|███████▌  | 525/700 [02:43<00:54,  3.23it/s]Training (remove=8):  75%|███████▌  | 526/700 [02:43<00:54,  3.22it/s]Training (remove=8):  75%|███████▌  | 527/700 [02:43<00:53,  3.22it/s]Training (remove=8):  75%|███████▌  | 528/700 [02:44<00:53,  3.22it/s]Training (remove=8):  76%|███████▌  | 529/700 [02:44<00:53,  3.22it/s]Training (remove=8):  76%|███████▌  | 530/700 [02:44<00:52,  3.23it/s]Training (remove=8):  76%|███████▌  | 531/700 [02:45<00:52,  3.22it/s]Training (remove=8):  76%|███████▌  | 532/700 [02:45<00:52,  3.23it/s]Training (remove=8):  76%|███████▌  | 533/700 [02:45<00:51,  3.23it/s]Training (remove=8):  76%|███████▋  | 534/700 [02:45<00:51,  3.23it/s]Training (remove=8):  76%|███████▋  | 535/700 [02:46<00:51,  3.23it/s]Training (remove=8):  77%|███████▋  | 536/700 [02:46<00:50,  3.23it/s]Training (remove=8):  77%|███████▋  | 537/700 [02:46<00:50,  3.23it/s]Training (remove=8):  77%|███████▋  | 538/700 [02:47<00:50,  3.22it/s]Training (remove=8):  77%|███████▋  | 539/700 [02:47<00:50,  3.22it/s]Training (remove=8):  77%|███████▋  | 540/700 [02:47<00:49,  3.22it/s]Training (remove=8):  77%|███████▋  | 541/700 [02:48<00:49,  3.22it/s]Training (remove=8):  77%|███████▋  | 542/700 [02:48<00:48,  3.23it/s]Training (remove=8):  78%|███████▊  | 543/700 [02:48<00:48,  3.23it/s]Training (remove=8):  78%|███████▊  | 544/700 [02:49<00:48,  3.23it/s]Training (remove=8):  78%|███████▊  | 545/700 [02:49<00:48,  3.23it/s]Training (remove=8):  78%|███████▊  | 546/700 [02:49<00:47,  3.23it/s]Training (remove=8):  78%|███████▊  | 547/700 [02:49<00:47,  3.23it/s]Training (remove=8):  78%|███████▊  | 548/700 [02:50<00:47,  3.23it/s]Training (remove=8):  78%|███████▊  | 549/700 [02:50<00:46,  3.23it/s]Training (remove=8):  79%|███████▊  | 550/700 [02:50<00:46,  3.23it/s]Training (remove=8):  79%|███████▊  | 551/700 [02:51<00:46,  3.24it/s]Training (remove=8):  79%|███████▉  | 552/700 [02:51<00:45,  3.23it/s]Training (remove=8):  79%|███████▉  | 553/700 [02:51<00:45,  3.23it/s]Training (remove=8):  79%|███████▉  | 554/700 [02:52<00:45,  3.23it/s]Training (remove=8):  79%|███████▉  | 555/700 [02:52<00:44,  3.22it/s]Training (remove=8):  79%|███████▉  | 556/700 [02:52<00:44,  3.23it/s]Training (remove=8):  80%|███████▉  | 557/700 [02:53<00:44,  3.23it/s]Training (remove=8):  80%|███████▉  | 558/700 [02:53<00:44,  3.22it/s]Training (remove=8):  80%|███████▉  | 559/700 [02:53<00:43,  3.22it/s]Training (remove=8):  80%|████████  | 560/700 [02:54<00:43,  3.23it/s]Training (remove=8):  80%|████████  | 561/700 [02:54<00:43,  3.23it/s]Training (remove=8):  80%|████████  | 562/700 [02:54<00:42,  3.23it/s]Training (remove=8):  80%|████████  | 563/700 [02:54<00:42,  3.23it/s]Training (remove=8):  81%|████████  | 564/700 [02:55<00:42,  3.23it/s]Training (remove=8):  81%|████████  | 565/700 [02:55<00:41,  3.23it/s]Training (remove=8):  81%|████████  | 566/700 [02:55<00:41,  3.23it/s]Training (remove=8):  81%|████████  | 567/700 [02:56<00:41,  3.23it/s]Training (remove=8):  81%|████████  | 568/700 [02:56<00:40,  3.23it/s]Training (remove=8):  81%|████████▏ | 569/700 [02:56<00:40,  3.23it/s]Training (remove=8):  81%|████████▏ | 570/700 [02:57<00:40,  3.23it/s]Training (remove=8):  82%|████████▏ | 571/700 [02:57<00:40,  3.22it/s]Training (remove=8):  82%|████████▏ | 572/700 [02:57<00:39,  3.22it/s]Training (remove=8):  82%|████████▏ | 573/700 [02:58<00:39,  3.23it/s]Training (remove=8):  82%|████████▏ | 574/700 [02:58<00:39,  3.23it/s]Training (remove=8):  82%|████████▏ | 575/700 [02:58<00:38,  3.22it/s]Training (remove=8):  82%|████████▏ | 576/700 [02:58<00:38,  3.22it/s]Training (remove=8):  82%|████████▏ | 577/700 [02:59<00:38,  3.22it/s]Training (remove=8):  83%|████████▎ | 578/700 [02:59<00:37,  3.22it/s]Training (remove=8):  83%|████████▎ | 579/700 [02:59<00:37,  3.23it/s]Training (remove=8):  83%|████████▎ | 580/700 [03:00<00:37,  3.23it/s]Training (remove=8):  83%|████████▎ | 581/700 [03:00<00:36,  3.23it/s]Training (remove=8):  83%|████████▎ | 582/700 [03:00<00:36,  3.23it/s]Training (remove=8):  83%|████████▎ | 583/700 [03:01<00:36,  3.22it/s]Training (remove=8):  83%|████████▎ | 584/700 [03:01<00:35,  3.23it/s]Training (remove=8):  84%|████████▎ | 585/700 [03:01<00:35,  3.23it/s]Training (remove=8):  84%|████████▎ | 586/700 [03:02<00:35,  3.23it/s]Training (remove=8):  84%|████████▍ | 587/700 [03:02<00:35,  3.22it/s]Training (remove=8):  84%|████████▍ | 588/700 [03:02<00:34,  3.23it/s]Training (remove=8):  84%|████████▍ | 589/700 [03:02<00:34,  3.23it/s]Training (remove=8):  84%|████████▍ | 590/700 [03:03<00:34,  3.23it/s]Training (remove=8):  84%|████████▍ | 591/700 [03:03<00:33,  3.23it/s]Training (remove=8):  85%|████████▍ | 592/700 [03:03<00:33,  3.20it/s]Training (remove=8):  85%|████████▍ | 593/700 [03:04<00:33,  3.18it/s]Training (remove=8):  85%|████████▍ | 594/700 [03:04<00:33,  3.17it/s]Training (remove=8):  85%|████████▌ | 595/700 [03:04<00:33,  3.15it/s]Training (remove=8):  85%|████████▌ | 596/700 [03:05<00:33,  3.14it/s]Training (remove=8):  85%|████████▌ | 597/700 [03:05<00:32,  3.14it/s]Training (remove=8):  85%|████████▌ | 598/700 [03:05<00:32,  3.13it/s]Training (remove=8):  86%|████████▌ | 599/700 [03:06<00:32,  3.13it/s]Training (remove=8):  86%|████████▌ | 600/700 [03:06<00:31,  3.16it/s]Training (remove=8):  86%|████████▌ | 601/700 [03:06<00:31,  3.18it/s]Training (remove=8):  86%|████████▌ | 602/700 [03:07<00:31,  3.10it/s]Training (remove=8):  86%|████████▌ | 603/700 [03:07<00:31,  3.06it/s]Training (remove=8):  86%|████████▋ | 604/700 [03:07<00:31,  3.07it/s]Training (remove=8):  86%|████████▋ | 605/700 [03:08<00:31,  2.99it/s]Training (remove=8):  87%|████████▋ | 606/700 [03:08<00:32,  2.93it/s]Training (remove=8):  87%|████████▋ | 607/700 [03:08<00:31,  2.98it/s]Training (remove=8):  87%|████████▋ | 608/700 [03:09<00:30,  2.99it/s]Training (remove=8):  87%|████████▋ | 609/700 [03:09<00:30,  2.98it/s]Training (remove=8):  87%|████████▋ | 610/700 [03:09<00:29,  3.00it/s]Training (remove=8):  87%|████████▋ | 611/700 [03:10<00:29,  3.02it/s]Training (remove=8):  87%|████████▋ | 612/700 [03:10<00:29,  3.03it/s]Training (remove=8):  88%|████████▊ | 613/700 [03:10<00:28,  3.04it/s]Training (remove=8):  88%|████████▊ | 614/700 [03:11<00:28,  3.02it/s]Training (remove=8):  88%|████████▊ | 615/700 [03:11<00:28,  3.00it/s]Training (remove=8):  88%|████████▊ | 616/700 [03:11<00:28,  2.98it/s]Training (remove=8):  88%|████████▊ | 617/700 [03:12<00:27,  2.97it/s]Training (remove=8):  88%|████████▊ | 618/700 [03:12<00:27,  2.97it/s]Training (remove=8):  88%|████████▊ | 619/700 [03:12<00:27,  2.96it/s]Training (remove=8):  89%|████████▊ | 620/700 [03:13<00:27,  2.95it/s]Training (remove=8):  89%|████████▊ | 621/700 [03:13<00:26,  2.95it/s]Training (remove=8):  89%|████████▉ | 622/700 [03:13<00:26,  2.95it/s]Training (remove=8):  89%|████████▉ | 623/700 [03:14<00:26,  2.95it/s]Training (remove=8):  89%|████████▉ | 624/700 [03:14<00:25,  2.95it/s]Training (remove=8):  89%|████████▉ | 625/700 [03:14<00:25,  2.95it/s]Training (remove=8):  89%|████████▉ | 626/700 [03:15<00:25,  2.95it/s]Training (remove=8):  90%|████████▉ | 627/700 [03:15<00:24,  2.95it/s]Training (remove=8):  90%|████████▉ | 628/700 [03:15<00:24,  2.94it/s]Training (remove=8):  90%|████████▉ | 629/700 [03:16<00:24,  2.94it/s]Training (remove=8):  90%|█████████ | 630/700 [03:16<00:23,  2.94it/s]Training (remove=8):  90%|█████████ | 631/700 [03:16<00:23,  2.95it/s]Training (remove=8):  90%|█████████ | 632/700 [03:17<00:23,  2.95it/s]Training (remove=8):  90%|█████████ | 633/700 [03:17<00:22,  2.95it/s]Training (remove=8):  91%|█████████ | 634/700 [03:17<00:22,  2.97it/s]Training (remove=8):  91%|█████████ | 635/700 [03:18<00:22,  2.90it/s]Training (remove=8):  91%|█████████ | 636/700 [03:18<00:22,  2.90it/s]Training (remove=8):  91%|█████████ | 637/700 [03:18<00:21,  2.94it/s]Training (remove=8):  91%|█████████ | 638/700 [03:19<00:20,  2.97it/s]Training (remove=8):  91%|█████████▏| 639/700 [03:19<00:20,  2.99it/s]Training (remove=8):  91%|█████████▏| 640/700 [03:19<00:19,  3.00it/s]Training (remove=8):  92%|█████████▏| 641/700 [03:20<00:19,  3.02it/s]Training (remove=8):  92%|█████████▏| 642/700 [03:20<00:19,  3.03it/s]Training (remove=8):  92%|█████████▏| 643/700 [03:20<00:18,  3.00it/s]Training (remove=8):  92%|█████████▏| 644/700 [03:21<00:18,  2.98it/s]Training (remove=8):  92%|█████████▏| 645/700 [03:21<00:18,  2.94it/s]Training (remove=8):  92%|█████████▏| 646/700 [03:22<00:18,  2.86it/s]Training (remove=8):  92%|█████████▏| 647/700 [03:22<00:18,  2.80it/s]Training (remove=8):  93%|█████████▎| 648/700 [03:22<00:18,  2.76it/s]Training (remove=8):  93%|█████████▎| 649/700 [03:23<00:18,  2.74it/s]Training (remove=8):  93%|█████████▎| 650/700 [03:23<00:18,  2.72it/s]Training (remove=8):  93%|█████████▎| 651/700 [03:23<00:18,  2.72it/s]Training (remove=8):  93%|█████████▎| 652/700 [03:24<00:17,  2.71it/s]Training (remove=8):  93%|█████████▎| 653/700 [03:24<00:17,  2.72it/s]Training (remove=8):  93%|█████████▎| 654/700 [03:24<00:16,  2.72it/s]Training (remove=8):  94%|█████████▎| 655/700 [03:25<00:16,  2.72it/s]Training (remove=8):  94%|█████████▎| 656/700 [03:25<00:16,  2.73it/s]Training (remove=8):  94%|█████████▍| 657/700 [03:26<00:15,  2.75it/s]Training (remove=8):  94%|█████████▍| 658/700 [03:26<00:15,  2.75it/s]Training (remove=8):  94%|█████████▍| 659/700 [03:26<00:14,  2.75it/s]Training (remove=8):  94%|█████████▍| 660/700 [03:27<00:14,  2.75it/s]Training (remove=8):  94%|█████████▍| 661/700 [03:27<00:14,  2.75it/s]Training (remove=8):  95%|█████████▍| 662/700 [03:27<00:13,  2.74it/s]Training (remove=8):  95%|█████████▍| 663/700 [03:28<00:13,  2.74it/s]Training (remove=8):  95%|█████████▍| 664/700 [03:28<00:13,  2.76it/s]Training (remove=8):  95%|█████████▌| 665/700 [03:28<00:12,  2.75it/s]Training (remove=8):  95%|█████████▌| 666/700 [03:29<00:12,  2.75it/s]Training (remove=8):  95%|█████████▌| 667/700 [03:29<00:12,  2.75it/s]Training (remove=8):  95%|█████████▌| 668/700 [03:30<00:11,  2.75it/s]Training (remove=8):  96%|█████████▌| 669/700 [03:30<00:11,  2.75it/s]Training (remove=8):  96%|█████████▌| 670/700 [03:30<00:10,  2.75it/s]Training (remove=8):  96%|█████████▌| 671/700 [03:31<00:10,  2.79it/s]Training (remove=8):  96%|█████████▌| 672/700 [03:31<00:10,  2.78it/s]Training (remove=8):  96%|█████████▌| 673/700 [03:31<00:09,  2.79it/s]Training (remove=8):  96%|█████████▋| 674/700 [03:32<00:09,  2.78it/s]Training (remove=8):  96%|█████████▋| 675/700 [03:32<00:09,  2.78it/s]Training (remove=8):  97%|█████████▋| 676/700 [03:32<00:08,  2.78it/s]Training (remove=8):  97%|█████████▋| 677/700 [03:33<00:08,  2.78it/s]Training (remove=8):  97%|█████████▋| 678/700 [03:33<00:07,  2.83it/s]Training (remove=8):  97%|█████████▋| 679/700 [03:33<00:07,  2.93it/s]Training (remove=8):  97%|█████████▋| 680/700 [03:34<00:06,  3.01it/s]Training (remove=8):  97%|█████████▋| 681/700 [03:34<00:06,  3.08it/s]Training (remove=8):  97%|█████████▋| 682/700 [03:34<00:05,  3.11it/s]Training (remove=8):  98%|█████████▊| 683/700 [03:35<00:05,  3.15it/s]Training (remove=8):  98%|█████████▊| 684/700 [03:35<00:05,  3.17it/s]Training (remove=8):  98%|█████████▊| 685/700 [03:35<00:04,  3.18it/s]Training (remove=8):  98%|█████████▊| 686/700 [03:36<00:04,  3.19it/s]Training (remove=8):  98%|█████████▊| 687/700 [03:36<00:04,  3.21it/s]Training (remove=8):  98%|█████████▊| 688/700 [03:36<00:03,  3.21it/s]Training (remove=8):  98%|█████████▊| 689/700 [03:37<00:03,  3.22it/s]Training (remove=8):  99%|█████████▊| 690/700 [03:37<00:03,  3.22it/s]Training (remove=8):  99%|█████████▊| 691/700 [03:37<00:02,  3.22it/s]Training (remove=8):  99%|█████████▉| 692/700 [03:37<00:02,  3.23it/s]Training (remove=8):  99%|█████████▉| 693/700 [03:38<00:02,  3.23it/s]Training (remove=8):  99%|█████████▉| 694/700 [03:38<00:01,  3.22it/s]Training (remove=8):  99%|█████████▉| 695/700 [03:38<00:01,  3.23it/s]Training (remove=8):  99%|█████████▉| 696/700 [03:39<00:01,  3.23it/s]Training (remove=8): 100%|█████████▉| 697/700 [03:39<00:00,  3.23it/s]Training (remove=8): 100%|█████████▉| 698/700 [03:39<00:00,  3.23it/s]Training (remove=8): 100%|█████████▉| 699/700 [03:40<00:00,  3.23it/s]Training (remove=8): 100%|██████████| 700/700 [03:40<00:00,  3.23it/s]Training (remove=8): 100%|██████████| 700/700 [03:40<00:00,  3.18it/s]
Step 100 - Loss: 0.0182
Step 200 - Loss: 0.0116
Step 300 - Loss: 0.0405
Step 400 - Loss: 0.1421
Step 500 - Loss: 0.0425
Step 600 - Loss: 0.0066
Step 700 - Loss: 0.0025
Epoch 2 - Average Loss: 0.0303
Evaluating (remove=8):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   0%|          | 1/200 [00:01<03:37,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   1%|          | 2/200 [00:02<03:35,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   2%|▏         | 3/200 [00:04<04:42,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   2%|▏         | 4/200 [00:06<05:53,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   2%|▎         | 5/200 [00:08<06:10,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   3%|▎         | 6/200 [00:11<07:37,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   4%|▎         | 7/200 [00:14<08:31,  2.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   4%|▍         | 8/200 [00:18<09:04,  2.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   4%|▍         | 9/200 [00:21<09:25,  2.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   5%|▌         | 10/200 [00:24<09:39,  3.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   6%|▌         | 11/200 [00:25<07:30,  2.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   6%|▌         | 12/200 [00:28<08:16,  2.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   6%|▋         | 13/200 [00:29<06:39,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   7%|▋         | 14/200 [00:32<07:26,  2.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   8%|▊         | 15/200 [00:33<06:12,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   8%|▊         | 16/200 [00:36<06:18,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   8%|▊         | 17/200 [00:36<05:10,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):   9%|▉         | 18/200 [00:40<06:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  10%|▉         | 19/200 [00:43<07:29,  2.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  10%|█         | 20/200 [00:46<08:07,  2.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  10%|█         | 21/200 [00:47<06:27,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  11%|█         | 22/200 [00:49<06:24,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  12%|█▏        | 23/200 [00:50<05:15,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  12%|█▏        | 24/200 [00:53<06:29,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  12%|█▎        | 25/200 [00:57<07:20,  2.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  13%|█▎        | 26/200 [00:57<05:52,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  14%|█▎        | 27/200 [00:58<04:50,  1.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  14%|█▍        | 28/200 [01:01<06:09,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  14%|█▍        | 29/200 [01:04<06:25,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  15%|█▌        | 30/200 [01:05<05:13,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  16%|█▌        | 31/200 [01:06<04:22,  1.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  16%|█▌        | 32/200 [01:07<04:13,  1.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  16%|█▋        | 33/200 [01:09<04:23,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  17%|█▋        | 34/200 [01:12<05:43,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  18%|█▊        | 35/200 [01:13<04:41,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  18%|█▊        | 36/200 [01:15<04:40,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  18%|█▊        | 37/200 [01:16<04:08,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  19%|█▉        | 38/200 [01:19<05:29,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  20%|█▉        | 39/200 [01:20<04:42,  1.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  20%|██        | 40/200 [01:21<03:57,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  20%|██        | 41/200 [01:22<03:27,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  21%|██        | 42/200 [01:25<04:42,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  22%|██▏       | 43/200 [01:26<03:58,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  22%|██▏       | 44/200 [01:28<04:16,  1.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  22%|██▎       | 45/200 [01:29<03:45,  1.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  23%|██▎       | 46/200 [01:31<04:36,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  24%|██▎       | 47/200 [01:32<03:57,  1.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  24%|██▍       | 48/200 [01:35<04:52,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  24%|██▍       | 49/200 [01:38<05:50,  2.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  25%|██▌       | 50/200 [01:40<05:42,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  26%|██▌       | 51/200 [01:42<04:47,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  26%|██▌       | 52/200 [01:45<05:43,  2.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  26%|██▋       | 53/200 [01:46<05:01,  2.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  27%|██▋       | 54/200 [01:47<04:07,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  28%|██▊       | 55/200 [01:48<03:29,  1.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  28%|██▊       | 56/200 [01:51<04:44,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  28%|██▊       | 57/200 [01:53<04:19,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  29%|██▉       | 58/200 [01:54<03:42,  1.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  30%|██▉       | 59/200 [01:57<04:51,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  30%|███       | 60/200 [01:58<04:08,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  30%|███       | 61/200 [02:01<05:07,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  31%|███       | 62/200 [02:03<04:55,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  32%|███▏      | 63/200 [02:05<04:32,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  32%|███▏      | 64/200 [02:06<04:11,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  32%|███▎      | 65/200 [02:09<05:05,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  33%|███▎      | 66/200 [02:12<05:21,  2.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  34%|███▎      | 67/200 [02:14<04:43,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  34%|███▍      | 68/200 [02:15<04:25,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  34%|███▍      | 69/200 [02:19<05:11,  2.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  35%|███▌      | 70/200 [02:22<05:35,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  36%|███▌      | 71/200 [02:23<04:26,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  36%|███▌      | 72/200 [02:25<04:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  36%|███▋      | 73/200 [02:28<05:17,  2.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  37%|███▋      | 74/200 [02:31<05:27,  2.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  38%|███▊      | 75/200 [02:34<05:49,  2.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  38%|███▊      | 76/200 [02:38<06:03,  2.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  38%|███▊      | 77/200 [02:39<04:57,  2.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  39%|███▉      | 78/200 [02:42<05:24,  2.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  40%|███▉      | 79/200 [02:45<05:43,  2.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  40%|████      | 80/200 [02:49<05:54,  2.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  40%|████      | 81/200 [02:52<06:02,  3.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  41%|████      | 82/200 [02:55<05:59,  3.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  42%|████▏     | 83/200 [02:57<05:14,  2.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  42%|████▏     | 84/200 [02:58<04:16,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  42%|████▎     | 85/200 [03:00<03:57,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  43%|████▎     | 86/200 [03:00<03:14,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  44%|████▎     | 87/200 [03:01<02:51,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  44%|████▍     | 88/200 [03:04<03:22,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  44%|████▍     | 89/200 [03:07<04:09,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  45%|████▌     | 90/200 [03:08<03:29,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  46%|████▌     | 91/200 [03:10<03:11,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  46%|████▌     | 92/200 [03:11<02:41,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  46%|████▋     | 93/200 [03:11<02:19,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  47%|████▋     | 94/200 [03:15<03:19,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  48%|████▊     | 95/200 [03:16<02:45,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  48%|████▊     | 96/200 [03:19<03:35,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  48%|████▊     | 97/200 [03:20<03:09,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  49%|████▉     | 98/200 [03:21<02:41,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  50%|████▉     | 99/200 [03:23<02:44,  1.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  50%|█████     | 100/200 [03:26<03:30,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  50%|█████     | 101/200 [03:27<02:51,  1.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  51%|█████     | 102/200 [03:28<02:43,  1.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  52%|█████▏    | 103/200 [03:30<02:24,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  52%|█████▏    | 104/200 [03:33<03:13,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  52%|█████▎    | 105/200 [03:34<02:45,  1.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  53%|█████▎    | 106/200 [03:35<02:31,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  54%|█████▎    | 107/200 [03:36<02:14,  1.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  54%|█████▍    | 108/200 [03:37<02:03,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  55%|█████▍    | 109/200 [03:41<02:53,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  55%|█████▌    | 110/200 [03:44<03:28,  2.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  56%|█████▌    | 111/200 [03:45<02:47,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  56%|█████▌    | 112/200 [03:47<02:53,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  56%|█████▋    | 113/200 [03:48<02:22,  1.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  57%|█████▋    | 114/200 [03:49<02:12,  1.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  57%|█████▊    | 115/200 [03:52<02:54,  2.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  58%|█████▊    | 116/200 [03:53<02:22,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  58%|█████▊    | 117/200 [03:54<02:05,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  59%|█████▉    | 118/200 [03:57<02:46,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  60%|█████▉    | 119/200 [03:59<02:27,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  60%|██████    | 120/200 [04:02<02:59,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  60%|██████    | 121/200 [04:03<02:30,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  61%|██████    | 122/200 [04:05<02:21,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  62%|██████▏   | 123/200 [04:08<02:52,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  62%|██████▏   | 124/200 [04:09<02:18,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  62%|██████▎   | 125/200 [04:10<02:00,  1.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  63%|██████▎   | 126/200 [04:13<02:34,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  64%|██████▎   | 127/200 [04:14<02:06,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  64%|██████▍   | 128/200 [04:15<01:45,  1.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  64%|██████▍   | 129/200 [04:16<01:36,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  65%|██████▌   | 130/200 [04:19<02:14,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  66%|██████▌   | 131/200 [04:20<01:51,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  66%|██████▌   | 132/200 [04:21<01:34,  1.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  66%|██████▋   | 133/200 [04:22<01:22,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  67%|██████▋   | 134/200 [04:23<01:14,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  68%|██████▊   | 135/200 [04:26<01:54,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  68%|██████▊   | 136/200 [04:27<01:42,  1.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  68%|██████▊   | 137/200 [04:30<02:11,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  69%|██████▉   | 138/200 [04:32<01:51,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  70%|██████▉   | 139/200 [04:35<02:15,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  70%|███████   | 140/200 [04:38<02:32,  2.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  70%|███████   | 141/200 [04:39<02:03,  2.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  71%|███████   | 142/200 [04:41<01:49,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  72%|███████▏  | 143/200 [04:44<02:10,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  72%|███████▏  | 144/200 [04:46<02:00,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  72%|███████▎  | 145/200 [04:47<01:44,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  73%|███████▎  | 146/200 [04:48<01:36,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  74%|███████▎  | 147/200 [04:50<01:28,  1.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  74%|███████▍  | 148/200 [04:53<01:51,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  74%|███████▍  | 149/200 [04:56<02:05,  2.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  75%|███████▌  | 150/200 [04:57<01:44,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  76%|███████▌  | 151/200 [04:59<01:27,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  76%|███████▌  | 152/200 [05:02<01:46,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  76%|███████▋  | 153/200 [05:03<01:25,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  77%|███████▋  | 154/200 [05:04<01:10,  1.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  78%|███████▊  | 155/200 [05:05<01:04,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  78%|███████▊  | 156/200 [05:08<01:26,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  78%|███████▊  | 157/200 [05:11<01:40,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  79%|███████▉  | 158/200 [05:14<01:49,  2.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  80%|███████▉  | 159/200 [05:16<01:31,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  80%|████████  | 160/200 [05:19<01:40,  2.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  80%|████████  | 161/200 [05:20<01:18,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  81%|████████  | 162/200 [05:21<01:03,  1.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  82%|████████▏ | 163/200 [05:22<01:02,  1.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  82%|████████▏ | 164/200 [05:23<00:51,  1.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  82%|████████▎ | 165/200 [05:26<01:08,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  83%|████████▎ | 166/200 [05:30<01:20,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  84%|████████▎ | 167/200 [05:31<01:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  84%|████████▍ | 168/200 [05:33<00:59,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  84%|████████▍ | 169/200 [05:34<00:50,  1.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  85%|████████▌ | 170/200 [05:35<00:43,  1.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  86%|████████▌ | 171/200 [05:38<00:57,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  86%|████████▌ | 172/200 [05:39<00:48,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  86%|████████▋ | 173/200 [05:40<00:41,  1.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  87%|████████▋ | 174/200 [05:43<00:53,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  88%|████████▊ | 175/200 [05:47<01:00,  2.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  88%|████████▊ | 176/200 [05:48<00:48,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  88%|████████▊ | 177/200 [05:49<00:40,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  89%|████████▉ | 178/200 [05:51<00:41,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  90%|████████▉ | 179/200 [05:54<00:48,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  90%|█████████ | 180/200 [05:58<00:51,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  90%|█████████ | 181/200 [05:58<00:39,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  91%|█████████ | 182/200 [06:02<00:43,  2.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  92%|█████████▏| 183/200 [06:03<00:33,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  92%|█████████▏| 184/200 [06:06<00:37,  2.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  92%|█████████▎| 185/200 [06:07<00:29,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  93%|█████████▎| 186/200 [06:08<00:24,  1.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  94%|█████████▎| 187/200 [06:09<00:19,  1.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  94%|█████████▍| 188/200 [06:10<00:15,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  94%|█████████▍| 189/200 [06:13<00:20,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  95%|█████████▌| 190/200 [06:14<00:16,  1.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  96%|█████████▌| 191/200 [06:17<00:19,  2.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  96%|█████████▌| 192/200 [06:19<00:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  96%|█████████▋| 193/200 [06:22<00:15,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  97%|█████████▋| 194/200 [06:25<00:15,  2.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  98%|█████████▊| 195/200 [06:27<00:11,  2.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  98%|█████████▊| 196/200 [06:28<00:07,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  98%|█████████▊| 197/200 [06:30<00:05,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8):  99%|█████████▉| 198/200 [06:31<00:03,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8): 100%|█████████▉| 199/200 [06:33<00:01,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=8): 100%|██████████| 200/200 [06:34<00:00,  1.62s/it]Evaluating (remove=8): 100%|██████████| 200/200 [06:34<00:00,  1.97s/it]
Epoch 2 - Accuracy: 0.0750
Epoch 3/10 - Removing 16 tokens
Training (remove=16):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=16):   0%|          | 1/700 [00:00<03:34,  3.26it/s]Training (remove=16):   0%|          | 2/700 [00:00<03:35,  3.25it/s]Training (remove=16):   0%|          | 3/700 [00:00<03:35,  3.23it/s]Training (remove=16):   1%|          | 4/700 [00:01<03:35,  3.23it/s]Training (remove=16):   1%|          | 5/700 [00:01<03:35,  3.22it/s]Training (remove=16):   1%|          | 6/700 [00:01<03:35,  3.22it/s]Training (remove=16):   1%|          | 7/700 [00:02<03:34,  3.23it/s]Training (remove=16):   1%|          | 8/700 [00:02<03:34,  3.22it/s]Training (remove=16):   1%|▏         | 9/700 [00:02<03:34,  3.22it/s]Training (remove=16):   1%|▏         | 10/700 [00:03<03:34,  3.22it/s]Training (remove=16):   2%|▏         | 11/700 [00:03<03:34,  3.21it/s]Training (remove=16):   2%|▏         | 12/700 [00:03<03:34,  3.21it/s]Training (remove=16):   2%|▏         | 13/700 [00:04<03:33,  3.21it/s]Training (remove=16):   2%|▏         | 14/700 [00:04<03:33,  3.22it/s]Training (remove=16):   2%|▏         | 15/700 [00:04<03:33,  3.21it/s]Training (remove=16):   2%|▏         | 16/700 [00:04<03:32,  3.22it/s]Training (remove=16):   2%|▏         | 17/700 [00:05<03:31,  3.22it/s]Training (remove=16):   3%|▎         | 18/700 [00:05<03:31,  3.22it/s]Training (remove=16):   3%|▎         | 19/700 [00:05<03:31,  3.22it/s]Training (remove=16):   3%|▎         | 20/700 [00:06<03:31,  3.22it/s]Training (remove=16):   3%|▎         | 21/700 [00:06<03:30,  3.22it/s]Training (remove=16):   3%|▎         | 22/700 [00:06<03:30,  3.23it/s]Training (remove=16):   3%|▎         | 23/700 [00:07<03:29,  3.23it/s]Training (remove=16):   3%|▎         | 24/700 [00:07<03:29,  3.22it/s]Training (remove=16):   4%|▎         | 25/700 [00:07<03:29,  3.23it/s]Training (remove=16):   4%|▎         | 26/700 [00:08<03:29,  3.22it/s]Training (remove=16):   4%|▍         | 27/700 [00:08<03:28,  3.22it/s]Training (remove=16):   4%|▍         | 28/700 [00:08<03:28,  3.22it/s]Training (remove=16):   4%|▍         | 29/700 [00:09<03:28,  3.22it/s]Training (remove=16):   4%|▍         | 30/700 [00:09<03:27,  3.22it/s]Training (remove=16):   4%|▍         | 31/700 [00:09<03:27,  3.23it/s]Training (remove=16):   5%|▍         | 32/700 [00:09<03:26,  3.23it/s]Training (remove=16):   5%|▍         | 33/700 [00:10<03:26,  3.23it/s]Training (remove=16):   5%|▍         | 34/700 [00:10<03:26,  3.23it/s]Training (remove=16):   5%|▌         | 35/700 [00:10<03:25,  3.23it/s]Training (remove=16):   5%|▌         | 36/700 [00:11<03:25,  3.23it/s]Training (remove=16):   5%|▌         | 37/700 [00:11<03:25,  3.23it/s]Training (remove=16):   5%|▌         | 38/700 [00:11<03:25,  3.22it/s]Training (remove=16):   6%|▌         | 39/700 [00:12<03:25,  3.22it/s]Training (remove=16):   6%|▌         | 40/700 [00:12<03:25,  3.22it/s]Training (remove=16):   6%|▌         | 41/700 [00:12<03:25,  3.21it/s]Training (remove=16):   6%|▌         | 42/700 [00:13<03:24,  3.22it/s]Training (remove=16):   6%|▌         | 43/700 [00:13<03:23,  3.22it/s]Training (remove=16):   6%|▋         | 44/700 [00:13<03:23,  3.22it/s]Training (remove=16):   6%|▋         | 45/700 [00:13<03:23,  3.22it/s]Training (remove=16):   7%|▋         | 46/700 [00:14<03:22,  3.22it/s]Training (remove=16):   7%|▋         | 47/700 [00:14<03:22,  3.22it/s]Training (remove=16):   7%|▋         | 48/700 [00:14<03:22,  3.22it/s]Training (remove=16):   7%|▋         | 49/700 [00:15<03:21,  3.23it/s]Training (remove=16):   7%|▋         | 50/700 [00:15<03:21,  3.22it/s]Training (remove=16):   7%|▋         | 51/700 [00:15<03:21,  3.23it/s]Training (remove=16):   7%|▋         | 52/700 [00:16<03:21,  3.22it/s]Training (remove=16):   8%|▊         | 53/700 [00:16<03:20,  3.22it/s]Training (remove=16):   8%|▊         | 54/700 [00:16<03:20,  3.22it/s]Training (remove=16):   8%|▊         | 55/700 [00:17<03:20,  3.22it/s]Training (remove=16):   8%|▊         | 56/700 [00:17<03:20,  3.22it/s]Training (remove=16):   8%|▊         | 57/700 [00:17<03:19,  3.22it/s]Training (remove=16):   8%|▊         | 58/700 [00:17<03:19,  3.22it/s]Training (remove=16):   8%|▊         | 59/700 [00:18<03:19,  3.22it/s]Training (remove=16):   9%|▊         | 60/700 [00:18<03:18,  3.22it/s]Training (remove=16):   9%|▊         | 61/700 [00:18<03:18,  3.23it/s]Training (remove=16):   9%|▉         | 62/700 [00:19<03:17,  3.23it/s]Training (remove=16):   9%|▉         | 63/700 [00:19<03:17,  3.22it/s]Training (remove=16):   9%|▉         | 64/700 [00:19<03:17,  3.22it/s]Training (remove=16):   9%|▉         | 65/700 [00:20<03:17,  3.22it/s]Training (remove=16):   9%|▉         | 66/700 [00:20<03:16,  3.22it/s]Training (remove=16):  10%|▉         | 67/700 [00:20<03:16,  3.22it/s]Training (remove=16):  10%|▉         | 68/700 [00:21<03:16,  3.22it/s]Training (remove=16):  10%|▉         | 69/700 [00:21<03:15,  3.22it/s]Training (remove=16):  10%|█         | 70/700 [00:21<03:15,  3.22it/s]Training (remove=16):  10%|█         | 71/700 [00:22<03:15,  3.22it/s]Training (remove=16):  10%|█         | 72/700 [00:22<03:14,  3.22it/s]Training (remove=16):  10%|█         | 73/700 [00:22<03:14,  3.22it/s]Training (remove=16):  11%|█         | 74/700 [00:22<03:13,  3.23it/s]Training (remove=16):  11%|█         | 75/700 [00:23<03:13,  3.23it/s]Training (remove=16):  11%|█         | 76/700 [00:23<03:13,  3.23it/s]Training (remove=16):  11%|█         | 77/700 [00:23<03:13,  3.22it/s]Training (remove=16):  11%|█         | 78/700 [00:24<03:13,  3.22it/s]Training (remove=16):  11%|█▏        | 79/700 [00:24<03:13,  3.22it/s]Training (remove=16):  11%|█▏        | 80/700 [00:24<03:12,  3.22it/s]Training (remove=16):  12%|█▏        | 81/700 [00:25<03:11,  3.23it/s]Training (remove=16):  12%|█▏        | 82/700 [00:25<03:11,  3.22it/s]Training (remove=16):  12%|█▏        | 83/700 [00:25<03:11,  3.22it/s]Training (remove=16):  12%|█▏        | 84/700 [00:26<03:11,  3.22it/s]Training (remove=16):  12%|█▏        | 85/700 [00:26<03:11,  3.22it/s]Training (remove=16):  12%|█▏        | 86/700 [00:26<03:10,  3.22it/s]Training (remove=16):  12%|█▏        | 87/700 [00:26<03:09,  3.23it/s]Training (remove=16):  13%|█▎        | 88/700 [00:27<03:09,  3.23it/s]Training (remove=16):  13%|█▎        | 89/700 [00:27<03:09,  3.22it/s]Training (remove=16):  13%|█▎        | 90/700 [00:27<03:09,  3.22it/s]Training (remove=16):  13%|█▎        | 91/700 [00:28<03:09,  3.22it/s]Training (remove=16):  13%|█▎        | 92/700 [00:28<03:09,  3.21it/s]Training (remove=16):  13%|█▎        | 93/700 [00:28<03:08,  3.21it/s]Training (remove=16):  13%|█▎        | 94/700 [00:29<03:08,  3.22it/s]Training (remove=16):  14%|█▎        | 95/700 [00:29<03:07,  3.22it/s]Training (remove=16):  14%|█▎        | 96/700 [00:29<03:07,  3.23it/s]Training (remove=16):  14%|█▍        | 97/700 [00:30<03:06,  3.23it/s]Training (remove=16):  14%|█▍        | 98/700 [00:30<03:06,  3.23it/s]Training (remove=16):  14%|█▍        | 99/700 [00:30<03:06,  3.23it/s]Training (remove=16):  14%|█▍        | 100/700 [00:31<03:05,  3.23it/s]Training (remove=16):  14%|█▍        | 101/700 [00:31<03:05,  3.23it/s]Training (remove=16):  15%|█▍        | 102/700 [00:31<03:04,  3.23it/s]Training (remove=16):  15%|█▍        | 103/700 [00:31<03:04,  3.23it/s]Training (remove=16):  15%|█▍        | 104/700 [00:32<03:04,  3.23it/s]Training (remove=16):  15%|█▌        | 105/700 [00:32<03:04,  3.23it/s]Training (remove=16):  15%|█▌        | 106/700 [00:32<03:04,  3.23it/s]Training (remove=16):  15%|█▌        | 107/700 [00:33<03:03,  3.22it/s]Training (remove=16):  15%|█▌        | 108/700 [00:33<03:03,  3.22it/s]Training (remove=16):  16%|█▌        | 109/700 [00:33<03:03,  3.21it/s]Training (remove=16):  16%|█▌        | 110/700 [00:34<03:03,  3.21it/s]Training (remove=16):  16%|█▌        | 111/700 [00:34<03:03,  3.21it/s]Training (remove=16):  16%|█▌        | 112/700 [00:34<03:02,  3.22it/s]Training (remove=16):  16%|█▌        | 113/700 [00:35<03:02,  3.21it/s]Training (remove=16):  16%|█▋        | 114/700 [00:35<03:02,  3.22it/s]Training (remove=16):  16%|█▋        | 115/700 [00:35<03:01,  3.22it/s]Training (remove=16):  17%|█▋        | 116/700 [00:35<03:01,  3.22it/s]Training (remove=16):  17%|█▋        | 117/700 [00:36<03:01,  3.21it/s]Training (remove=16):  17%|█▋        | 118/700 [00:36<03:00,  3.22it/s]Training (remove=16):  17%|█▋        | 119/700 [00:36<03:00,  3.22it/s]Training (remove=16):  17%|█▋        | 120/700 [00:37<02:59,  3.23it/s]Training (remove=16):  17%|█▋        | 121/700 [00:37<02:59,  3.23it/s]Training (remove=16):  17%|█▋        | 122/700 [00:37<02:59,  3.22it/s]Training (remove=16):  18%|█▊        | 123/700 [00:38<02:59,  3.22it/s]Training (remove=16):  18%|█▊        | 124/700 [00:38<02:58,  3.22it/s]Training (remove=16):  18%|█▊        | 125/700 [00:38<02:58,  3.22it/s]Training (remove=16):  18%|█▊        | 126/700 [00:39<02:58,  3.22it/s]Training (remove=16):  18%|█▊        | 127/700 [00:39<02:58,  3.22it/s]Training (remove=16):  18%|█▊        | 128/700 [00:39<02:57,  3.22it/s]Training (remove=16):  18%|█▊        | 129/700 [00:40<02:57,  3.22it/s]Training (remove=16):  19%|█▊        | 130/700 [00:40<02:56,  3.23it/s]Training (remove=16):  19%|█▊        | 131/700 [00:40<02:56,  3.22it/s]Training (remove=16):  19%|█▉        | 132/700 [00:40<02:56,  3.23it/s]Training (remove=16):  19%|█▉        | 133/700 [00:41<02:56,  3.22it/s]Training (remove=16):  19%|█▉        | 134/700 [00:41<02:55,  3.22it/s]Training (remove=16):  19%|█▉        | 135/700 [00:41<02:55,  3.22it/s]Training (remove=16):  19%|█▉        | 136/700 [00:42<02:55,  3.21it/s]Training (remove=16):  20%|█▉        | 137/700 [00:42<02:55,  3.21it/s]Training (remove=16):  20%|█▉        | 138/700 [00:42<02:55,  3.21it/s]Training (remove=16):  20%|█▉        | 139/700 [00:43<02:54,  3.21it/s]Training (remove=16):  20%|██        | 140/700 [00:43<02:54,  3.21it/s]Training (remove=16):  20%|██        | 141/700 [00:43<02:54,  3.21it/s]Training (remove=16):  20%|██        | 142/700 [00:44<02:53,  3.21it/s]Training (remove=16):  20%|██        | 143/700 [00:44<02:53,  3.22it/s]Training (remove=16):  21%|██        | 144/700 [00:44<02:52,  3.22it/s]Training (remove=16):  21%|██        | 145/700 [00:45<02:52,  3.22it/s]Training (remove=16):  21%|██        | 146/700 [00:45<02:51,  3.23it/s]Training (remove=16):  21%|██        | 147/700 [00:45<02:51,  3.23it/s]Training (remove=16):  21%|██        | 148/700 [00:45<02:51,  3.22it/s]Training (remove=16):  21%|██▏       | 149/700 [00:46<02:50,  3.22it/s]Training (remove=16):  21%|██▏       | 150/700 [00:46<02:50,  3.23it/s]Training (remove=16):  22%|██▏       | 151/700 [00:46<02:49,  3.23it/s]Training (remove=16):  22%|██▏       | 152/700 [00:47<02:49,  3.23it/s]Training (remove=16):  22%|██▏       | 153/700 [00:47<02:49,  3.23it/s]Training (remove=16):  22%|██▏       | 154/700 [00:47<02:48,  3.23it/s]Training (remove=16):  22%|██▏       | 155/700 [00:48<02:48,  3.23it/s]Training (remove=16):  22%|██▏       | 156/700 [00:48<02:48,  3.22it/s]Training (remove=16):  22%|██▏       | 157/700 [00:48<02:48,  3.22it/s]Training (remove=16):  23%|██▎       | 158/700 [00:49<02:48,  3.22it/s]Training (remove=16):  23%|██▎       | 159/700 [00:49<02:47,  3.23it/s]Training (remove=16):  23%|██▎       | 160/700 [00:49<02:47,  3.22it/s]Training (remove=16):  23%|██▎       | 161/700 [00:49<02:47,  3.22it/s]Training (remove=16):  23%|██▎       | 162/700 [00:50<02:47,  3.22it/s]Training (remove=16):  23%|██▎       | 163/700 [00:50<02:46,  3.22it/s]Training (remove=16):  23%|██▎       | 164/700 [00:50<02:46,  3.23it/s]Training (remove=16):  24%|██▎       | 165/700 [00:51<02:46,  3.22it/s]Training (remove=16):  24%|██▎       | 166/700 [00:51<02:45,  3.23it/s]Training (remove=16):  24%|██▍       | 167/700 [00:51<02:45,  3.22it/s]Training (remove=16):  24%|██▍       | 168/700 [00:52<02:44,  3.22it/s]Training (remove=16):  24%|██▍       | 169/700 [00:52<02:44,  3.23it/s]Training (remove=16):  24%|██▍       | 170/700 [00:52<02:44,  3.22it/s]Training (remove=16):  24%|██▍       | 171/700 [00:53<02:44,  3.22it/s]Training (remove=16):  25%|██▍       | 172/700 [00:53<02:44,  3.22it/s]Training (remove=16):  25%|██▍       | 173/700 [00:53<02:43,  3.22it/s]Training (remove=16):  25%|██▍       | 174/700 [00:54<02:43,  3.22it/s]Training (remove=16):  25%|██▌       | 175/700 [00:54<02:43,  3.22it/s]Training (remove=16):  25%|██▌       | 176/700 [00:54<02:43,  3.21it/s]Training (remove=16):  25%|██▌       | 177/700 [00:54<02:42,  3.21it/s]Training (remove=16):  25%|██▌       | 178/700 [00:55<02:42,  3.22it/s]Training (remove=16):  26%|██▌       | 179/700 [00:55<02:42,  3.22it/s]Training (remove=16):  26%|██▌       | 180/700 [00:55<02:41,  3.21it/s]Training (remove=16):  26%|██▌       | 181/700 [00:56<02:41,  3.21it/s]Training (remove=16):  26%|██▌       | 182/700 [00:56<02:40,  3.22it/s]Training (remove=16):  26%|██▌       | 183/700 [00:56<02:40,  3.22it/s]Training (remove=16):  26%|██▋       | 184/700 [00:57<02:40,  3.22it/s]Training (remove=16):  26%|██▋       | 185/700 [00:57<02:40,  3.21it/s]Training (remove=16):  27%|██▋       | 186/700 [00:57<02:39,  3.22it/s]Training (remove=16):  27%|██▋       | 187/700 [00:58<02:39,  3.22it/s]Training (remove=16):  27%|██▋       | 188/700 [00:58<02:38,  3.22it/s]Training (remove=16):  27%|██▋       | 189/700 [00:58<02:38,  3.22it/s]Training (remove=16):  27%|██▋       | 190/700 [00:58<02:38,  3.22it/s]Training (remove=16):  27%|██▋       | 191/700 [00:59<02:58,  2.85it/s]Training (remove=16):  27%|██▋       | 192/700 [00:59<02:52,  2.95it/s]Training (remove=16):  28%|██▊       | 193/700 [01:00<02:47,  3.03it/s]Training (remove=16):  28%|██▊       | 194/700 [01:00<02:43,  3.09it/s]Training (remove=16):  28%|██▊       | 195/700 [01:00<02:41,  3.13it/s]Training (remove=16):  28%|██▊       | 196/700 [01:00<02:39,  3.16it/s]Training (remove=16):  28%|██▊       | 197/700 [01:01<02:38,  3.18it/s]Training (remove=16):  28%|██▊       | 198/700 [01:01<02:37,  3.19it/s]Training (remove=16):  28%|██▊       | 199/700 [01:01<02:36,  3.19it/s]Training (remove=16):  29%|██▊       | 200/700 [01:02<02:36,  3.20it/s]Training (remove=16):  29%|██▊       | 201/700 [01:02<02:35,  3.21it/s]Training (remove=16):  29%|██▉       | 202/700 [01:02<02:34,  3.22it/s]Training (remove=16):  29%|██▉       | 203/700 [01:03<02:34,  3.22it/s]Training (remove=16):  29%|██▉       | 204/700 [01:03<02:34,  3.21it/s]Training (remove=16):  29%|██▉       | 205/700 [01:03<02:34,  3.21it/s]Training (remove=16):  29%|██▉       | 206/700 [01:04<02:33,  3.21it/s]Training (remove=16):  30%|██▉       | 207/700 [01:04<02:33,  3.21it/s]Training (remove=16):  30%|██▉       | 208/700 [01:04<02:32,  3.22it/s]Training (remove=16):  30%|██▉       | 209/700 [01:05<02:32,  3.22it/s]Training (remove=16):  30%|███       | 210/700 [01:05<02:32,  3.22it/s]Training (remove=16):  30%|███       | 211/700 [01:05<02:31,  3.22it/s]Training (remove=16):  30%|███       | 212/700 [01:05<02:31,  3.22it/s]Training (remove=16):  30%|███       | 213/700 [01:06<02:31,  3.22it/s]Training (remove=16):  31%|███       | 214/700 [01:06<02:30,  3.22it/s]Training (remove=16):  31%|███       | 215/700 [01:06<02:30,  3.22it/s]Training (remove=16):  31%|███       | 216/700 [01:07<02:30,  3.21it/s]Training (remove=16):  31%|███       | 217/700 [01:07<02:30,  3.21it/s]Training (remove=16):  31%|███       | 218/700 [01:07<02:29,  3.22it/s]Training (remove=16):  31%|███▏      | 219/700 [01:08<02:29,  3.22it/s]Training (remove=16):  31%|███▏      | 220/700 [01:08<02:29,  3.22it/s]Training (remove=16):  32%|███▏      | 221/700 [01:08<02:28,  3.22it/s]Training (remove=16):  32%|███▏      | 222/700 [01:09<02:28,  3.22it/s]Training (remove=16):  32%|███▏      | 223/700 [01:09<02:27,  3.23it/s]Training (remove=16):  32%|███▏      | 224/700 [01:09<02:27,  3.22it/s]Training (remove=16):  32%|███▏      | 225/700 [01:09<02:27,  3.21it/s]Training (remove=16):  32%|███▏      | 226/700 [01:10<02:27,  3.21it/s]Training (remove=16):  32%|███▏      | 227/700 [01:10<02:27,  3.21it/s]Training (remove=16):  33%|███▎      | 228/700 [01:10<02:26,  3.21it/s]Training (remove=16):  33%|███▎      | 229/700 [01:11<02:26,  3.21it/s]Training (remove=16):  33%|███▎      | 230/700 [01:11<02:26,  3.21it/s]Training (remove=16):  33%|███▎      | 231/700 [01:11<02:25,  3.22it/s]Training (remove=16):  33%|███▎      | 232/700 [01:12<02:25,  3.21it/s]Training (remove=16):  33%|███▎      | 233/700 [01:12<02:25,  3.22it/s]Training (remove=16):  33%|███▎      | 234/700 [01:12<02:24,  3.22it/s]Training (remove=16):  34%|███▎      | 235/700 [01:13<02:24,  3.22it/s]Training (remove=16):  34%|███▎      | 236/700 [01:13<02:24,  3.22it/s]Training (remove=16):  34%|███▍      | 237/700 [01:13<02:23,  3.22it/s]Training (remove=16):  34%|███▍      | 238/700 [01:14<02:23,  3.22it/s]Training (remove=16):  34%|███▍      | 239/700 [01:14<02:23,  3.22it/s]Training (remove=16):  34%|███▍      | 240/700 [01:14<02:22,  3.22it/s]Training (remove=16):  34%|███▍      | 241/700 [01:14<02:22,  3.23it/s]Training (remove=16):  35%|███▍      | 242/700 [01:15<02:21,  3.23it/s]Training (remove=16):  35%|███▍      | 243/700 [01:15<02:21,  3.22it/s]Training (remove=16):  35%|███▍      | 244/700 [01:15<02:21,  3.23it/s]Training (remove=16):  35%|███▌      | 245/700 [01:16<02:21,  3.22it/s]Training (remove=16):  35%|███▌      | 246/700 [01:16<02:21,  3.21it/s]Training (remove=16):  35%|███▌      | 247/700 [01:16<02:20,  3.22it/s]Training (remove=16):  35%|███▌      | 248/700 [01:17<02:20,  3.21it/s]Training (remove=16):  36%|███▌      | 249/700 [01:17<02:20,  3.22it/s]Training (remove=16):  36%|███▌      | 250/700 [01:17<02:19,  3.22it/s]Training (remove=16):  36%|███▌      | 251/700 [01:18<02:19,  3.22it/s]Training (remove=16):  36%|███▌      | 252/700 [01:18<02:19,  3.22it/s]Training (remove=16):  36%|███▌      | 253/700 [01:18<02:18,  3.22it/s]Training (remove=16):  36%|███▋      | 254/700 [01:18<02:18,  3.22it/s]Training (remove=16):  36%|███▋      | 255/700 [01:19<02:17,  3.23it/s]Training (remove=16):  37%|███▋      | 256/700 [01:19<02:17,  3.23it/s]Training (remove=16):  37%|███▋      | 257/700 [01:19<02:17,  3.23it/s]Training (remove=16):  37%|███▋      | 258/700 [01:20<02:16,  3.23it/s]Training (remove=16):  37%|███▋      | 259/700 [01:20<02:16,  3.23it/s]Training (remove=16):  37%|███▋      | 260/700 [01:20<02:16,  3.23it/s]Training (remove=16):  37%|███▋      | 261/700 [01:21<02:16,  3.23it/s]Training (remove=16):  37%|███▋      | 262/700 [01:21<02:15,  3.23it/s]Training (remove=16):  38%|███▊      | 263/700 [01:21<02:15,  3.23it/s]Training (remove=16):  38%|███▊      | 264/700 [01:22<02:14,  3.23it/s]Training (remove=16):  38%|███▊      | 265/700 [01:22<02:14,  3.22it/s]Training (remove=16):  38%|███▊      | 266/700 [01:22<02:14,  3.22it/s]Training (remove=16):  38%|███▊      | 267/700 [01:23<02:14,  3.23it/s]Training (remove=16):  38%|███▊      | 268/700 [01:23<02:13,  3.23it/s]Training (remove=16):  38%|███▊      | 269/700 [01:23<02:13,  3.22it/s]Training (remove=16):  39%|███▊      | 270/700 [01:23<02:13,  3.23it/s]Training (remove=16):  39%|███▊      | 271/700 [01:24<02:12,  3.23it/s]Training (remove=16):  39%|███▉      | 272/700 [01:24<02:12,  3.23it/s]Training (remove=16):  39%|███▉      | 273/700 [01:24<02:12,  3.23it/s]Training (remove=16):  39%|███▉      | 274/700 [01:25<02:12,  3.23it/s]Training (remove=16):  39%|███▉      | 275/700 [01:25<02:11,  3.23it/s]Training (remove=16):  39%|███▉      | 276/700 [01:25<02:11,  3.22it/s]Training (remove=16):  40%|███▉      | 277/700 [01:26<02:11,  3.22it/s]Training (remove=16):  40%|███▉      | 278/700 [01:26<02:11,  3.22it/s]Training (remove=16):  40%|███▉      | 279/700 [01:26<02:10,  3.22it/s]Training (remove=16):  40%|████      | 280/700 [01:27<02:10,  3.22it/s]Training (remove=16):  40%|████      | 281/700 [01:27<02:09,  3.22it/s]Training (remove=16):  40%|████      | 282/700 [01:27<02:10,  3.21it/s]Training (remove=16):  40%|████      | 283/700 [01:27<02:09,  3.22it/s]Training (remove=16):  41%|████      | 284/700 [01:28<02:09,  3.22it/s]Training (remove=16):  41%|████      | 285/700 [01:28<02:09,  3.22it/s]Training (remove=16):  41%|████      | 286/700 [01:28<02:08,  3.22it/s]Training (remove=16):  41%|████      | 287/700 [01:29<02:08,  3.22it/s]Training (remove=16):  41%|████      | 288/700 [01:29<02:08,  3.21it/s]Training (remove=16):  41%|████▏     | 289/700 [01:29<02:07,  3.22it/s]Training (remove=16):  41%|████▏     | 290/700 [01:30<02:07,  3.21it/s]Training (remove=16):  42%|████▏     | 291/700 [01:30<02:07,  3.21it/s]Training (remove=16):  42%|████▏     | 292/700 [01:30<02:06,  3.22it/s]Training (remove=16):  42%|████▏     | 293/700 [01:31<02:06,  3.21it/s]Training (remove=16):  42%|████▏     | 294/700 [01:31<02:06,  3.21it/s]Training (remove=16):  42%|████▏     | 295/700 [01:31<02:05,  3.22it/s]Training (remove=16):  42%|████▏     | 296/700 [01:32<02:05,  3.22it/s]Training (remove=16):  42%|████▏     | 297/700 [01:32<02:04,  3.23it/s]Training (remove=16):  43%|████▎     | 298/700 [01:32<02:04,  3.23it/s]Training (remove=16):  43%|████▎     | 299/700 [01:32<02:04,  3.23it/s]Training (remove=16):  43%|████▎     | 300/700 [01:33<02:03,  3.23it/s]Training (remove=16):  43%|████▎     | 301/700 [01:33<02:03,  3.23it/s]Training (remove=16):  43%|████▎     | 302/700 [01:33<02:03,  3.22it/s]Training (remove=16):  43%|████▎     | 303/700 [01:34<02:03,  3.22it/s]Training (remove=16):  43%|████▎     | 304/700 [01:34<02:03,  3.22it/s]Training (remove=16):  44%|████▎     | 305/700 [01:34<02:02,  3.22it/s]Training (remove=16):  44%|████▎     | 306/700 [01:35<02:02,  3.22it/s]Training (remove=16):  44%|████▍     | 307/700 [01:35<02:01,  3.22it/s]Training (remove=16):  44%|████▍     | 308/700 [01:35<02:01,  3.22it/s]Training (remove=16):  44%|████▍     | 309/700 [01:36<02:01,  3.22it/s]Training (remove=16):  44%|████▍     | 310/700 [01:36<02:01,  3.21it/s]Training (remove=16):  44%|████▍     | 311/700 [01:36<02:01,  3.21it/s]Training (remove=16):  45%|████▍     | 312/700 [01:36<02:00,  3.21it/s]Training (remove=16):  45%|████▍     | 313/700 [01:37<02:00,  3.21it/s]Training (remove=16):  45%|████▍     | 314/700 [01:37<02:00,  3.21it/s]Training (remove=16):  45%|████▌     | 315/700 [01:37<01:59,  3.21it/s]Training (remove=16):  45%|████▌     | 316/700 [01:38<01:59,  3.22it/s]Training (remove=16):  45%|████▌     | 317/700 [01:38<01:59,  3.22it/s]Training (remove=16):  45%|████▌     | 318/700 [01:38<01:58,  3.22it/s]Training (remove=16):  46%|████▌     | 319/700 [01:39<01:58,  3.22it/s]Training (remove=16):  46%|████▌     | 320/700 [01:39<01:57,  3.22it/s]Training (remove=16):  46%|████▌     | 321/700 [01:39<01:57,  3.22it/s]Training (remove=16):  46%|████▌     | 322/700 [01:40<01:57,  3.22it/s]Training (remove=16):  46%|████▌     | 323/700 [01:40<01:57,  3.22it/s]Training (remove=16):  46%|████▋     | 324/700 [01:40<01:56,  3.22it/s]Training (remove=16):  46%|████▋     | 325/700 [01:41<01:56,  3.22it/s]Training (remove=16):  47%|████▋     | 326/700 [01:41<01:55,  3.23it/s]Training (remove=16):  47%|████▋     | 327/700 [01:41<01:55,  3.22it/s]Training (remove=16):  47%|████▋     | 328/700 [01:41<01:55,  3.22it/s]Training (remove=16):  47%|████▋     | 329/700 [01:42<01:55,  3.22it/s]Training (remove=16):  47%|████▋     | 330/700 [01:42<01:54,  3.22it/s]Training (remove=16):  47%|████▋     | 331/700 [01:42<01:54,  3.23it/s]Training (remove=16):  47%|████▋     | 332/700 [01:43<01:54,  3.23it/s]Training (remove=16):  48%|████▊     | 333/700 [01:43<01:53,  3.22it/s]Training (remove=16):  48%|████▊     | 334/700 [01:43<01:53,  3.22it/s]Training (remove=16):  48%|████▊     | 335/700 [01:44<01:53,  3.22it/s]Training (remove=16):  48%|████▊     | 336/700 [01:44<01:53,  3.21it/s]Training (remove=16):  48%|████▊     | 337/700 [01:44<01:52,  3.21it/s]Training (remove=16):  48%|████▊     | 338/700 [01:45<01:52,  3.22it/s]Training (remove=16):  48%|████▊     | 339/700 [01:45<01:52,  3.21it/s]Training (remove=16):  49%|████▊     | 340/700 [01:45<01:52,  3.21it/s]Training (remove=16):  49%|████▊     | 341/700 [01:46<01:51,  3.21it/s]Training (remove=16):  49%|████▉     | 342/700 [01:46<01:51,  3.22it/s]Training (remove=16):  49%|████▉     | 343/700 [01:46<01:51,  3.21it/s]Training (remove=16):  49%|████▉     | 344/700 [01:46<01:50,  3.22it/s]Training (remove=16):  49%|████▉     | 345/700 [01:47<01:50,  3.21it/s]Training (remove=16):  49%|████▉     | 346/700 [01:47<01:49,  3.22it/s]Training (remove=16):  50%|████▉     | 347/700 [01:47<01:49,  3.22it/s]Training (remove=16):  50%|████▉     | 348/700 [01:48<01:49,  3.22it/s]Training (remove=16):  50%|████▉     | 349/700 [01:48<01:49,  3.22it/s]Training (remove=16):  50%|█████     | 350/700 [01:48<01:48,  3.22it/s]Training (remove=16):  50%|█████     | 351/700 [01:49<01:48,  3.22it/s]Training (remove=16):  50%|█████     | 352/700 [01:49<01:47,  3.23it/s]Training (remove=16):  50%|█████     | 353/700 [01:49<01:47,  3.23it/s]Training (remove=16):  51%|█████     | 354/700 [01:50<01:47,  3.23it/s]Training (remove=16):  51%|█████     | 355/700 [01:50<01:46,  3.23it/s]Training (remove=16):  51%|█████     | 356/700 [01:50<01:46,  3.22it/s]Training (remove=16):  51%|█████     | 357/700 [01:50<01:46,  3.23it/s]Training (remove=16):  51%|█████     | 358/700 [01:51<01:45,  3.23it/s]Training (remove=16):  51%|█████▏    | 359/700 [01:51<01:45,  3.22it/s]Training (remove=16):  51%|█████▏    | 360/700 [01:51<01:45,  3.22it/s]Training (remove=16):  52%|█████▏    | 361/700 [01:52<01:45,  3.22it/s]Training (remove=16):  52%|█████▏    | 362/700 [01:52<01:45,  3.22it/s]Training (remove=16):  52%|█████▏    | 363/700 [01:52<01:44,  3.22it/s]Training (remove=16):  52%|█████▏    | 364/700 [01:53<01:44,  3.22it/s]Training (remove=16):  52%|█████▏    | 365/700 [01:53<01:44,  3.22it/s]Training (remove=16):  52%|█████▏    | 366/700 [01:53<01:43,  3.21it/s]Training (remove=16):  52%|█████▏    | 367/700 [01:54<01:43,  3.22it/s]Training (remove=16):  53%|█████▎    | 368/700 [01:54<01:43,  3.22it/s]Training (remove=16):  53%|█████▎    | 369/700 [01:54<01:42,  3.23it/s]Training (remove=16):  53%|█████▎    | 370/700 [01:55<01:42,  3.22it/s]Training (remove=16):  53%|█████▎    | 371/700 [01:55<01:42,  3.22it/s]Training (remove=16):  53%|█████▎    | 372/700 [01:55<01:42,  3.21it/s]Training (remove=16):  53%|█████▎    | 373/700 [01:55<01:41,  3.21it/s]Training (remove=16):  53%|█████▎    | 374/700 [01:56<01:41,  3.21it/s]Training (remove=16):  54%|█████▎    | 375/700 [01:56<01:40,  3.22it/s]Training (remove=16):  54%|█████▎    | 376/700 [01:56<01:40,  3.22it/s]Training (remove=16):  54%|█████▍    | 377/700 [01:57<01:40,  3.21it/s]Training (remove=16):  54%|█████▍    | 378/700 [01:57<01:40,  3.21it/s]Training (remove=16):  54%|█████▍    | 379/700 [01:57<01:40,  3.21it/s]Training (remove=16):  54%|█████▍    | 380/700 [01:58<01:39,  3.21it/s]Training (remove=16):  54%|█████▍    | 381/700 [01:58<01:39,  3.21it/s]Training (remove=16):  55%|█████▍    | 382/700 [01:58<01:39,  3.21it/s]Training (remove=16):  55%|█████▍    | 383/700 [01:59<01:38,  3.22it/s]Training (remove=16):  55%|█████▍    | 384/700 [01:59<01:38,  3.21it/s]Training (remove=16):  55%|█████▌    | 385/700 [01:59<01:37,  3.22it/s]Training (remove=16):  55%|█████▌    | 386/700 [01:59<01:37,  3.21it/s]Training (remove=16):  55%|█████▌    | 387/700 [02:00<01:37,  3.22it/s]Training (remove=16):  55%|█████▌    | 388/700 [02:00<01:36,  3.22it/s]Training (remove=16):  56%|█████▌    | 389/700 [02:00<01:36,  3.22it/s]Training (remove=16):  56%|█████▌    | 390/700 [02:01<01:36,  3.22it/s]Training (remove=16):  56%|█████▌    | 391/700 [02:01<01:35,  3.22it/s]Training (remove=16):  56%|█████▌    | 392/700 [02:01<01:35,  3.21it/s]Training (remove=16):  56%|█████▌    | 393/700 [02:02<01:35,  3.21it/s]Training (remove=16):  56%|█████▋    | 394/700 [02:02<01:35,  3.22it/s]Training (remove=16):  56%|█████▋    | 395/700 [02:02<01:34,  3.22it/s]Training (remove=16):  57%|█████▋    | 396/700 [02:03<01:34,  3.22it/s]Training (remove=16):  57%|█████▋    | 397/700 [02:03<01:34,  3.22it/s]Training (remove=16):  57%|█████▋    | 398/700 [02:03<01:33,  3.22it/s]Training (remove=16):  57%|█████▋    | 399/700 [02:04<01:33,  3.22it/s]Training (remove=16):  57%|█████▋    | 400/700 [02:04<01:33,  3.22it/s]Training (remove=16):  57%|█████▋    | 401/700 [02:04<01:32,  3.22it/s]Training (remove=16):  57%|█████▋    | 402/700 [02:04<01:32,  3.21it/s]Training (remove=16):  58%|█████▊    | 403/700 [02:05<01:32,  3.21it/s]Training (remove=16):  58%|█████▊    | 404/700 [02:05<01:31,  3.22it/s]Training (remove=16):  58%|█████▊    | 405/700 [02:05<01:31,  3.22it/s]Training (remove=16):  58%|█████▊    | 406/700 [02:06<01:31,  3.22it/s]Training (remove=16):  58%|█████▊    | 407/700 [02:06<01:31,  3.22it/s]Training (remove=16):  58%|█████▊    | 408/700 [02:06<01:30,  3.22it/s]Training (remove=16):  58%|█████▊    | 409/700 [02:07<01:30,  3.22it/s]Training (remove=16):  59%|█████▊    | 410/700 [02:07<01:30,  3.21it/s]Training (remove=16):  59%|█████▊    | 411/700 [02:07<01:30,  3.21it/s]Training (remove=16):  59%|█████▉    | 412/700 [02:08<01:29,  3.21it/s]Training (remove=16):  59%|█████▉    | 413/700 [02:08<01:29,  3.22it/s]Training (remove=16):  59%|█████▉    | 414/700 [02:08<01:28,  3.22it/s]Training (remove=16):  59%|█████▉    | 415/700 [02:08<01:28,  3.22it/s]Training (remove=16):  59%|█████▉    | 416/700 [02:09<01:28,  3.22it/s]Training (remove=16):  60%|█████▉    | 417/700 [02:09<01:27,  3.22it/s]Training (remove=16):  60%|█████▉    | 418/700 [02:09<01:27,  3.23it/s]Training (remove=16):  60%|█████▉    | 419/700 [02:10<01:27,  3.23it/s]Training (remove=16):  60%|██████    | 420/700 [02:10<01:26,  3.23it/s]Training (remove=16):  60%|██████    | 421/700 [02:10<01:26,  3.22it/s]Training (remove=16):  60%|██████    | 422/700 [02:11<01:26,  3.22it/s]Training (remove=16):  60%|██████    | 423/700 [02:11<01:26,  3.22it/s]Training (remove=16):  61%|██████    | 424/700 [02:11<01:25,  3.22it/s]Training (remove=16):  61%|██████    | 425/700 [02:12<01:25,  3.22it/s]Training (remove=16):  61%|██████    | 426/700 [02:12<01:25,  3.22it/s]Training (remove=16):  61%|██████    | 427/700 [02:12<01:24,  3.22it/s]Training (remove=16):  61%|██████    | 428/700 [02:13<01:24,  3.21it/s]Training (remove=16):  61%|██████▏   | 429/700 [02:13<01:24,  3.22it/s]Training (remove=16):  61%|██████▏   | 430/700 [02:13<01:23,  3.22it/s]Training (remove=16):  62%|██████▏   | 431/700 [02:13<01:23,  3.22it/s]Training (remove=16):  62%|██████▏   | 432/700 [02:14<01:23,  3.22it/s]Training (remove=16):  62%|██████▏   | 433/700 [02:14<01:22,  3.22it/s]Training (remove=16):  62%|██████▏   | 434/700 [02:14<01:22,  3.23it/s]Training (remove=16):  62%|██████▏   | 435/700 [02:15<01:22,  3.22it/s]Training (remove=16):  62%|██████▏   | 436/700 [02:15<01:21,  3.22it/s]Training (remove=16):  62%|██████▏   | 437/700 [02:15<01:21,  3.22it/s]Training (remove=16):  63%|██████▎   | 438/700 [02:16<01:21,  3.22it/s]Training (remove=16):  63%|██████▎   | 439/700 [02:16<01:20,  3.22it/s]Training (remove=16):  63%|██████▎   | 440/700 [02:16<01:20,  3.22it/s]Training (remove=16):  63%|██████▎   | 441/700 [02:17<01:20,  3.23it/s]Training (remove=16):  63%|██████▎   | 442/700 [02:17<01:19,  3.23it/s]Training (remove=16):  63%|██████▎   | 443/700 [02:17<01:19,  3.23it/s]Training (remove=16):  63%|██████▎   | 444/700 [02:18<01:19,  3.22it/s]Training (remove=16):  64%|██████▎   | 445/700 [02:18<01:19,  3.22it/s]Training (remove=16):  64%|██████▎   | 446/700 [02:18<01:18,  3.22it/s]Training (remove=16):  64%|██████▍   | 447/700 [02:18<01:18,  3.22it/s]Training (remove=16):  64%|██████▍   | 448/700 [02:19<01:18,  3.22it/s]Training (remove=16):  64%|██████▍   | 449/700 [02:19<01:17,  3.22it/s]Training (remove=16):  64%|██████▍   | 450/700 [02:19<01:17,  3.22it/s]Training (remove=16):  64%|██████▍   | 451/700 [02:20<01:17,  3.22it/s]Training (remove=16):  65%|██████▍   | 452/700 [02:20<01:17,  3.21it/s]Training (remove=16):  65%|██████▍   | 453/700 [02:20<01:16,  3.22it/s]Training (remove=16):  65%|██████▍   | 454/700 [02:21<01:16,  3.21it/s]Training (remove=16):  65%|██████▌   | 455/700 [02:21<01:16,  3.21it/s]Training (remove=16):  65%|██████▌   | 456/700 [02:21<01:15,  3.21it/s]Training (remove=16):  65%|██████▌   | 457/700 [02:22<01:15,  3.21it/s]Training (remove=16):  65%|██████▌   | 458/700 [02:22<01:15,  3.22it/s]Training (remove=16):  66%|██████▌   | 459/700 [02:22<01:14,  3.22it/s]Training (remove=16):  66%|██████▌   | 460/700 [02:22<01:14,  3.22it/s]Training (remove=16):  66%|██████▌   | 461/700 [02:23<01:14,  3.22it/s]Training (remove=16):  66%|██████▌   | 462/700 [02:23<01:13,  3.23it/s]Training (remove=16):  66%|██████▌   | 463/700 [02:23<01:13,  3.23it/s]Training (remove=16):  66%|██████▋   | 464/700 [02:24<01:13,  3.23it/s]Training (remove=16):  66%|██████▋   | 465/700 [02:24<01:12,  3.22it/s]Training (remove=16):  67%|██████▋   | 466/700 [02:24<01:12,  3.22it/s]Training (remove=16):  67%|██████▋   | 467/700 [02:25<01:12,  3.22it/s]Training (remove=16):  67%|██████▋   | 468/700 [02:25<01:11,  3.23it/s]Training (remove=16):  67%|██████▋   | 469/700 [02:25<01:11,  3.23it/s]Training (remove=16):  67%|██████▋   | 470/700 [02:26<01:11,  3.22it/s]Training (remove=16):  67%|██████▋   | 471/700 [02:26<01:11,  3.22it/s]Training (remove=16):  67%|██████▋   | 472/700 [02:26<01:10,  3.22it/s]Training (remove=16):  68%|██████▊   | 473/700 [02:27<01:10,  3.22it/s]Training (remove=16):  68%|██████▊   | 474/700 [02:27<01:10,  3.22it/s]Training (remove=16):  68%|██████▊   | 475/700 [02:27<01:09,  3.22it/s]Training (remove=16):  68%|██████▊   | 476/700 [02:27<01:09,  3.22it/s]Training (remove=16):  68%|██████▊   | 477/700 [02:28<01:09,  3.22it/s]Training (remove=16):  68%|██████▊   | 478/700 [02:28<01:08,  3.22it/s]Training (remove=16):  68%|██████▊   | 479/700 [02:28<01:08,  3.23it/s]Training (remove=16):  69%|██████▊   | 480/700 [02:29<01:08,  3.22it/s]Training (remove=16):  69%|██████▊   | 481/700 [02:29<01:08,  3.21it/s]Training (remove=16):  69%|██████▉   | 482/700 [02:29<01:07,  3.22it/s]Training (remove=16):  69%|██████▉   | 483/700 [02:30<01:07,  3.22it/s]Training (remove=16):  69%|██████▉   | 484/700 [02:30<01:07,  3.22it/s]Training (remove=16):  69%|██████▉   | 485/700 [02:30<01:06,  3.22it/s]Training (remove=16):  69%|██████▉   | 486/700 [02:31<01:06,  3.21it/s]Training (remove=16):  70%|██████▉   | 487/700 [02:31<01:06,  3.22it/s]Training (remove=16):  70%|██████▉   | 488/700 [02:31<01:05,  3.22it/s]Training (remove=16):  70%|██████▉   | 489/700 [02:31<01:05,  3.23it/s]Training (remove=16):  70%|███████   | 490/700 [02:32<01:05,  3.23it/s]Training (remove=16):  70%|███████   | 491/700 [02:32<01:04,  3.23it/s]Training (remove=16):  70%|███████   | 492/700 [02:32<01:04,  3.23it/s]Training (remove=16):  70%|███████   | 493/700 [02:33<01:04,  3.22it/s]Training (remove=16):  71%|███████   | 494/700 [02:33<01:03,  3.22it/s]Training (remove=16):  71%|███████   | 495/700 [02:33<01:03,  3.22it/s]Training (remove=16):  71%|███████   | 496/700 [02:34<01:03,  3.22it/s]Training (remove=16):  71%|███████   | 497/700 [02:34<01:02,  3.23it/s]Training (remove=16):  71%|███████   | 498/700 [02:34<01:02,  3.23it/s]Training (remove=16):  71%|███████▏  | 499/700 [02:35<01:02,  3.22it/s]Training (remove=16):  71%|███████▏  | 500/700 [02:35<01:02,  3.22it/s]Training (remove=16):  72%|███████▏  | 501/700 [02:35<01:01,  3.22it/s]Training (remove=16):  72%|███████▏  | 502/700 [02:36<01:01,  3.22it/s]Training (remove=16):  72%|███████▏  | 503/700 [02:36<01:01,  3.22it/s]Training (remove=16):  72%|███████▏  | 504/700 [02:36<01:00,  3.21it/s]Training (remove=16):  72%|███████▏  | 505/700 [02:36<01:00,  3.21it/s]Training (remove=16):  72%|███████▏  | 506/700 [02:37<01:00,  3.22it/s]Training (remove=16):  72%|███████▏  | 507/700 [02:37<01:00,  3.21it/s]Training (remove=16):  73%|███████▎  | 508/700 [02:37<00:59,  3.21it/s]Training (remove=16):  73%|███████▎  | 509/700 [02:38<00:59,  3.21it/s]Training (remove=16):  73%|███████▎  | 510/700 [02:38<00:59,  3.21it/s]Training (remove=16):  73%|███████▎  | 511/700 [02:38<00:58,  3.21it/s]Training (remove=16):  73%|███████▎  | 512/700 [02:39<00:58,  3.21it/s]Training (remove=16):  73%|███████▎  | 513/700 [02:39<00:58,  3.21it/s]Training (remove=16):  73%|███████▎  | 514/700 [02:39<00:57,  3.22it/s]Training (remove=16):  74%|███████▎  | 515/700 [02:40<00:57,  3.22it/s]Training (remove=16):  74%|███████▎  | 516/700 [02:40<00:57,  3.23it/s]Training (remove=16):  74%|███████▍  | 517/700 [02:40<00:56,  3.23it/s]Training (remove=16):  74%|███████▍  | 518/700 [02:40<00:56,  3.22it/s]Training (remove=16):  74%|███████▍  | 519/700 [02:41<00:56,  3.21it/s]Training (remove=16):  74%|███████▍  | 520/700 [02:41<00:56,  3.21it/s]Training (remove=16):  74%|███████▍  | 521/700 [02:41<00:55,  3.22it/s]Training (remove=16):  75%|███████▍  | 522/700 [02:42<00:55,  3.22it/s]Training (remove=16):  75%|███████▍  | 523/700 [02:42<00:54,  3.22it/s]Training (remove=16):  75%|███████▍  | 524/700 [02:42<00:54,  3.22it/s]Training (remove=16):  75%|███████▌  | 525/700 [02:43<00:54,  3.22it/s]Training (remove=16):  75%|███████▌  | 526/700 [02:43<00:54,  3.21it/s]Training (remove=16):  75%|███████▌  | 527/700 [02:43<00:53,  3.22it/s]Training (remove=16):  75%|███████▌  | 528/700 [02:44<00:53,  3.22it/s]Training (remove=16):  76%|███████▌  | 529/700 [02:44<00:53,  3.22it/s]Training (remove=16):  76%|███████▌  | 530/700 [02:44<00:52,  3.23it/s]Training (remove=16):  76%|███████▌  | 531/700 [02:45<00:52,  3.22it/s]Training (remove=16):  76%|███████▌  | 532/700 [02:45<00:52,  3.22it/s]Training (remove=16):  76%|███████▌  | 533/700 [02:45<00:51,  3.22it/s]Training (remove=16):  76%|███████▋  | 534/700 [02:45<00:51,  3.22it/s]Training (remove=16):  76%|███████▋  | 535/700 [02:46<00:51,  3.21it/s]Training (remove=16):  77%|███████▋  | 536/700 [02:46<00:51,  3.21it/s]Training (remove=16):  77%|███████▋  | 537/700 [02:46<00:50,  3.22it/s]Training (remove=16):  77%|███████▋  | 538/700 [02:47<00:50,  3.21it/s]Training (remove=16):  77%|███████▋  | 539/700 [02:47<00:50,  3.21it/s]Training (remove=16):  77%|███████▋  | 540/700 [02:47<00:49,  3.22it/s]Training (remove=16):  77%|███████▋  | 541/700 [02:48<00:49,  3.22it/s]Training (remove=16):  77%|███████▋  | 542/700 [02:48<00:49,  3.22it/s]Training (remove=16):  78%|███████▊  | 543/700 [02:48<00:48,  3.22it/s]Training (remove=16):  78%|███████▊  | 544/700 [02:49<00:48,  3.21it/s]Training (remove=16):  78%|███████▊  | 545/700 [02:49<00:48,  3.22it/s]Training (remove=16):  78%|███████▊  | 546/700 [02:49<00:47,  3.22it/s]Training (remove=16):  78%|███████▊  | 547/700 [02:49<00:47,  3.22it/s]Training (remove=16):  78%|███████▊  | 548/700 [02:50<00:47,  3.23it/s]Training (remove=16):  78%|███████▊  | 549/700 [02:50<00:46,  3.23it/s]Training (remove=16):  79%|███████▊  | 550/700 [02:50<00:46,  3.22it/s]Training (remove=16):  79%|███████▊  | 551/700 [02:51<00:46,  3.22it/s]Training (remove=16):  79%|███████▉  | 552/700 [02:51<00:46,  3.21it/s]Training (remove=16):  79%|███████▉  | 553/700 [02:51<00:45,  3.21it/s]Training (remove=16):  79%|███████▉  | 554/700 [02:52<00:45,  3.21it/s]Training (remove=16):  79%|███████▉  | 555/700 [02:52<00:45,  3.21it/s]Training (remove=16):  79%|███████▉  | 556/700 [02:52<00:44,  3.21it/s]Training (remove=16):  80%|███████▉  | 557/700 [02:53<00:44,  3.21it/s]Training (remove=16):  80%|███████▉  | 558/700 [02:53<00:44,  3.21it/s]Training (remove=16):  80%|███████▉  | 559/700 [02:53<00:43,  3.21it/s]Training (remove=16):  80%|████████  | 560/700 [02:54<00:43,  3.22it/s]Training (remove=16):  80%|████████  | 561/700 [02:54<00:43,  3.22it/s]Training (remove=16):  80%|████████  | 562/700 [02:54<00:42,  3.22it/s]Training (remove=16):  80%|████████  | 563/700 [02:54<00:42,  3.23it/s]Training (remove=16):  81%|████████  | 564/700 [02:55<00:42,  3.23it/s]Training (remove=16):  81%|████████  | 565/700 [02:55<00:41,  3.23it/s]Training (remove=16):  81%|████████  | 566/700 [02:55<00:41,  3.23it/s]Training (remove=16):  81%|████████  | 567/700 [02:56<00:41,  3.23it/s]Training (remove=16):  81%|████████  | 568/700 [02:56<00:40,  3.23it/s]Training (remove=16):  81%|████████▏ | 569/700 [02:56<00:40,  3.22it/s]Training (remove=16):  81%|████████▏ | 570/700 [02:57<00:40,  3.22it/s]Training (remove=16):  82%|████████▏ | 571/700 [02:57<00:40,  3.21it/s]Training (remove=16):  82%|████████▏ | 572/700 [02:57<00:39,  3.22it/s]Training (remove=16):  82%|████████▏ | 573/700 [02:58<00:39,  3.22it/s]Training (remove=16):  82%|████████▏ | 574/700 [02:58<00:39,  3.22it/s]Training (remove=16):  82%|████████▏ | 575/700 [02:58<00:38,  3.21it/s]Training (remove=16):  82%|████████▏ | 576/700 [02:59<00:38,  3.22it/s]Training (remove=16):  82%|████████▏ | 577/700 [02:59<00:38,  3.21it/s]Training (remove=16):  83%|████████▎ | 578/700 [02:59<00:38,  3.21it/s]Training (remove=16):  83%|████████▎ | 579/700 [02:59<00:37,  3.22it/s]Training (remove=16):  83%|████████▎ | 580/700 [03:00<00:37,  3.22it/s]Training (remove=16):  83%|████████▎ | 581/700 [03:00<00:36,  3.22it/s]Training (remove=16):  83%|████████▎ | 582/700 [03:00<00:36,  3.23it/s]Training (remove=16):  83%|████████▎ | 583/700 [03:01<00:36,  3.22it/s]Training (remove=16):  83%|████████▎ | 584/700 [03:01<00:35,  3.23it/s]Training (remove=16):  84%|████████▎ | 585/700 [03:01<00:35,  3.22it/s]Training (remove=16):  84%|████████▎ | 586/700 [03:02<00:35,  3.23it/s]Training (remove=16):  84%|████████▍ | 587/700 [03:02<00:35,  3.22it/s]Training (remove=16):  84%|████████▍ | 588/700 [03:02<00:34,  3.22it/s]Training (remove=16):  84%|████████▍ | 589/700 [03:03<00:34,  3.22it/s]Training (remove=16):  84%|████████▍ | 590/700 [03:03<00:34,  3.22it/s]Training (remove=16):  84%|████████▍ | 591/700 [03:03<00:33,  3.22it/s]Training (remove=16):  85%|████████▍ | 592/700 [03:03<00:33,  3.22it/s]Training (remove=16):  85%|████████▍ | 593/700 [03:04<00:33,  3.22it/s]Training (remove=16):  85%|████████▍ | 594/700 [03:04<00:32,  3.22it/s]Training (remove=16):  85%|████████▌ | 595/700 [03:04<00:32,  3.22it/s]Training (remove=16):  85%|████████▌ | 596/700 [03:05<00:32,  3.22it/s]Training (remove=16):  85%|████████▌ | 597/700 [03:05<00:31,  3.22it/s]Training (remove=16):  85%|████████▌ | 598/700 [03:05<00:31,  3.22it/s]Training (remove=16):  86%|████████▌ | 599/700 [03:06<00:31,  3.22it/s]Training (remove=16):  86%|████████▌ | 600/700 [03:06<00:31,  3.22it/s]Training (remove=16):  86%|████████▌ | 601/700 [03:06<00:30,  3.23it/s]Training (remove=16):  86%|████████▌ | 602/700 [03:07<00:30,  3.22it/s]Training (remove=16):  86%|████████▌ | 603/700 [03:07<00:30,  3.22it/s]Training (remove=16):  86%|████████▋ | 604/700 [03:07<00:29,  3.22it/s]Training (remove=16):  86%|████████▋ | 605/700 [03:08<00:29,  3.22it/s]Training (remove=16):  87%|████████▋ | 606/700 [03:08<00:29,  3.23it/s]Training (remove=16):  87%|████████▋ | 607/700 [03:08<00:28,  3.22it/s]Training (remove=16):  87%|████████▋ | 608/700 [03:08<00:28,  3.22it/s]Training (remove=16):  87%|████████▋ | 609/700 [03:09<00:28,  3.22it/s]Training (remove=16):  87%|████████▋ | 610/700 [03:09<00:27,  3.22it/s]Training (remove=16):  87%|████████▋ | 611/700 [03:09<00:27,  3.22it/s]Training (remove=16):  87%|████████▋ | 612/700 [03:10<00:27,  3.22it/s]Training (remove=16):  88%|████████▊ | 613/700 [03:10<00:26,  3.22it/s]Training (remove=16):  88%|████████▊ | 614/700 [03:10<00:26,  3.22it/s]Training (remove=16):  88%|████████▊ | 615/700 [03:11<00:26,  3.22it/s]Training (remove=16):  88%|████████▊ | 616/700 [03:11<00:26,  3.21it/s]Training (remove=16):  88%|████████▊ | 617/700 [03:11<00:25,  3.22it/s]Training (remove=16):  88%|████████▊ | 618/700 [03:12<00:25,  3.22it/s]Training (remove=16):  88%|████████▊ | 619/700 [03:12<00:25,  3.23it/s]Training (remove=16):  89%|████████▊ | 620/700 [03:12<00:24,  3.23it/s]Training (remove=16):  89%|████████▊ | 621/700 [03:12<00:24,  3.23it/s]Training (remove=16):  89%|████████▉ | 622/700 [03:13<00:24,  3.22it/s]Training (remove=16):  89%|████████▉ | 623/700 [03:13<00:23,  3.22it/s]Training (remove=16):  89%|████████▉ | 624/700 [03:13<00:23,  3.22it/s]Training (remove=16):  89%|████████▉ | 625/700 [03:14<00:23,  3.22it/s]Training (remove=16):  89%|████████▉ | 626/700 [03:14<00:23,  3.22it/s]Training (remove=16):  90%|████████▉ | 627/700 [03:14<00:22,  3.22it/s]Training (remove=16):  90%|████████▉ | 628/700 [03:15<00:22,  3.21it/s]Training (remove=16):  90%|████████▉ | 629/700 [03:15<00:22,  3.21it/s]Training (remove=16):  90%|█████████ | 630/700 [03:15<00:21,  3.21it/s]Training (remove=16):  90%|█████████ | 631/700 [03:16<00:21,  3.22it/s]Training (remove=16):  90%|█████████ | 632/700 [03:16<00:21,  3.22it/s]Training (remove=16):  90%|█████████ | 633/700 [03:16<00:20,  3.23it/s]Training (remove=16):  91%|█████████ | 634/700 [03:17<00:20,  3.22it/s]Training (remove=16):  91%|█████████ | 635/700 [03:17<00:20,  3.22it/s]Training (remove=16):  91%|█████████ | 636/700 [03:17<00:19,  3.21it/s]Training (remove=16):  91%|█████████ | 637/700 [03:17<00:19,  3.22it/s]Training (remove=16):  91%|█████████ | 638/700 [03:18<00:19,  3.21it/s]Training (remove=16):  91%|█████████▏| 639/700 [03:18<00:18,  3.21it/s]Training (remove=16):  91%|█████████▏| 640/700 [03:18<00:18,  3.21it/s]Training (remove=16):  92%|█████████▏| 641/700 [03:19<00:18,  3.22it/s]Training (remove=16):  92%|█████████▏| 642/700 [03:19<00:18,  3.21it/s]Training (remove=16):  92%|█████████▏| 643/700 [03:19<00:17,  3.22it/s]Training (remove=16):  92%|█████████▏| 644/700 [03:20<00:17,  3.21it/s]Training (remove=16):  92%|█████████▏| 645/700 [03:20<00:17,  3.22it/s]Training (remove=16):  92%|█████████▏| 646/700 [03:20<00:16,  3.21it/s]Training (remove=16):  92%|█████████▏| 647/700 [03:21<00:16,  3.22it/s]Training (remove=16):  93%|█████████▎| 648/700 [03:21<00:16,  3.22it/s]Training (remove=16):  93%|█████████▎| 649/700 [03:21<00:15,  3.22it/s]Training (remove=16):  93%|█████████▎| 650/700 [03:21<00:15,  3.22it/s]Training (remove=16):  93%|█████████▎| 651/700 [03:22<00:15,  3.22it/s]Training (remove=16):  93%|█████████▎| 652/700 [03:22<00:14,  3.23it/s]Training (remove=16):  93%|█████████▎| 653/700 [03:22<00:14,  3.23it/s]Training (remove=16):  93%|█████████▎| 654/700 [03:23<00:14,  3.23it/s]Training (remove=16):  94%|█████████▎| 655/700 [03:23<00:13,  3.23it/s]Training (remove=16):  94%|█████████▎| 656/700 [03:23<00:13,  3.23it/s]Training (remove=16):  94%|█████████▍| 657/700 [03:24<00:13,  3.22it/s]Training (remove=16):  94%|█████████▍| 658/700 [03:24<00:13,  3.22it/s]Training (remove=16):  94%|█████████▍| 659/700 [03:24<00:12,  3.22it/s]Training (remove=16):  94%|█████████▍| 660/700 [03:25<00:12,  3.23it/s]Training (remove=16):  94%|█████████▍| 661/700 [03:25<00:12,  3.22it/s]Training (remove=16):  95%|█████████▍| 662/700 [03:25<00:11,  3.22it/s]Training (remove=16):  95%|█████████▍| 663/700 [03:26<00:11,  3.22it/s]Training (remove=16):  95%|█████████▍| 664/700 [03:26<00:11,  3.22it/s]Training (remove=16):  95%|█████████▌| 665/700 [03:26<00:10,  3.22it/s]Training (remove=16):  95%|█████████▌| 666/700 [03:26<00:10,  3.21it/s]Training (remove=16):  95%|█████████▌| 667/700 [03:27<00:10,  3.22it/s]Training (remove=16):  95%|█████████▌| 668/700 [03:27<00:09,  3.21it/s]Training (remove=16):  96%|█████████▌| 669/700 [03:27<00:09,  3.21it/s]Training (remove=16):  96%|█████████▌| 670/700 [03:28<00:09,  3.22it/s]Training (remove=16):  96%|█████████▌| 671/700 [03:28<00:09,  3.22it/s]Training (remove=16):  96%|█████████▌| 672/700 [03:28<00:08,  3.22it/s]Training (remove=16):  96%|█████████▌| 673/700 [03:29<00:08,  3.22it/s]Training (remove=16):  96%|█████████▋| 674/700 [03:29<00:08,  3.21it/s]Training (remove=16):  96%|█████████▋| 675/700 [03:29<00:07,  3.21it/s]Training (remove=16):  97%|█████████▋| 676/700 [03:30<00:07,  3.22it/s]Training (remove=16):  97%|█████████▋| 677/700 [03:30<00:07,  3.21it/s]Training (remove=16):  97%|█████████▋| 678/700 [03:30<00:06,  3.21it/s]Training (remove=16):  97%|█████████▋| 679/700 [03:31<00:06,  3.22it/s]Training (remove=16):  97%|█████████▋| 680/700 [03:31<00:06,  3.22it/s]Training (remove=16):  97%|█████████▋| 681/700 [03:31<00:05,  3.22it/s]Training (remove=16):  97%|█████████▋| 682/700 [03:31<00:05,  3.22it/s]Training (remove=16):  98%|█████████▊| 683/700 [03:32<00:05,  3.21it/s]Training (remove=16):  98%|█████████▊| 684/700 [03:32<00:04,  3.22it/s]Training (remove=16):  98%|█████████▊| 685/700 [03:32<00:04,  3.22it/s]Training (remove=16):  98%|█████████▊| 686/700 [03:33<00:04,  3.21it/s]Training (remove=16):  98%|█████████▊| 687/700 [03:33<00:04,  3.22it/s]Training (remove=16):  98%|█████████▊| 688/700 [03:33<00:03,  3.22it/s]Training (remove=16):  98%|█████████▊| 689/700 [03:34<00:03,  3.22it/s]Training (remove=16):  99%|█████████▊| 690/700 [03:34<00:03,  3.23it/s]Training (remove=16):  99%|█████████▊| 691/700 [03:34<00:02,  3.23it/s]Training (remove=16):  99%|█████████▉| 692/700 [03:35<00:02,  3.23it/s]Training (remove=16):  99%|█████████▉| 693/700 [03:35<00:02,  3.23it/s]Training (remove=16):  99%|█████████▉| 694/700 [03:35<00:01,  3.23it/s]Training (remove=16):  99%|█████████▉| 695/700 [03:35<00:01,  3.22it/s]Training (remove=16):  99%|█████████▉| 696/700 [03:36<00:01,  3.23it/s]Training (remove=16): 100%|█████████▉| 697/700 [03:36<00:00,  3.22it/s]Training (remove=16): 100%|█████████▉| 698/700 [03:36<00:00,  3.22it/s]Training (remove=16): 100%|█████████▉| 699/700 [03:37<00:00,  3.22it/s]Training (remove=16): 100%|██████████| 700/700 [03:37<00:00,  3.22it/s]Training (remove=16): 100%|██████████| 700/700 [03:37<00:00,  3.22it/s]
Step 100 - Loss: 0.0164
Step 200 - Loss: 0.0018
Step 300 - Loss: 0.0329
Step 400 - Loss: 0.1784
Step 500 - Loss: 0.0440
Step 600 - Loss: 0.0180
Step 700 - Loss: 0.0008
Epoch 3 - Average Loss: 0.0264
Evaluating (remove=16):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   0%|          | 1/200 [00:01<04:19,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   1%|          | 2/200 [00:02<03:27,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   2%|▏         | 3/200 [00:05<06:42,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   2%|▏         | 4/200 [00:06<05:28,  1.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   2%|▎         | 5/200 [00:08<06:23,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   3%|▎         | 6/200 [00:12<07:44,  2.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   4%|▎         | 7/200 [00:15<08:34,  2.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   4%|▍         | 8/200 [00:18<09:06,  2.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   4%|▍         | 9/200 [00:21<09:27,  2.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   5%|▌         | 10/200 [00:25<09:41,  3.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   6%|▌         | 11/200 [00:26<07:31,  2.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   6%|▌         | 12/200 [00:29<08:17,  2.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   6%|▋         | 13/200 [00:30<06:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   7%|▋         | 14/200 [00:33<07:13,  2.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   8%|▊         | 15/200 [00:34<06:00,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   8%|▊         | 16/200 [00:37<06:56,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   8%|▊         | 17/200 [00:37<05:37,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):   9%|▉         | 18/200 [00:39<05:28,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  10%|▉         | 19/200 [00:42<06:43,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  10%|█         | 20/200 [00:46<07:34,  2.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  10%|█         | 21/200 [00:46<06:02,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  11%|█         | 22/200 [00:48<05:49,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  12%|█▏        | 23/200 [00:49<04:49,  1.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  12%|█▏        | 24/200 [00:52<06:11,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  12%|█▎        | 25/200 [00:56<07:07,  2.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  13%|█▎        | 26/200 [00:56<05:42,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  14%|█▎        | 27/200 [00:58<04:54,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  14%|█▍        | 28/200 [01:01<06:11,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  14%|█▍        | 29/200 [01:03<06:30,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  15%|█▌        | 30/200 [01:04<05:15,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  16%|█▌        | 31/200 [01:05<04:23,  1.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  16%|█▌        | 32/200 [01:08<05:45,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  16%|█▋        | 33/200 [01:10<05:12,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  17%|█▋        | 34/200 [01:11<04:51,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  18%|█▊        | 35/200 [01:12<04:05,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  18%|█▊        | 36/200 [01:14<04:00,  1.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  18%|█▊        | 37/200 [01:14<03:29,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  19%|█▉        | 38/200 [01:18<05:02,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  20%|█▉        | 39/200 [01:18<04:06,  1.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  20%|██        | 40/200 [01:19<03:32,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  20%|██        | 41/200 [01:20<03:09,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  21%|██        | 42/200 [01:23<04:44,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  22%|██▏       | 43/200 [01:24<04:08,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  22%|██▏       | 44/200 [01:26<03:53,  1.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  22%|██▎       | 45/200 [01:27<04:02,  1.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  23%|██▎       | 46/200 [01:29<04:08,  1.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  24%|██▎       | 47/200 [01:30<03:37,  1.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  24%|██▍       | 48/200 [01:33<04:58,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  24%|██▍       | 49/200 [01:37<05:54,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  25%|██▌       | 50/200 [01:40<06:32,  2.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  26%|██▌       | 51/200 [01:43<06:57,  2.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  26%|██▌       | 52/200 [01:46<07:13,  2.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  26%|██▋       | 53/200 [01:48<06:22,  2.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  27%|██▋       | 54/200 [01:49<05:13,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  28%|██▊       | 55/200 [01:50<04:15,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  28%|██▊       | 56/200 [01:53<05:16,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  28%|██▊       | 57/200 [01:55<04:54,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  29%|██▉       | 58/200 [01:56<04:20,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  30%|██▉       | 59/200 [02:00<05:16,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  30%|███       | 60/200 [02:01<04:26,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  30%|███       | 61/200 [02:04<05:19,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  31%|███       | 62/200 [02:05<04:45,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  32%|███▏      | 63/200 [02:07<04:16,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  32%|███▏      | 64/200 [02:08<03:55,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  32%|███▎      | 65/200 [02:10<04:11,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  33%|███▎      | 66/200 [02:12<03:51,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  34%|███▎      | 67/200 [02:13<03:32,  1.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  34%|███▍      | 68/200 [02:15<03:48,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  34%|███▍      | 69/200 [02:18<04:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  35%|███▌      | 70/200 [02:22<05:23,  2.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  36%|███▌      | 71/200 [02:22<04:18,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  36%|███▌      | 72/200 [02:24<03:53,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  36%|███▋      | 73/200 [02:26<03:55,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  37%|███▋      | 74/200 [02:27<03:46,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  38%|███▊      | 75/200 [02:31<04:38,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  38%|███▊      | 76/200 [02:33<04:49,  2.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  38%|███▊      | 77/200 [02:34<04:00,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  39%|███▉      | 78/200 [02:38<04:45,  2.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  40%|███▉      | 79/200 [02:41<05:15,  2.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  40%|████      | 80/200 [02:44<05:35,  2.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  40%|████      | 81/200 [02:47<05:48,  2.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  41%|████      | 82/200 [02:50<05:55,  3.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  42%|████▏     | 83/200 [02:52<04:44,  2.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  42%|████▏     | 84/200 [02:53<04:06,  2.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  42%|████▎     | 85/200 [02:56<04:42,  2.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  43%|████▎     | 86/200 [02:57<03:46,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  44%|████▎     | 87/200 [02:59<03:27,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  44%|████▍     | 88/200 [03:00<03:00,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  44%|████▍     | 89/200 [03:02<03:38,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  45%|████▌     | 90/200 [03:04<03:18,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  46%|████▌     | 91/200 [03:05<02:59,  1.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  46%|████▌     | 92/200 [03:06<02:32,  1.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  46%|████▋     | 93/200 [03:07<02:20,  1.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  47%|████▋     | 94/200 [03:09<02:32,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  48%|████▊     | 95/200 [03:10<02:12,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  48%|████▊     | 96/200 [03:13<03:12,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  48%|████▊     | 97/200 [03:14<02:43,  1.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  49%|████▉     | 98/200 [03:15<02:26,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  50%|████▉     | 99/200 [03:17<02:36,  1.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  50%|█████     | 100/200 [03:20<03:25,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  50%|█████     | 101/200 [03:21<02:48,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  51%|█████     | 102/200 [03:23<02:47,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  52%|█████▏    | 103/200 [03:24<02:24,  1.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  52%|█████▏    | 104/200 [03:27<03:12,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  52%|█████▎    | 105/200 [03:28<02:50,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  53%|█████▎    | 106/200 [03:29<02:22,  1.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  54%|█████▎    | 107/200 [03:30<02:05,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  54%|█████▍    | 108/200 [03:32<02:14,  1.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  55%|█████▍    | 109/200 [03:35<03:01,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  55%|█████▌    | 110/200 [03:38<03:33,  2.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  56%|█████▌    | 111/200 [03:39<02:57,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  56%|█████▌    | 112/200 [03:41<02:48,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  56%|█████▋    | 113/200 [03:42<02:19,  1.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  57%|█████▋    | 114/200 [03:43<02:09,  1.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  57%|█████▊    | 115/200 [03:46<02:49,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  58%|█████▊    | 116/200 [03:47<02:24,  1.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  58%|█████▊    | 117/200 [03:48<02:07,  1.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  59%|█████▉    | 118/200 [03:52<02:46,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  60%|█████▉    | 119/200 [03:53<02:27,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  60%|██████    | 120/200 [03:56<02:59,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  60%|██████    | 121/200 [03:57<02:24,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  61%|██████    | 122/200 [03:59<02:15,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  62%|██████▏   | 123/200 [04:02<02:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  62%|██████▏   | 124/200 [04:03<02:15,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  62%|██████▎   | 125/200 [04:04<01:53,  1.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  63%|██████▎   | 126/200 [04:04<01:37,  1.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  64%|██████▎   | 127/200 [04:05<01:26,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  64%|██████▍   | 128/200 [04:06<01:18,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  64%|██████▍   | 129/200 [04:07<01:17,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  65%|██████▌   | 130/200 [04:10<02:00,  1.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  66%|██████▌   | 131/200 [04:11<01:41,  1.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  66%|██████▌   | 132/200 [04:12<01:27,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  66%|██████▋   | 133/200 [04:13<01:17,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  67%|██████▋   | 134/200 [04:14<01:15,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  68%|██████▊   | 135/200 [04:16<01:35,  1.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  68%|██████▊   | 136/200 [04:17<01:27,  1.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  68%|██████▊   | 137/200 [04:20<01:51,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  69%|██████▉   | 138/200 [04:21<01:37,  1.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  70%|██████▉   | 139/200 [04:24<02:00,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  70%|███████   | 140/200 [04:27<02:21,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  70%|███████   | 141/200 [04:29<01:56,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  71%|███████   | 142/200 [04:30<01:40,  1.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  72%|███████▏  | 143/200 [04:32<01:47,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  72%|███████▏  | 144/200 [04:35<02:08,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  72%|███████▎  | 145/200 [04:37<01:53,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  73%|███████▎  | 146/200 [04:38<01:39,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  74%|███████▎  | 147/200 [04:39<01:25,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  74%|███████▍  | 148/200 [04:42<01:48,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  74%|███████▍  | 149/200 [04:46<02:04,  2.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  75%|███████▌  | 150/200 [04:47<01:41,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  76%|███████▌  | 151/200 [04:48<01:28,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  76%|███████▌  | 152/200 [04:51<01:47,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  76%|███████▋  | 153/200 [04:52<01:25,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  77%|███████▋  | 154/200 [04:53<01:10,  1.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  78%|███████▊  | 155/200 [04:54<01:02,  1.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  78%|███████▊  | 156/200 [04:57<01:25,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  78%|███████▊  | 157/200 [04:59<01:24,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  79%|███████▉  | 158/200 [05:02<01:38,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  80%|███████▉  | 159/200 [05:04<01:23,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  80%|████████  | 160/200 [05:07<01:35,  2.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  80%|████████  | 161/200 [05:08<01:18,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  81%|████████  | 162/200 [05:09<01:03,  1.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  82%|████████▏ | 163/200 [05:10<00:52,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  82%|████████▏ | 164/200 [05:11<00:47,  1.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  82%|████████▎ | 165/200 [05:14<01:06,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  83%|████████▎ | 166/200 [05:16<01:08,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  84%|████████▎ | 167/200 [05:18<01:02,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  84%|████████▍ | 168/200 [05:19<00:52,  1.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  84%|████████▍ | 169/200 [05:20<00:47,  1.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  85%|████████▌ | 170/200 [05:22<00:42,  1.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  86%|████████▌ | 171/200 [05:25<00:56,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  86%|████████▌ | 172/200 [05:27<00:54,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  86%|████████▋ | 173/200 [05:28<00:45,  1.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  87%|████████▋ | 174/200 [05:31<00:55,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  88%|████████▊ | 175/200 [05:34<01:02,  2.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  88%|████████▊ | 176/200 [05:36<00:51,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  88%|████████▊ | 177/200 [05:37<00:44,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  89%|████████▉ | 178/200 [05:39<00:41,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  90%|████████▉ | 179/200 [05:42<00:47,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  90%|█████████ | 180/200 [05:45<00:51,  2.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  90%|█████████ | 181/200 [05:46<00:39,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  91%|█████████ | 182/200 [05:49<00:43,  2.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  92%|█████████▏| 183/200 [05:51<00:34,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  92%|█████████▏| 184/200 [05:54<00:38,  2.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  92%|█████████▎| 185/200 [05:56<00:35,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  93%|█████████▎| 186/200 [05:57<00:27,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  94%|█████████▎| 187/200 [05:58<00:21,  1.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  94%|█████████▍| 188/200 [05:59<00:16,  1.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  94%|█████████▍| 189/200 [06:02<00:21,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  95%|█████████▌| 190/200 [06:03<00:17,  1.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  96%|█████████▌| 191/200 [06:06<00:19,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  96%|█████████▌| 192/200 [06:08<00:14,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  96%|█████████▋| 193/200 [06:11<00:15,  2.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  97%|█████████▋| 194/200 [06:14<00:15,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  98%|█████████▊| 195/200 [06:16<00:12,  2.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  98%|█████████▊| 196/200 [06:17<00:07,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  98%|█████████▊| 197/200 [06:19<00:06,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16):  99%|█████████▉| 198/200 [06:20<00:03,  1.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16): 100%|█████████▉| 199/200 [06:23<00:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=16): 100%|██████████| 200/200 [06:25<00:00,  1.86s/it]Evaluating (remove=16): 100%|██████████| 200/200 [06:25<00:00,  1.93s/it]
Epoch 3 - Accuracy: 0.1800
Epoch 4/10 - Removing 24 tokens
Training (remove=24):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=24):   0%|          | 1/700 [00:00<03:34,  3.26it/s]Training (remove=24):   0%|          | 2/700 [00:00<03:36,  3.23it/s]Training (remove=24):   0%|          | 3/700 [00:00<03:36,  3.22it/s]Training (remove=24):   1%|          | 4/700 [00:01<03:35,  3.23it/s]Training (remove=24):   1%|          | 5/700 [00:01<03:35,  3.22it/s]Training (remove=24):   1%|          | 6/700 [00:01<03:35,  3.23it/s]Training (remove=24):   1%|          | 7/700 [00:02<03:35,  3.22it/s]Training (remove=24):   1%|          | 8/700 [00:02<03:35,  3.21it/s]Training (remove=24):   1%|▏         | 9/700 [00:02<03:35,  3.21it/s]Training (remove=24):   1%|▏         | 10/700 [00:03<03:35,  3.21it/s]Training (remove=24):   2%|▏         | 11/700 [00:03<03:34,  3.21it/s]Training (remove=24):   2%|▏         | 12/700 [00:03<03:34,  3.21it/s]Training (remove=24):   2%|▏         | 13/700 [00:04<03:34,  3.21it/s]Training (remove=24):   2%|▏         | 14/700 [00:04<03:33,  3.21it/s]Training (remove=24):   2%|▏         | 15/700 [00:04<03:33,  3.21it/s]Training (remove=24):   2%|▏         | 16/700 [00:04<03:32,  3.22it/s]Training (remove=24):   2%|▏         | 17/700 [00:05<03:32,  3.21it/s]Training (remove=24):   3%|▎         | 18/700 [00:05<03:31,  3.22it/s]Training (remove=24):   3%|▎         | 19/700 [00:05<03:31,  3.21it/s]Training (remove=24):   3%|▎         | 20/700 [00:06<03:31,  3.21it/s]Training (remove=24):   3%|▎         | 21/700 [00:06<03:30,  3.22it/s]Training (remove=24):   3%|▎         | 22/700 [00:06<03:30,  3.22it/s]Training (remove=24):   3%|▎         | 23/700 [00:07<03:29,  3.23it/s]Training (remove=24):   3%|▎         | 24/700 [00:07<03:29,  3.22it/s]Training (remove=24):   4%|▎         | 25/700 [00:07<03:29,  3.22it/s]Training (remove=24):   4%|▎         | 26/700 [00:08<03:29,  3.22it/s]Training (remove=24):   4%|▍         | 27/700 [00:08<03:29,  3.21it/s]Training (remove=24):   4%|▍         | 29/700 [00:08<02:40,  4.17it/s]Training (remove=24):   4%|▍         | 30/700 [00:09<02:52,  3.89it/s]Training (remove=24):   4%|▍         | 31/700 [00:09<03:01,  3.69it/s]Training (remove=24):   5%|▍         | 32/700 [00:09<03:08,  3.54it/s]Training (remove=24):   5%|▍         | 33/700 [00:09<03:13,  3.45it/s]Training (remove=24):   5%|▍         | 34/700 [00:10<03:16,  3.38it/s]Training (remove=24):   5%|▌         | 35/700 [00:10<03:19,  3.33it/s]Training (remove=24):   5%|▌         | 36/700 [00:10<03:21,  3.29it/s]Training (remove=24):   5%|▌         | 37/700 [00:11<03:22,  3.27it/s]Training (remove=24):   5%|▌         | 38/700 [00:11<03:23,  3.25it/s]Training (remove=24):   6%|▌         | 39/700 [00:11<03:23,  3.24it/s]Training (remove=24):   6%|▌         | 40/700 [00:12<03:24,  3.23it/s]Training (remove=24):   6%|▌         | 41/700 [00:12<03:24,  3.23it/s]Training (remove=24):   6%|▌         | 42/700 [00:12<03:24,  3.22it/s]Training (remove=24):   6%|▌         | 43/700 [00:13<03:24,  3.22it/s]Training (remove=24):   6%|▋         | 44/700 [00:13<03:23,  3.22it/s]Training (remove=24):   6%|▋         | 45/700 [00:13<03:23,  3.21it/s]Training (remove=24):   7%|▋         | 46/700 [00:13<03:23,  3.22it/s]Training (remove=24):   7%|▋         | 47/700 [00:14<03:23,  3.22it/s]Training (remove=24):   7%|▋         | 48/700 [00:14<03:22,  3.22it/s]Training (remove=24):   7%|▋         | 49/700 [00:14<03:22,  3.22it/s]Training (remove=24):   7%|▋         | 50/700 [00:15<03:22,  3.21it/s]Training (remove=24):   7%|▋         | 51/700 [00:15<03:22,  3.21it/s]Training (remove=24):   7%|▋         | 52/700 [00:15<03:21,  3.21it/s]Training (remove=24):   8%|▊         | 53/700 [00:16<03:21,  3.22it/s]Training (remove=24):   8%|▊         | 54/700 [00:16<03:20,  3.21it/s]Training (remove=24):   8%|▊         | 55/700 [00:16<03:20,  3.22it/s]Training (remove=24):   8%|▊         | 56/700 [00:17<03:20,  3.22it/s]Training (remove=24):   8%|▊         | 57/700 [00:17<03:20,  3.21it/s]Training (remove=24):   8%|▊         | 58/700 [00:17<03:19,  3.22it/s]Training (remove=24):   8%|▊         | 59/700 [00:18<03:19,  3.22it/s]Training (remove=24):   9%|▊         | 60/700 [00:18<03:18,  3.22it/s]Training (remove=24):   9%|▊         | 61/700 [00:18<03:18,  3.22it/s]Training (remove=24):   9%|▉         | 62/700 [00:18<03:18,  3.22it/s]Training (remove=24):   9%|▉         | 63/700 [00:19<03:18,  3.22it/s]Training (remove=24):   9%|▉         | 64/700 [00:19<03:17,  3.21it/s]Training (remove=24):   9%|▉         | 65/700 [00:19<03:17,  3.21it/s]Training (remove=24):   9%|▉         | 66/700 [00:20<03:16,  3.22it/s]Training (remove=24):  10%|▉         | 67/700 [00:20<03:16,  3.21it/s]Training (remove=24):  10%|▉         | 68/700 [00:20<03:16,  3.21it/s]Training (remove=24):  10%|▉         | 69/700 [00:21<03:16,  3.21it/s]Training (remove=24):  10%|█         | 70/700 [00:21<03:16,  3.21it/s]Training (remove=24):  10%|█         | 71/700 [00:21<03:15,  3.22it/s]Training (remove=24):  10%|█         | 72/700 [00:22<03:14,  3.22it/s]Training (remove=24):  10%|█         | 73/700 [00:22<03:14,  3.22it/s]Training (remove=24):  11%|█         | 74/700 [00:22<03:14,  3.21it/s]Training (remove=24):  11%|█         | 75/700 [00:23<03:14,  3.21it/s]Training (remove=24):  11%|█         | 76/700 [00:23<03:14,  3.21it/s]Training (remove=24):  11%|█         | 77/700 [00:23<03:14,  3.21it/s]Training (remove=24):  11%|█         | 78/700 [00:23<03:13,  3.21it/s]Training (remove=24):  11%|█▏        | 79/700 [00:24<03:13,  3.21it/s]Training (remove=24):  11%|█▏        | 80/700 [00:24<03:13,  3.21it/s]Training (remove=24):  12%|█▏        | 81/700 [00:24<03:12,  3.21it/s]Training (remove=24):  12%|█▏        | 82/700 [00:25<03:12,  3.21it/s]Training (remove=24):  12%|█▏        | 83/700 [00:25<03:11,  3.22it/s]Training (remove=24):  12%|█▏        | 84/700 [00:25<03:11,  3.22it/s]Training (remove=24):  12%|█▏        | 85/700 [00:26<03:11,  3.22it/s]Training (remove=24):  12%|█▏        | 86/700 [00:26<03:10,  3.22it/s]Training (remove=24):  12%|█▏        | 87/700 [00:26<03:10,  3.22it/s]Training (remove=24):  13%|█▎        | 88/700 [00:27<03:10,  3.22it/s]Training (remove=24):  13%|█▎        | 89/700 [00:27<03:10,  3.21it/s]Training (remove=24):  13%|█▎        | 90/700 [00:27<03:09,  3.22it/s]Training (remove=24):  13%|█▎        | 91/700 [00:27<03:09,  3.22it/s]Training (remove=24):  13%|█▎        | 92/700 [00:28<03:09,  3.21it/s]Training (remove=24):  13%|█▎        | 93/700 [00:28<03:08,  3.22it/s]Training (remove=24):  13%|█▎        | 94/700 [00:28<03:08,  3.21it/s]Training (remove=24):  14%|█▎        | 95/700 [00:29<03:08,  3.22it/s]Training (remove=24):  14%|█▎        | 96/700 [00:29<03:07,  3.22it/s]Training (remove=24):  14%|█▍        | 97/700 [00:29<03:06,  3.23it/s]Training (remove=24):  14%|█▍        | 98/700 [00:30<03:06,  3.22it/s]Training (remove=24):  14%|█▍        | 99/700 [00:30<03:06,  3.22it/s]Training (remove=24):  14%|█▍        | 100/700 [00:30<03:06,  3.21it/s]Training (remove=24):  14%|█▍        | 101/700 [00:31<03:06,  3.21it/s]Training (remove=24):  15%|█▍        | 102/700 [00:31<03:06,  3.21it/s]Training (remove=24):  15%|█▍        | 103/700 [00:31<03:05,  3.22it/s]Training (remove=24):  15%|█▍        | 104/700 [00:32<03:05,  3.22it/s]Training (remove=24):  15%|█▌        | 105/700 [00:32<03:05,  3.21it/s]Training (remove=24):  15%|█▌        | 106/700 [00:32<03:04,  3.22it/s]Training (remove=24):  15%|█▌        | 107/700 [00:32<03:04,  3.21it/s]Training (remove=24):  15%|█▌        | 108/700 [00:33<03:04,  3.21it/s]Training (remove=24):  16%|█▌        | 109/700 [00:33<03:04,  3.21it/s]Training (remove=24):  16%|█▌        | 110/700 [00:33<03:03,  3.21it/s]Training (remove=24):  16%|█▌        | 111/700 [00:34<03:03,  3.21it/s]Training (remove=24):  16%|█▌        | 112/700 [00:34<03:03,  3.20it/s]Training (remove=24):  16%|█▌        | 113/700 [00:34<03:03,  3.20it/s]Training (remove=24):  16%|█▋        | 114/700 [00:35<03:02,  3.20it/s]Training (remove=24):  16%|█▋        | 115/700 [00:35<03:02,  3.21it/s]Training (remove=24):  17%|█▋        | 116/700 [00:35<03:02,  3.21it/s]Training (remove=24):  17%|█▋        | 117/700 [00:36<03:01,  3.21it/s]Training (remove=24):  17%|█▋        | 118/700 [00:36<03:00,  3.22it/s]Training (remove=24):  17%|█▋        | 119/700 [00:36<03:00,  3.21it/s]Training (remove=24):  17%|█▋        | 120/700 [00:37<03:00,  3.21it/s]Training (remove=24):  17%|█▋        | 121/700 [00:37<03:00,  3.21it/s]Training (remove=24):  17%|█▋        | 122/700 [00:37<03:00,  3.21it/s]Training (remove=24):  18%|█▊        | 123/700 [00:37<02:59,  3.21it/s]Training (remove=24):  18%|█▊        | 124/700 [00:38<02:59,  3.21it/s]Training (remove=24):  18%|█▊        | 125/700 [00:38<02:58,  3.21it/s]Training (remove=24):  18%|█▊        | 126/700 [00:38<02:58,  3.21it/s]Training (remove=24):  18%|█▊        | 127/700 [00:39<02:58,  3.21it/s]Training (remove=24):  18%|█▊        | 128/700 [00:39<02:58,  3.21it/s]Training (remove=24):  18%|█▊        | 129/700 [00:39<02:57,  3.22it/s]Training (remove=24):  19%|█▊        | 130/700 [00:40<02:56,  3.22it/s]Training (remove=24):  19%|█▊        | 131/700 [00:40<02:56,  3.22it/s]Training (remove=24):  19%|█▉        | 132/700 [00:40<02:56,  3.21it/s]Training (remove=24):  19%|█▉        | 133/700 [00:41<02:56,  3.21it/s]Training (remove=24):  19%|█▉        | 134/700 [00:41<02:56,  3.21it/s]Training (remove=24):  19%|█▉        | 135/700 [00:41<02:55,  3.21it/s]Training (remove=24):  19%|█▉        | 136/700 [00:41<02:55,  3.21it/s]Training (remove=24):  20%|█▉        | 137/700 [00:42<02:55,  3.21it/s]Training (remove=24):  20%|█▉        | 138/700 [00:42<02:54,  3.21it/s]Training (remove=24):  20%|█▉        | 139/700 [00:42<02:54,  3.21it/s]Training (remove=24):  20%|██        | 140/700 [00:43<02:54,  3.21it/s]Training (remove=24):  20%|██        | 141/700 [00:43<02:54,  3.21it/s]Training (remove=24):  20%|██        | 142/700 [00:43<02:53,  3.21it/s]Training (remove=24):  20%|██        | 143/700 [00:44<02:53,  3.22it/s]Training (remove=24):  21%|██        | 144/700 [00:44<02:52,  3.22it/s]Training (remove=24):  21%|██        | 145/700 [00:44<02:52,  3.22it/s]Training (remove=24):  21%|██        | 146/700 [00:45<02:52,  3.22it/s]Training (remove=24):  21%|██        | 147/700 [00:45<02:51,  3.22it/s]Training (remove=24):  21%|██        | 148/700 [00:45<02:51,  3.22it/s]Training (remove=24):  21%|██▏       | 149/700 [00:46<02:51,  3.22it/s]Training (remove=24):  21%|██▏       | 150/700 [00:46<02:51,  3.21it/s]Training (remove=24):  22%|██▏       | 151/700 [00:46<02:50,  3.21it/s]Training (remove=24):  22%|██▏       | 152/700 [00:46<02:50,  3.22it/s]Training (remove=24):  22%|██▏       | 153/700 [00:47<02:49,  3.22it/s]Training (remove=24):  22%|██▏       | 154/700 [00:47<02:49,  3.22it/s]Training (remove=24):  22%|██▏       | 155/700 [00:47<02:49,  3.22it/s]Training (remove=24):  22%|██▏       | 156/700 [00:48<02:49,  3.21it/s]Training (remove=24):  22%|██▏       | 157/700 [00:48<02:49,  3.21it/s]Training (remove=24):  23%|██▎       | 158/700 [00:48<02:48,  3.21it/s]Training (remove=24):  23%|██▎       | 159/700 [00:49<02:48,  3.21it/s]Training (remove=24):  23%|██▎       | 160/700 [00:49<02:48,  3.21it/s]Training (remove=24):  23%|██▎       | 161/700 [00:49<02:47,  3.21it/s]Training (remove=24):  23%|██▎       | 162/700 [00:50<02:47,  3.21it/s]Training (remove=24):  23%|██▎       | 163/700 [00:50<02:47,  3.21it/s]Training (remove=24):  23%|██▎       | 164/700 [00:50<02:46,  3.22it/s]Training (remove=24):  24%|██▎       | 165/700 [00:51<02:46,  3.21it/s]Training (remove=24):  24%|██▎       | 166/700 [00:51<02:46,  3.21it/s]Training (remove=24):  24%|██▍       | 167/700 [00:51<02:46,  3.21it/s]Training (remove=24):  24%|██▍       | 168/700 [00:51<02:45,  3.21it/s]Training (remove=24):  24%|██▍       | 169/700 [00:52<02:45,  3.21it/s]Training (remove=24):  24%|██▍       | 170/700 [00:52<02:45,  3.21it/s]Training (remove=24):  24%|██▍       | 171/700 [00:52<02:44,  3.21it/s]Training (remove=24):  25%|██▍       | 172/700 [00:53<02:44,  3.21it/s]Training (remove=24):  25%|██▍       | 173/700 [00:53<02:44,  3.21it/s]Training (remove=24):  25%|██▍       | 174/700 [00:53<02:43,  3.22it/s]Training (remove=24):  25%|██▌       | 175/700 [00:54<02:43,  3.21it/s]Training (remove=24):  25%|██▌       | 176/700 [00:54<02:43,  3.21it/s]Training (remove=24):  25%|██▌       | 177/700 [00:54<02:43,  3.21it/s]Training (remove=24):  25%|██▌       | 178/700 [00:55<02:42,  3.21it/s]Training (remove=24):  26%|██▌       | 179/700 [00:55<02:42,  3.21it/s]Training (remove=24):  26%|██▌       | 180/700 [00:55<02:41,  3.21it/s]Training (remove=24):  26%|██▌       | 181/700 [00:56<02:41,  3.21it/s]Training (remove=24):  26%|██▌       | 182/700 [00:56<02:41,  3.21it/s]Training (remove=24):  26%|██▌       | 183/700 [00:56<02:40,  3.22it/s]Training (remove=24):  26%|██▋       | 184/700 [00:56<02:40,  3.21it/s]Training (remove=24):  26%|██▋       | 185/700 [00:57<02:40,  3.21it/s]Training (remove=24):  27%|██▋       | 186/700 [00:57<02:40,  3.21it/s]Training (remove=24):  27%|██▋       | 187/700 [00:57<02:39,  3.21it/s]Training (remove=24):  27%|██▋       | 188/700 [00:58<02:39,  3.21it/s]Training (remove=24):  27%|██▋       | 189/700 [00:58<02:39,  3.21it/s]Training (remove=24):  27%|██▋       | 190/700 [00:58<02:38,  3.22it/s]Training (remove=24):  27%|██▋       | 191/700 [00:59<02:38,  3.21it/s]Training (remove=24):  27%|██▋       | 192/700 [00:59<02:37,  3.22it/s]Training (remove=24):  28%|██▊       | 193/700 [00:59<02:37,  3.21it/s]Training (remove=24):  28%|██▊       | 194/700 [01:00<02:37,  3.22it/s]Training (remove=24):  28%|██▊       | 195/700 [01:00<02:36,  3.22it/s]Training (remove=24):  28%|██▊       | 196/700 [01:00<02:36,  3.21it/s]Training (remove=24):  28%|██▊       | 197/700 [01:00<02:36,  3.21it/s]Training (remove=24):  28%|██▊       | 198/700 [01:01<02:36,  3.21it/s]Training (remove=24):  28%|██▊       | 199/700 [01:01<02:36,  3.21it/s]Training (remove=24):  29%|██▊       | 200/700 [01:01<02:35,  3.21it/s]Training (remove=24):  29%|██▊       | 201/700 [01:02<02:35,  3.22it/s]Training (remove=24):  29%|██▉       | 202/700 [01:02<02:34,  3.21it/s]Training (remove=24):  29%|██▉       | 203/700 [01:02<02:34,  3.22it/s]Training (remove=24):  29%|██▉       | 204/700 [01:03<02:34,  3.21it/s]Training (remove=24):  29%|██▉       | 205/700 [01:03<02:33,  3.22it/s]Training (remove=24):  29%|██▉       | 206/700 [01:03<02:33,  3.22it/s]Training (remove=24):  30%|██▉       | 207/700 [01:04<02:33,  3.22it/s]Training (remove=24):  30%|██▉       | 208/700 [01:04<02:32,  3.22it/s]Training (remove=24):  30%|██▉       | 209/700 [01:04<02:32,  3.22it/s]Training (remove=24):  30%|███       | 210/700 [01:05<02:32,  3.22it/s]Training (remove=24):  30%|███       | 211/700 [01:05<02:31,  3.22it/s]Training (remove=24):  30%|███       | 212/700 [01:05<02:31,  3.21it/s]Training (remove=24):  30%|███       | 213/700 [01:05<02:31,  3.21it/s]Training (remove=24):  31%|███       | 214/700 [01:06<02:31,  3.21it/s]Training (remove=24):  31%|███       | 215/700 [01:06<02:31,  3.21it/s]Training (remove=24):  31%|███       | 216/700 [01:06<02:30,  3.21it/s]Training (remove=24):  31%|███       | 217/700 [01:07<02:30,  3.21it/s]Training (remove=24):  31%|███       | 218/700 [01:07<02:30,  3.21it/s]Training (remove=24):  31%|███▏      | 219/700 [01:07<02:29,  3.21it/s]Training (remove=24):  31%|███▏      | 220/700 [01:08<02:29,  3.21it/s]Training (remove=24):  32%|███▏      | 221/700 [01:08<02:29,  3.21it/s]Training (remove=24):  32%|███▏      | 222/700 [01:08<02:28,  3.21it/s]Training (remove=24):  32%|███▏      | 223/700 [01:09<02:28,  3.22it/s]Training (remove=24):  32%|███▏      | 224/700 [01:09<02:27,  3.22it/s]Training (remove=24):  32%|███▏      | 225/700 [01:09<02:27,  3.21it/s]Training (remove=24):  32%|███▏      | 226/700 [01:10<02:27,  3.22it/s]Training (remove=24):  32%|███▏      | 227/700 [01:10<02:27,  3.21it/s]Training (remove=24):  33%|███▎      | 228/700 [01:10<02:26,  3.21it/s]Training (remove=24):  33%|███▎      | 229/700 [01:10<02:26,  3.21it/s]Training (remove=24):  33%|███▎      | 230/700 [01:11<02:26,  3.21it/s]Training (remove=24):  33%|███▎      | 231/700 [01:11<02:25,  3.22it/s]Training (remove=24):  33%|███▎      | 232/700 [01:11<02:25,  3.21it/s]Training (remove=24):  33%|███▎      | 233/700 [01:12<02:25,  3.21it/s]Training (remove=24):  33%|███▎      | 234/700 [01:12<02:25,  3.21it/s]Training (remove=24):  34%|███▎      | 235/700 [01:12<02:25,  3.21it/s]Training (remove=24):  34%|███▎      | 236/700 [01:13<02:24,  3.21it/s]Training (remove=24):  34%|███▍      | 237/700 [01:13<02:23,  3.22it/s]Training (remove=24):  34%|███▍      | 238/700 [01:13<02:23,  3.21it/s]Training (remove=24):  34%|███▍      | 239/700 [01:14<02:23,  3.22it/s]Training (remove=24):  34%|███▍      | 240/700 [01:14<02:23,  3.22it/s]Training (remove=24):  34%|███▍      | 241/700 [01:14<02:22,  3.22it/s]Training (remove=24):  35%|███▍      | 242/700 [01:14<02:22,  3.22it/s]Training (remove=24):  35%|███▍      | 243/700 [01:15<02:21,  3.22it/s]Training (remove=24):  35%|███▍      | 244/700 [01:15<02:21,  3.22it/s]Training (remove=24):  35%|███▌      | 245/700 [01:15<02:21,  3.21it/s]Training (remove=24):  35%|███▌      | 246/700 [01:16<02:21,  3.21it/s]Training (remove=24):  35%|███▌      | 247/700 [01:16<02:20,  3.22it/s]Training (remove=24):  35%|███▌      | 248/700 [01:16<02:20,  3.21it/s]Training (remove=24):  36%|███▌      | 249/700 [01:17<02:20,  3.21it/s]Training (remove=24):  36%|███▌      | 250/700 [01:17<02:19,  3.22it/s]Training (remove=24):  36%|███▌      | 251/700 [01:17<02:19,  3.22it/s]Training (remove=24):  36%|███▌      | 252/700 [01:18<02:19,  3.21it/s]Training (remove=24):  36%|███▌      | 253/700 [01:18<02:18,  3.22it/s]Training (remove=24):  36%|███▋      | 254/700 [01:18<02:18,  3.22it/s]Training (remove=24):  36%|███▋      | 255/700 [01:19<02:18,  3.22it/s]Training (remove=24):  37%|███▋      | 256/700 [01:19<02:17,  3.23it/s]Training (remove=24):  37%|███▋      | 257/700 [01:19<02:17,  3.22it/s]Training (remove=24):  37%|███▋      | 258/700 [01:19<02:17,  3.22it/s]Training (remove=24):  37%|███▋      | 259/700 [01:20<02:16,  3.22it/s]Training (remove=24):  37%|███▋      | 260/700 [01:20<02:16,  3.22it/s]Training (remove=24):  37%|███▋      | 261/700 [01:20<02:16,  3.21it/s]Training (remove=24):  37%|███▋      | 262/700 [01:21<02:16,  3.22it/s]Training (remove=24):  38%|███▊      | 263/700 [01:21<02:15,  3.21it/s]Training (remove=24):  38%|███▊      | 264/700 [01:21<02:15,  3.21it/s]Training (remove=24):  38%|███▊      | 265/700 [01:22<02:15,  3.21it/s]Training (remove=24):  38%|███▊      | 266/700 [01:22<02:14,  3.22it/s]Training (remove=24):  38%|███▊      | 267/700 [01:22<02:14,  3.22it/s]Training (remove=24):  38%|███▊      | 268/700 [01:23<02:14,  3.22it/s]Training (remove=24):  38%|███▊      | 269/700 [01:23<02:13,  3.22it/s]Training (remove=24):  39%|███▊      | 270/700 [01:23<02:13,  3.22it/s]Training (remove=24):  39%|███▊      | 271/700 [01:23<02:13,  3.21it/s]Training (remove=24):  39%|███▉      | 272/700 [01:24<02:12,  3.22it/s]Training (remove=24):  39%|███▉      | 273/700 [01:24<02:12,  3.22it/s]Training (remove=24):  39%|███▉      | 274/700 [01:24<02:12,  3.22it/s]Training (remove=24):  39%|███▉      | 275/700 [01:25<02:11,  3.22it/s]Training (remove=24):  39%|███▉      | 276/700 [01:25<02:11,  3.22it/s]Training (remove=24):  40%|███▉      | 277/700 [01:25<02:11,  3.21it/s]Training (remove=24):  40%|███▉      | 278/700 [01:26<02:11,  3.21it/s]Training (remove=24):  40%|███▉      | 279/700 [01:26<02:10,  3.22it/s]Training (remove=24):  40%|████      | 280/700 [01:26<02:10,  3.22it/s]Training (remove=24):  40%|████      | 281/700 [01:27<02:10,  3.22it/s]Training (remove=24):  40%|████      | 282/700 [01:27<02:09,  3.22it/s]Training (remove=24):  40%|████      | 283/700 [01:27<02:09,  3.21it/s]Training (remove=24):  41%|████      | 284/700 [01:28<02:09,  3.21it/s]Training (remove=24):  41%|████      | 285/700 [01:28<02:09,  3.21it/s]Training (remove=24):  41%|████      | 286/700 [01:28<02:08,  3.22it/s]Training (remove=24):  41%|████      | 287/700 [01:28<02:08,  3.22it/s]Training (remove=24):  41%|████      | 288/700 [01:29<02:08,  3.21it/s]Training (remove=24):  41%|████▏     | 289/700 [01:29<02:08,  3.21it/s]Training (remove=24):  41%|████▏     | 290/700 [01:29<02:07,  3.21it/s]Training (remove=24):  42%|████▏     | 291/700 [01:30<02:07,  3.21it/s]Training (remove=24):  42%|████▏     | 292/700 [01:30<02:06,  3.22it/s]Training (remove=24):  42%|████▏     | 293/700 [01:30<02:06,  3.22it/s]Training (remove=24):  42%|████▏     | 294/700 [01:31<02:06,  3.21it/s]Training (remove=24):  42%|████▏     | 295/700 [01:31<02:05,  3.22it/s]Training (remove=24):  42%|████▏     | 296/700 [01:31<02:05,  3.22it/s]Training (remove=24):  42%|████▏     | 297/700 [01:32<02:05,  3.22it/s]Training (remove=24):  43%|████▎     | 298/700 [01:32<02:04,  3.22it/s]Training (remove=24):  43%|████▎     | 299/700 [01:32<02:04,  3.22it/s]Training (remove=24):  43%|████▎     | 300/700 [01:33<02:04,  3.22it/s]Training (remove=24):  43%|████▎     | 301/700 [01:33<02:03,  3.23it/s]Training (remove=24):  43%|████▎     | 302/700 [01:33<02:03,  3.22it/s]Training (remove=24):  43%|████▎     | 303/700 [01:33<02:03,  3.22it/s]Training (remove=24):  43%|████▎     | 304/700 [01:34<02:03,  3.22it/s]Training (remove=24):  44%|████▎     | 305/700 [01:34<02:02,  3.21it/s]Training (remove=24):  44%|████▎     | 306/700 [01:34<02:02,  3.22it/s]Training (remove=24):  44%|████▍     | 307/700 [01:35<02:02,  3.22it/s]Training (remove=24):  44%|████▍     | 308/700 [01:35<02:02,  3.21it/s]Training (remove=24):  44%|████▍     | 309/700 [01:35<02:01,  3.21it/s]Training (remove=24):  44%|████▍     | 310/700 [01:36<02:01,  3.21it/s]Training (remove=24):  44%|████▍     | 311/700 [01:36<02:01,  3.21it/s]Training (remove=24):  45%|████▍     | 312/700 [01:36<02:00,  3.21it/s]Training (remove=24):  45%|████▍     | 313/700 [01:37<02:00,  3.21it/s]Training (remove=24):  45%|████▍     | 314/700 [01:37<02:00,  3.21it/s]Training (remove=24):  45%|████▌     | 315/700 [01:37<01:59,  3.21it/s]Training (remove=24):  45%|████▌     | 316/700 [01:37<01:59,  3.21it/s]Training (remove=24):  45%|████▌     | 317/700 [01:38<01:59,  3.21it/s]Training (remove=24):  45%|████▌     | 318/700 [01:38<01:58,  3.22it/s]Training (remove=24):  46%|████▌     | 319/700 [01:38<01:58,  3.22it/s]Training (remove=24):  46%|████▌     | 320/700 [01:39<01:57,  3.22it/s]Training (remove=24):  46%|████▌     | 321/700 [01:39<01:57,  3.22it/s]Training (remove=24):  46%|████▌     | 322/700 [01:39<01:57,  3.22it/s]Training (remove=24):  46%|████▌     | 323/700 [01:40<01:57,  3.21it/s]Training (remove=24):  46%|████▋     | 324/700 [01:40<01:56,  3.22it/s]Training (remove=24):  46%|████▋     | 325/700 [01:40<01:56,  3.21it/s]Training (remove=24):  47%|████▋     | 326/700 [01:41<01:56,  3.21it/s]Training (remove=24):  47%|████▋     | 327/700 [01:41<01:56,  3.21it/s]Training (remove=24):  47%|████▋     | 328/700 [01:41<01:55,  3.21it/s]Training (remove=24):  47%|████▋     | 329/700 [01:42<01:55,  3.21it/s]Training (remove=24):  47%|████▋     | 330/700 [01:42<01:55,  3.22it/s]Training (remove=24):  47%|████▋     | 331/700 [01:42<01:54,  3.21it/s]Training (remove=24):  47%|████▋     | 332/700 [01:42<01:54,  3.22it/s]Training (remove=24):  48%|████▊     | 333/700 [01:43<01:54,  3.21it/s]Training (remove=24):  48%|████▊     | 334/700 [01:43<01:53,  3.21it/s]Training (remove=24):  48%|████▊     | 335/700 [01:43<01:53,  3.21it/s]Training (remove=24):  48%|████▊     | 336/700 [01:44<01:53,  3.21it/s]Training (remove=24):  48%|████▊     | 337/700 [01:44<01:53,  3.21it/s]Training (remove=24):  48%|████▊     | 338/700 [01:44<01:52,  3.21it/s]Training (remove=24):  48%|████▊     | 339/700 [01:45<01:52,  3.21it/s]Training (remove=24):  49%|████▊     | 340/700 [01:45<01:51,  3.21it/s]Training (remove=24):  49%|████▊     | 341/700 [01:45<01:51,  3.21it/s]Training (remove=24):  49%|████▉     | 342/700 [01:46<01:51,  3.21it/s]Training (remove=24):  49%|████▉     | 343/700 [01:46<01:51,  3.21it/s]Training (remove=24):  49%|████▉     | 344/700 [01:46<01:50,  3.21it/s]Training (remove=24):  49%|████▉     | 345/700 [01:47<01:50,  3.21it/s]Training (remove=24):  49%|████▉     | 346/700 [01:47<01:50,  3.21it/s]Training (remove=24):  50%|████▉     | 347/700 [01:47<01:49,  3.21it/s]Training (remove=24):  50%|████▉     | 348/700 [01:47<01:49,  3.21it/s]Training (remove=24):  50%|████▉     | 349/700 [01:48<01:49,  3.21it/s]Training (remove=24):  50%|█████     | 350/700 [01:48<01:48,  3.22it/s]Training (remove=24):  50%|█████     | 351/700 [01:48<01:48,  3.22it/s]Training (remove=24):  50%|█████     | 352/700 [01:49<01:48,  3.22it/s]Training (remove=24):  50%|█████     | 353/700 [01:49<01:47,  3.21it/s]Training (remove=24):  51%|█████     | 354/700 [01:49<01:47,  3.21it/s]Training (remove=24):  51%|█████     | 355/700 [01:50<01:47,  3.21it/s]Training (remove=24):  51%|█████     | 356/700 [01:50<01:47,  3.21it/s]Training (remove=24):  51%|█████     | 357/700 [01:50<01:46,  3.21it/s]Training (remove=24):  51%|█████     | 358/700 [01:51<01:46,  3.21it/s]Training (remove=24):  51%|█████▏    | 359/700 [01:51<01:46,  3.21it/s]Training (remove=24):  51%|█████▏    | 360/700 [01:51<01:46,  3.21it/s]Training (remove=24):  52%|█████▏    | 361/700 [01:51<01:45,  3.21it/s]Training (remove=24):  52%|█████▏    | 362/700 [01:52<01:45,  3.21it/s]Training (remove=24):  52%|█████▏    | 363/700 [01:52<01:44,  3.21it/s]Training (remove=24):  52%|█████▏    | 364/700 [01:52<01:44,  3.22it/s]Training (remove=24):  52%|█████▏    | 365/700 [01:53<01:44,  3.21it/s]Training (remove=24):  52%|█████▏    | 366/700 [01:53<01:44,  3.21it/s]Training (remove=24):  52%|█████▏    | 367/700 [01:53<01:43,  3.21it/s]Training (remove=24):  53%|█████▎    | 368/700 [01:54<01:43,  3.21it/s]Training (remove=24):  53%|█████▎    | 369/700 [01:54<01:43,  3.21it/s]Training (remove=24):  53%|█████▎    | 370/700 [01:54<01:42,  3.22it/s]Training (remove=24):  53%|█████▎    | 371/700 [01:55<01:42,  3.22it/s]Training (remove=24):  53%|█████▎    | 372/700 [01:55<01:42,  3.22it/s]Training (remove=24):  53%|█████▎    | 373/700 [01:55<01:41,  3.22it/s]Training (remove=24):  53%|█████▎    | 374/700 [01:56<01:41,  3.22it/s]Training (remove=24):  54%|█████▎    | 375/700 [01:56<01:41,  3.22it/s]Training (remove=24):  54%|█████▎    | 376/700 [01:56<01:40,  3.21it/s]Training (remove=24):  54%|█████▍    | 377/700 [01:56<01:40,  3.21it/s]Training (remove=24):  54%|█████▍    | 378/700 [01:57<01:40,  3.21it/s]Training (remove=24):  54%|█████▍    | 379/700 [01:57<01:40,  3.21it/s]Training (remove=24):  54%|█████▍    | 380/700 [01:57<01:39,  3.21it/s]Training (remove=24):  54%|█████▍    | 381/700 [01:58<01:39,  3.21it/s]Training (remove=24):  55%|█████▍    | 382/700 [01:58<01:39,  3.21it/s]Training (remove=24):  55%|█████▍    | 383/700 [01:58<01:38,  3.21it/s]Training (remove=24):  55%|█████▍    | 384/700 [01:59<01:38,  3.21it/s]Training (remove=24):  55%|█████▌    | 385/700 [01:59<01:37,  3.21it/s]Training (remove=24):  55%|█████▌    | 386/700 [01:59<01:37,  3.21it/s]Training (remove=24):  55%|█████▌    | 387/700 [02:00<01:37,  3.22it/s]Training (remove=24):  55%|█████▌    | 388/700 [02:00<01:36,  3.22it/s]Training (remove=24):  56%|█████▌    | 389/700 [02:00<01:36,  3.22it/s]Training (remove=24):  56%|█████▌    | 390/700 [02:01<01:36,  3.21it/s]Training (remove=24):  56%|█████▌    | 391/700 [02:01<01:36,  3.21it/s]Training (remove=24):  56%|█████▌    | 392/700 [02:01<01:35,  3.21it/s]Training (remove=24):  56%|█████▌    | 393/700 [02:01<01:35,  3.21it/s]Training (remove=24):  56%|█████▋    | 394/700 [02:02<01:35,  3.21it/s]Training (remove=24):  56%|█████▋    | 395/700 [02:02<01:35,  3.21it/s]Training (remove=24):  57%|█████▋    | 396/700 [02:02<01:34,  3.21it/s]Training (remove=24):  57%|█████▋    | 397/700 [02:03<01:34,  3.21it/s]Training (remove=24):  57%|█████▋    | 398/700 [02:03<01:34,  3.20it/s]Training (remove=24):  57%|█████▋    | 399/700 [02:03<01:33,  3.21it/s]Training (remove=24):  57%|█████▋    | 400/700 [02:04<01:33,  3.22it/s]Training (remove=24):  57%|█████▋    | 401/700 [02:04<01:32,  3.22it/s]Training (remove=24):  57%|█████▋    | 402/700 [02:04<01:32,  3.21it/s]Training (remove=24):  58%|█████▊    | 403/700 [02:05<01:32,  3.21it/s]Training (remove=24):  58%|█████▊    | 404/700 [02:05<01:32,  3.21it/s]Training (remove=24):  58%|█████▊    | 405/700 [02:05<01:31,  3.21it/s]Training (remove=24):  58%|█████▊    | 406/700 [02:06<01:31,  3.20it/s]Training (remove=24):  58%|█████▊    | 407/700 [02:06<01:31,  3.20it/s]Training (remove=24):  58%|█████▊    | 408/700 [02:06<01:31,  3.20it/s]Training (remove=24):  58%|█████▊    | 409/700 [02:06<01:30,  3.20it/s]Training (remove=24):  59%|█████▊    | 410/700 [02:07<01:30,  3.21it/s]Training (remove=24):  59%|█████▊    | 411/700 [02:07<01:30,  3.21it/s]Training (remove=24):  59%|█████▉    | 412/700 [02:07<01:29,  3.21it/s]Training (remove=24):  59%|█████▉    | 413/700 [02:08<01:29,  3.21it/s]Training (remove=24):  59%|█████▉    | 414/700 [02:08<01:29,  3.21it/s]Training (remove=24):  59%|█████▉    | 415/700 [02:08<01:28,  3.22it/s]Training (remove=24):  59%|█████▉    | 416/700 [02:09<01:28,  3.22it/s]Training (remove=24):  60%|█████▉    | 417/700 [02:09<01:28,  3.22it/s]Training (remove=24):  60%|█████▉    | 418/700 [02:09<01:27,  3.21it/s]Training (remove=24):  60%|█████▉    | 419/700 [02:10<01:27,  3.21it/s]Training (remove=24):  60%|██████    | 420/700 [02:10<01:27,  3.22it/s]Training (remove=24):  60%|██████    | 421/700 [02:10<01:26,  3.21it/s]Training (remove=24):  60%|██████    | 422/700 [02:10<01:26,  3.22it/s]Training (remove=24):  60%|██████    | 423/700 [02:11<01:26,  3.22it/s]Training (remove=24):  61%|██████    | 424/700 [02:11<01:25,  3.22it/s]Training (remove=24):  61%|██████    | 425/700 [02:11<01:25,  3.22it/s]Training (remove=24):  61%|██████    | 426/700 [02:12<01:25,  3.22it/s]Training (remove=24):  61%|██████    | 427/700 [02:12<01:24,  3.22it/s]Training (remove=24):  61%|██████    | 428/700 [02:12<01:24,  3.22it/s]Training (remove=24):  61%|██████▏   | 429/700 [02:13<01:24,  3.22it/s]Training (remove=24):  61%|██████▏   | 430/700 [02:13<01:23,  3.22it/s]Training (remove=24):  62%|██████▏   | 431/700 [02:13<01:23,  3.22it/s]Training (remove=24):  62%|██████▏   | 432/700 [02:14<01:23,  3.22it/s]Training (remove=24):  62%|██████▏   | 433/700 [02:14<01:23,  3.21it/s]Training (remove=24):  62%|██████▏   | 434/700 [02:14<01:22,  3.22it/s]Training (remove=24):  62%|██████▏   | 435/700 [02:15<01:22,  3.22it/s]Training (remove=24):  62%|██████▏   | 436/700 [02:15<01:21,  3.22it/s]Training (remove=24):  62%|██████▏   | 437/700 [02:15<01:21,  3.22it/s]Training (remove=24):  63%|██████▎   | 438/700 [02:15<01:21,  3.22it/s]Training (remove=24):  63%|██████▎   | 439/700 [02:16<01:20,  3.23it/s]Training (remove=24):  63%|██████▎   | 440/700 [02:16<01:20,  3.23it/s]Training (remove=24):  63%|██████▎   | 441/700 [02:16<01:20,  3.22it/s]Training (remove=24):  63%|██████▎   | 442/700 [02:17<01:20,  3.22it/s]Training (remove=24):  63%|██████▎   | 443/700 [02:17<01:19,  3.23it/s]Training (remove=24):  63%|██████▎   | 444/700 [02:17<01:19,  3.22it/s]Training (remove=24):  64%|██████▎   | 445/700 [02:18<01:19,  3.22it/s]Training (remove=24):  64%|██████▎   | 446/700 [02:18<01:19,  3.21it/s]Training (remove=24):  64%|██████▍   | 447/700 [02:18<01:18,  3.22it/s]Training (remove=24):  64%|██████▍   | 448/700 [02:19<01:18,  3.22it/s]Training (remove=24):  64%|██████▍   | 449/700 [02:19<01:17,  3.22it/s]Training (remove=24):  64%|██████▍   | 450/700 [02:19<01:17,  3.22it/s]Training (remove=24):  64%|██████▍   | 451/700 [02:19<01:17,  3.22it/s]Training (remove=24):  65%|██████▍   | 452/700 [02:20<01:17,  3.21it/s]Training (remove=24):  65%|██████▍   | 453/700 [02:20<01:16,  3.22it/s]Training (remove=24):  65%|██████▍   | 454/700 [02:20<01:16,  3.22it/s]Training (remove=24):  65%|██████▌   | 455/700 [02:21<01:16,  3.21it/s]Training (remove=24):  65%|██████▌   | 456/700 [02:21<01:15,  3.22it/s]Training (remove=24):  65%|██████▌   | 457/700 [02:21<01:15,  3.22it/s]Training (remove=24):  65%|██████▌   | 458/700 [02:22<01:15,  3.22it/s]Training (remove=24):  66%|██████▌   | 459/700 [02:22<01:14,  3.22it/s]Training (remove=24):  66%|██████▌   | 460/700 [02:22<01:14,  3.21it/s]Training (remove=24):  66%|██████▌   | 461/700 [02:23<01:14,  3.22it/s]Training (remove=24):  66%|██████▌   | 462/700 [02:23<01:13,  3.22it/s]Training (remove=24):  66%|██████▌   | 463/700 [02:23<01:13,  3.22it/s]Training (remove=24):  66%|██████▋   | 464/700 [02:24<01:13,  3.23it/s]Training (remove=24):  66%|██████▋   | 465/700 [02:24<01:12,  3.22it/s]Training (remove=24):  67%|██████▋   | 466/700 [02:24<01:12,  3.21it/s]Training (remove=24):  67%|██████▋   | 467/700 [02:24<01:12,  3.21it/s]Training (remove=24):  67%|██████▋   | 468/700 [02:25<01:12,  3.21it/s]Training (remove=24):  67%|██████▋   | 469/700 [02:25<01:11,  3.22it/s]Training (remove=24):  67%|██████▋   | 470/700 [02:25<01:11,  3.21it/s]Training (remove=24):  67%|██████▋   | 471/700 [02:26<01:11,  3.21it/s]Training (remove=24):  67%|██████▋   | 472/700 [02:26<01:10,  3.21it/s]Training (remove=24):  68%|██████▊   | 473/700 [02:26<01:10,  3.22it/s]Training (remove=24):  68%|██████▊   | 474/700 [02:27<01:10,  3.22it/s]Training (remove=24):  68%|██████▊   | 475/700 [02:27<01:09,  3.22it/s]Training (remove=24):  68%|██████▊   | 476/700 [02:27<01:09,  3.22it/s]Training (remove=24):  68%|██████▊   | 477/700 [02:28<01:09,  3.22it/s]Training (remove=24):  68%|██████▊   | 478/700 [02:28<01:09,  3.21it/s]Training (remove=24):  68%|██████▊   | 479/700 [02:28<01:08,  3.22it/s]Training (remove=24):  69%|██████▊   | 480/700 [02:29<01:08,  3.22it/s]Training (remove=24):  69%|██████▊   | 481/700 [02:29<01:08,  3.22it/s]Training (remove=24):  69%|██████▉   | 482/700 [02:29<01:07,  3.22it/s]Training (remove=24):  69%|██████▉   | 483/700 [02:29<01:07,  3.22it/s]Training (remove=24):  69%|██████▉   | 484/700 [02:30<01:07,  3.22it/s]Training (remove=24):  69%|██████▉   | 485/700 [02:30<01:06,  3.22it/s]Training (remove=24):  69%|██████▉   | 486/700 [02:30<01:06,  3.21it/s]Training (remove=24):  70%|██████▉   | 487/700 [02:31<01:06,  3.22it/s]Training (remove=24):  70%|██████▉   | 488/700 [02:31<01:05,  3.22it/s]Training (remove=24):  70%|██████▉   | 489/700 [02:31<01:05,  3.21it/s]Training (remove=24):  70%|███████   | 490/700 [02:32<01:05,  3.22it/s]Training (remove=24):  70%|███████   | 491/700 [02:32<01:04,  3.22it/s]Training (remove=24):  70%|███████   | 492/700 [02:32<01:04,  3.22it/s]Training (remove=24):  70%|███████   | 493/700 [02:33<01:04,  3.23it/s]Training (remove=24):  71%|███████   | 494/700 [02:33<01:03,  3.22it/s]Training (remove=24):  71%|███████   | 495/700 [02:33<01:03,  3.22it/s]Training (remove=24):  71%|███████   | 496/700 [02:33<01:03,  3.22it/s]Training (remove=24):  71%|███████   | 497/700 [02:34<01:02,  3.23it/s]Training (remove=24):  71%|███████   | 498/700 [02:34<01:02,  3.22it/s]Training (remove=24):  71%|███████▏  | 499/700 [02:34<01:02,  3.22it/s]Training (remove=24):  71%|███████▏  | 500/700 [02:35<01:02,  3.22it/s]Training (remove=24):  72%|███████▏  | 501/700 [02:35<01:01,  3.23it/s]Training (remove=24):  72%|███████▏  | 502/700 [02:35<01:01,  3.22it/s]Training (remove=24):  72%|███████▏  | 503/700 [02:36<01:01,  3.22it/s]Training (remove=24):  72%|███████▏  | 504/700 [02:36<01:00,  3.22it/s]Training (remove=24):  72%|███████▏  | 505/700 [02:36<01:00,  3.22it/s]Training (remove=24):  72%|███████▏  | 506/700 [02:37<01:00,  3.22it/s]Training (remove=24):  72%|███████▏  | 507/700 [02:37<01:00,  3.21it/s]Training (remove=24):  73%|███████▎  | 508/700 [02:37<00:59,  3.21it/s]Training (remove=24):  73%|███████▎  | 509/700 [02:38<00:59,  3.21it/s]Training (remove=24):  73%|███████▎  | 510/700 [02:38<00:59,  3.21it/s]Training (remove=24):  73%|███████▎  | 511/700 [02:38<00:58,  3.21it/s]Training (remove=24):  73%|███████▎  | 512/700 [02:38<00:58,  3.21it/s]Training (remove=24):  73%|███████▎  | 513/700 [02:39<00:58,  3.22it/s]Training (remove=24):  73%|███████▎  | 514/700 [02:39<00:57,  3.22it/s]Training (remove=24):  74%|███████▎  | 515/700 [02:39<00:57,  3.22it/s]Training (remove=24):  74%|███████▎  | 516/700 [02:40<00:57,  3.22it/s]Training (remove=24):  74%|███████▍  | 517/700 [02:40<00:56,  3.22it/s]Training (remove=24):  74%|███████▍  | 518/700 [02:40<00:56,  3.22it/s]Training (remove=24):  74%|███████▍  | 519/700 [02:41<00:56,  3.22it/s]Training (remove=24):  74%|███████▍  | 520/700 [02:41<00:55,  3.22it/s]Training (remove=24):  74%|███████▍  | 521/700 [02:41<00:55,  3.21it/s]Training (remove=24):  75%|███████▍  | 522/700 [02:42<00:55,  3.21it/s]Training (remove=24):  75%|███████▍  | 523/700 [02:42<00:55,  3.22it/s]Training (remove=24):  75%|███████▍  | 524/700 [02:42<00:54,  3.22it/s]Training (remove=24):  75%|███████▌  | 525/700 [02:42<00:54,  3.22it/s]Training (remove=24):  75%|███████▌  | 526/700 [02:43<00:54,  3.22it/s]Training (remove=24):  75%|███████▌  | 527/700 [02:43<00:53,  3.22it/s]Training (remove=24):  75%|███████▌  | 528/700 [02:43<00:53,  3.23it/s]Training (remove=24):  76%|███████▌  | 529/700 [02:44<00:53,  3.22it/s]Training (remove=24):  76%|███████▌  | 530/700 [02:44<00:52,  3.23it/s]Training (remove=24):  76%|███████▌  | 531/700 [02:44<00:52,  3.22it/s]Training (remove=24):  76%|███████▌  | 532/700 [02:45<00:52,  3.22it/s]Training (remove=24):  76%|███████▌  | 533/700 [02:45<00:51,  3.21it/s]Training (remove=24):  76%|███████▋  | 534/700 [02:45<00:51,  3.21it/s]Training (remove=24):  76%|███████▋  | 535/700 [02:46<00:51,  3.21it/s]Training (remove=24):  77%|███████▋  | 536/700 [02:46<00:51,  3.21it/s]Training (remove=24):  77%|███████▋  | 537/700 [02:46<00:50,  3.22it/s]Training (remove=24):  77%|███████▋  | 538/700 [02:47<00:50,  3.22it/s]Training (remove=24):  77%|███████▋  | 539/700 [02:47<00:50,  3.22it/s]Training (remove=24):  77%|███████▋  | 540/700 [02:47<00:49,  3.21it/s]Training (remove=24):  77%|███████▋  | 541/700 [02:47<00:49,  3.22it/s]Training (remove=24):  77%|███████▋  | 542/700 [02:48<00:49,  3.22it/s]Training (remove=24):  78%|███████▊  | 543/700 [02:48<00:48,  3.22it/s]Training (remove=24):  78%|███████▊  | 544/700 [02:48<00:48,  3.22it/s]Training (remove=24):  78%|███████▊  | 545/700 [02:49<00:48,  3.22it/s]Training (remove=24):  78%|███████▊  | 546/700 [02:49<00:47,  3.22it/s]Training (remove=24):  78%|███████▊  | 547/700 [02:49<00:47,  3.22it/s]Training (remove=24):  78%|███████▊  | 548/700 [02:50<00:47,  3.22it/s]Training (remove=24):  78%|███████▊  | 549/700 [02:50<00:46,  3.22it/s]Training (remove=24):  79%|███████▊  | 550/700 [02:50<00:46,  3.22it/s]Training (remove=24):  79%|███████▊  | 551/700 [02:51<00:46,  3.22it/s]Training (remove=24):  79%|███████▉  | 552/700 [02:51<00:46,  3.22it/s]Training (remove=24):  79%|███████▉  | 553/700 [02:51<00:45,  3.22it/s]Training (remove=24):  79%|███████▉  | 554/700 [02:52<00:45,  3.21it/s]Training (remove=24):  79%|███████▉  | 555/700 [02:52<00:45,  3.21it/s]Training (remove=24):  79%|███████▉  | 556/700 [02:52<00:44,  3.21it/s]Training (remove=24):  80%|███████▉  | 557/700 [02:52<00:44,  3.21it/s]Training (remove=24):  80%|███████▉  | 558/700 [02:53<00:44,  3.21it/s]Training (remove=24):  80%|███████▉  | 559/700 [02:53<00:43,  3.22it/s]Training (remove=24):  80%|████████  | 560/700 [02:53<00:43,  3.23it/s]Training (remove=24):  80%|████████  | 561/700 [02:54<00:43,  3.23it/s]Training (remove=24):  80%|████████  | 562/700 [02:54<00:42,  3.22it/s]Training (remove=24):  80%|████████  | 563/700 [02:54<00:42,  3.22it/s]Training (remove=24):  81%|████████  | 564/700 [02:55<00:42,  3.21it/s]Training (remove=24):  81%|████████  | 565/700 [02:55<00:42,  3.21it/s]Training (remove=24):  81%|████████  | 566/700 [02:55<00:41,  3.22it/s]Training (remove=24):  81%|████████  | 567/700 [02:56<00:41,  3.22it/s]Training (remove=24):  81%|████████  | 568/700 [02:56<00:40,  3.22it/s]Training (remove=24):  81%|████████▏ | 569/700 [02:56<00:40,  3.22it/s]Training (remove=24):  81%|████████▏ | 570/700 [02:56<00:40,  3.22it/s]Training (remove=24):  82%|████████▏ | 571/700 [02:57<00:40,  3.22it/s]Training (remove=24):  82%|████████▏ | 572/700 [02:57<00:39,  3.22it/s]Training (remove=24):  82%|████████▏ | 573/700 [02:57<00:39,  3.21it/s]Training (remove=24):  82%|████████▏ | 574/700 [02:58<00:39,  3.21it/s]Training (remove=24):  82%|████████▏ | 575/700 [02:58<00:38,  3.21it/s]Training (remove=24):  82%|████████▏ | 576/700 [02:58<00:38,  3.22it/s]Training (remove=24):  82%|████████▏ | 577/700 [02:59<00:38,  3.22it/s]Training (remove=24):  83%|████████▎ | 578/700 [02:59<00:37,  3.21it/s]Training (remove=24):  83%|████████▎ | 579/700 [02:59<00:37,  3.22it/s]Training (remove=24):  83%|████████▎ | 580/700 [03:00<00:37,  3.22it/s]Training (remove=24):  83%|████████▎ | 581/700 [03:00<00:36,  3.22it/s]Training (remove=24):  83%|████████▎ | 582/700 [03:00<00:36,  3.22it/s]Training (remove=24):  83%|████████▎ | 583/700 [03:01<00:36,  3.22it/s]Training (remove=24):  83%|████████▎ | 584/700 [03:01<00:35,  3.22it/s]Training (remove=24):  84%|████████▎ | 585/700 [03:01<00:35,  3.22it/s]Training (remove=24):  84%|████████▎ | 586/700 [03:01<00:35,  3.22it/s]Training (remove=24):  84%|████████▍ | 587/700 [03:02<00:35,  3.22it/s]Training (remove=24):  84%|████████▍ | 588/700 [03:02<00:34,  3.22it/s]Training (remove=24):  84%|████████▍ | 589/700 [03:02<00:34,  3.21it/s]Training (remove=24):  84%|████████▍ | 590/700 [03:03<00:34,  3.21it/s]Training (remove=24):  84%|████████▍ | 591/700 [03:03<00:33,  3.21it/s]Training (remove=24):  85%|████████▍ | 592/700 [03:03<00:33,  3.21it/s]Training (remove=24):  85%|████████▍ | 593/700 [03:04<00:33,  3.21it/s]Training (remove=24):  85%|████████▍ | 594/700 [03:04<00:33,  3.21it/s]Training (remove=24):  85%|████████▌ | 595/700 [03:04<00:32,  3.21it/s]Training (remove=24):  85%|████████▌ | 596/700 [03:05<00:32,  3.21it/s]Training (remove=24):  85%|████████▌ | 597/700 [03:05<00:32,  3.22it/s]Training (remove=24):  85%|████████▌ | 598/700 [03:05<00:31,  3.22it/s]Training (remove=24):  86%|████████▌ | 599/700 [03:05<00:31,  3.22it/s]Training (remove=24):  86%|████████▌ | 600/700 [03:06<00:31,  3.22it/s]Training (remove=24):  86%|████████▌ | 601/700 [03:06<00:30,  3.23it/s]Training (remove=24):  86%|████████▌ | 602/700 [03:06<00:30,  3.22it/s]Training (remove=24):  86%|████████▌ | 603/700 [03:07<00:30,  3.23it/s]Training (remove=24):  86%|████████▋ | 604/700 [03:07<00:29,  3.22it/s]Training (remove=24):  86%|████████▋ | 605/700 [03:07<00:29,  3.23it/s]Training (remove=24):  87%|████████▋ | 606/700 [03:08<00:29,  3.23it/s]Training (remove=24):  87%|████████▋ | 607/700 [03:08<00:28,  3.22it/s]Training (remove=24):  87%|████████▋ | 608/700 [03:08<00:28,  3.22it/s]Training (remove=24):  87%|████████▋ | 609/700 [03:09<00:28,  3.22it/s]Training (remove=24):  87%|████████▋ | 610/700 [03:09<00:27,  3.21it/s]Training (remove=24):  87%|████████▋ | 611/700 [03:09<00:27,  3.22it/s]Training (remove=24):  87%|████████▋ | 612/700 [03:10<00:27,  3.22it/s]Training (remove=24):  88%|████████▊ | 613/700 [03:10<00:27,  3.22it/s]Training (remove=24):  88%|████████▊ | 614/700 [03:10<00:26,  3.22it/s]Training (remove=24):  88%|████████▊ | 615/700 [03:10<00:26,  3.22it/s]Training (remove=24):  88%|████████▊ | 616/700 [03:11<00:26,  3.22it/s]Training (remove=24):  88%|████████▊ | 617/700 [03:11<00:25,  3.23it/s]Training (remove=24):  88%|████████▊ | 618/700 [03:11<00:25,  3.22it/s]Training (remove=24):  88%|████████▊ | 619/700 [03:12<00:25,  3.23it/s]Training (remove=24):  89%|████████▊ | 620/700 [03:12<00:24,  3.23it/s]Training (remove=24):  89%|████████▊ | 621/700 [03:12<00:24,  3.22it/s]Training (remove=24):  89%|████████▉ | 622/700 [03:13<00:24,  3.22it/s]Training (remove=24):  89%|████████▉ | 623/700 [03:13<00:23,  3.21it/s]Training (remove=24):  89%|████████▉ | 624/700 [03:13<00:23,  3.21it/s]Training (remove=24):  89%|████████▉ | 625/700 [03:14<00:23,  3.22it/s]Training (remove=24):  89%|████████▉ | 626/700 [03:14<00:22,  3.22it/s]Training (remove=24):  90%|████████▉ | 627/700 [03:14<00:22,  3.22it/s]Training (remove=24):  90%|████████▉ | 628/700 [03:14<00:22,  3.22it/s]Training (remove=24):  90%|████████▉ | 629/700 [03:15<00:22,  3.22it/s]Training (remove=24):  90%|█████████ | 630/700 [03:15<00:21,  3.22it/s]Training (remove=24):  90%|█████████ | 631/700 [03:15<00:21,  3.22it/s]Training (remove=24):  90%|█████████ | 632/700 [03:16<00:21,  3.22it/s]Training (remove=24):  90%|█████████ | 633/700 [03:16<00:20,  3.22it/s]Training (remove=24):  91%|█████████ | 634/700 [03:16<00:20,  3.22it/s]Training (remove=24):  91%|█████████ | 635/700 [03:17<00:20,  3.22it/s]Training (remove=24):  91%|█████████ | 636/700 [03:17<00:19,  3.22it/s]Training (remove=24):  91%|█████████ | 637/700 [03:17<00:19,  3.22it/s]Training (remove=24):  91%|█████████ | 638/700 [03:18<00:19,  3.22it/s]Training (remove=24):  91%|█████████▏| 639/700 [03:18<00:18,  3.22it/s]Training (remove=24):  91%|█████████▏| 640/700 [03:18<00:18,  3.22it/s]Training (remove=24):  92%|█████████▏| 641/700 [03:19<00:18,  3.22it/s]Training (remove=24):  92%|█████████▏| 642/700 [03:19<00:18,  3.22it/s]Training (remove=24):  92%|█████████▏| 643/700 [03:19<00:17,  3.22it/s]Training (remove=24):  92%|█████████▏| 644/700 [03:19<00:17,  3.22it/s]Training (remove=24):  92%|█████████▏| 645/700 [03:20<00:17,  3.22it/s]Training (remove=24):  92%|█████████▏| 646/700 [03:20<00:16,  3.22it/s]Training (remove=24):  92%|█████████▏| 647/700 [03:20<00:16,  3.21it/s]Training (remove=24):  93%|█████████▎| 648/700 [03:21<00:16,  3.21it/s]Training (remove=24):  93%|█████████▎| 649/700 [03:21<00:15,  3.21it/s]Training (remove=24):  93%|█████████▎| 650/700 [03:21<00:15,  3.22it/s]Training (remove=24):  93%|█████████▎| 651/700 [03:22<00:15,  3.22it/s]Training (remove=24):  93%|█████████▎| 652/700 [03:22<00:14,  3.22it/s]Training (remove=24):  93%|█████████▎| 653/700 [03:22<00:14,  3.22it/s]Training (remove=24):  93%|█████████▎| 654/700 [03:23<00:14,  3.22it/s]Training (remove=24):  94%|█████████▎| 655/700 [03:23<00:13,  3.22it/s]Training (remove=24):  94%|█████████▎| 656/700 [03:23<00:13,  3.22it/s]Training (remove=24):  94%|█████████▍| 657/700 [03:24<00:13,  3.21it/s]Training (remove=24):  94%|█████████▍| 658/700 [03:24<00:13,  3.21it/s]Training (remove=24):  94%|█████████▍| 659/700 [03:24<00:12,  3.21it/s]Training (remove=24):  94%|█████████▍| 660/700 [03:24<00:12,  3.22it/s]Training (remove=24):  94%|█████████▍| 661/700 [03:25<00:12,  3.22it/s]Training (remove=24):  95%|█████████▍| 662/700 [03:25<00:11,  3.21it/s]Training (remove=24):  95%|█████████▍| 663/700 [03:25<00:11,  3.21it/s]Training (remove=24):  95%|█████████▍| 664/700 [03:26<00:11,  3.22it/s]Training (remove=24):  95%|█████████▌| 665/700 [03:26<00:10,  3.22it/s]Training (remove=24):  95%|█████████▌| 666/700 [03:26<00:10,  3.22it/s]Training (remove=24):  95%|█████████▌| 667/700 [03:27<00:10,  3.22it/s]Training (remove=24):  95%|█████████▌| 668/700 [03:27<00:09,  3.22it/s]Training (remove=24):  96%|█████████▌| 669/700 [03:27<00:09,  3.21it/s]Training (remove=24):  96%|█████████▌| 670/700 [03:28<00:09,  3.22it/s]Training (remove=24):  96%|█████████▌| 671/700 [03:28<00:09,  3.22it/s]Training (remove=24):  96%|█████████▌| 672/700 [03:28<00:08,  3.23it/s]Training (remove=24):  96%|█████████▌| 673/700 [03:28<00:08,  3.22it/s]Training (remove=24):  96%|█████████▋| 674/700 [03:29<00:08,  3.21it/s]Training (remove=24):  96%|█████████▋| 675/700 [03:29<00:07,  3.21it/s]Training (remove=24):  97%|█████████▋| 676/700 [03:29<00:07,  3.21it/s]Training (remove=24):  97%|█████████▋| 677/700 [03:30<00:07,  3.21it/s]Training (remove=24):  97%|█████████▋| 678/700 [03:30<00:06,  3.21it/s]Training (remove=24):  97%|█████████▋| 679/700 [03:30<00:06,  3.22it/s]Training (remove=24):  97%|█████████▋| 680/700 [03:31<00:06,  3.21it/s]Training (remove=24):  97%|█████████▋| 681/700 [03:31<00:05,  3.22it/s]Training (remove=24):  97%|█████████▋| 682/700 [03:31<00:05,  3.21it/s]Training (remove=24):  98%|█████████▊| 683/700 [03:32<00:05,  3.21it/s]Training (remove=24):  98%|█████████▊| 684/700 [03:32<00:04,  3.21it/s]Training (remove=24):  98%|█████████▊| 685/700 [03:32<00:04,  3.22it/s]Training (remove=24):  98%|█████████▊| 686/700 [03:33<00:04,  3.22it/s]Training (remove=24):  98%|█████████▊| 687/700 [03:33<00:04,  3.21it/s]Training (remove=24):  98%|█████████▊| 688/700 [03:33<00:03,  3.22it/s]Training (remove=24):  98%|█████████▊| 689/700 [03:33<00:03,  3.22it/s]Training (remove=24):  99%|█████████▊| 690/700 [03:34<00:03,  3.23it/s]Training (remove=24):  99%|█████████▊| 691/700 [03:34<00:02,  3.23it/s]Training (remove=24):  99%|█████████▉| 692/700 [03:34<00:02,  3.22it/s]Training (remove=24):  99%|█████████▉| 693/700 [03:35<00:02,  3.22it/s]Training (remove=24):  99%|█████████▉| 694/700 [03:35<00:01,  3.22it/s]Training (remove=24):  99%|█████████▉| 695/700 [03:35<00:01,  3.22it/s]Training (remove=24):  99%|█████████▉| 696/700 [03:36<00:01,  3.21it/s]Training (remove=24): 100%|█████████▉| 697/700 [03:36<00:00,  3.21it/s]Training (remove=24): 100%|█████████▉| 698/700 [03:36<00:00,  3.22it/s]Training (remove=24): 100%|█████████▉| 699/700 [03:37<00:00,  3.22it/s]Training (remove=24): 100%|██████████| 700/700 [03:37<00:00,  3.22it/s]Training (remove=24): 100%|██████████| 700/700 [03:37<00:00,  3.22it/s]
Step 100 - Loss: 0.0530
Step 200 - Loss: 0.1469
Step 300 - Loss: 0.0158
Step 400 - Loss: 0.0657
Step 500 - Loss: 0.0778
Step 600 - Loss: 0.0035
Epoch 4 - Average Loss: 0.0813
Evaluating (remove=24):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   0%|          | 1/200 [00:01<05:43,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   1%|          | 2/200 [00:03<04:51,  1.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   2%|▏         | 3/200 [00:04<04:55,  1.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   2%|▏         | 4/200 [00:07<07:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   2%|▎         | 5/200 [00:11<08:19,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   3%|▎         | 6/200 [00:14<09:00,  2.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   4%|▎         | 7/200 [00:15<07:23,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   4%|▍         | 8/200 [00:18<08:17,  2.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   4%|▍         | 9/200 [00:22<08:54,  2.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   5%|▌         | 10/200 [00:25<09:17,  2.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   6%|▌         | 11/200 [00:26<07:51,  2.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   6%|▌         | 12/200 [00:29<08:30,  2.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   6%|▋         | 13/200 [00:32<07:55,  2.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   7%|▋         | 14/200 [00:33<07:06,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   8%|▊         | 15/200 [00:36<07:20,  2.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   8%|▊         | 16/200 [00:39<08:04,  2.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   8%|▊         | 17/200 [00:40<06:47,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):   9%|▉         | 18/200 [00:44<07:39,  2.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  10%|▉         | 19/200 [00:47<08:15,  2.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  10%|█         | 20/200 [00:49<07:29,  2.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  10%|█         | 21/200 [00:50<06:22,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  11%|█         | 22/200 [00:53<07:18,  2.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  12%|█▏        | 23/200 [00:55<06:13,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  12%|█▏        | 24/200 [00:58<07:10,  2.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  12%|█▎        | 25/200 [01:01<07:48,  2.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  13%|█▎        | 26/200 [01:02<06:33,  2.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  14%|█▎        | 27/200 [01:04<05:52,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  14%|█▍        | 28/200 [01:07<06:51,  2.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  14%|█▍        | 29/200 [01:10<07:32,  2.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  15%|█▌        | 30/200 [01:12<06:20,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  16%|█▌        | 31/200 [01:13<05:30,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  16%|█▌        | 32/200 [01:15<05:32,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  16%|█▋        | 33/200 [01:18<06:32,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  17%|█▋        | 34/200 [01:20<05:42,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  18%|█▊        | 35/200 [01:21<04:52,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  18%|█▊        | 36/200 [01:22<04:32,  1.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  18%|█▊        | 37/200 [01:24<04:22,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  19%|█▉        | 38/200 [01:27<05:39,  2.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  20%|█▉        | 39/200 [01:29<05:45,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  20%|██        | 40/200 [01:30<05:02,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  20%|██        | 41/200 [01:32<04:31,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  21%|██        | 42/200 [01:34<04:46,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  22%|██▏       | 43/200 [01:35<04:30,  1.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  22%|██▏       | 44/200 [01:38<05:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  22%|██▎       | 45/200 [01:40<05:20,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  23%|██▎       | 46/200 [01:43<06:11,  2.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  24%|██▎       | 47/200 [01:45<05:37,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  24%|██▍       | 48/200 [01:48<06:21,  2.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  24%|██▍       | 49/200 [01:52<06:51,  2.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  25%|██▌       | 50/200 [01:53<06:08,  2.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  26%|██▌       | 51/200 [01:56<05:58,  2.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  26%|██▌       | 52/200 [01:59<06:31,  2.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  26%|██▋       | 53/200 [02:02<06:35,  2.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  27%|██▋       | 54/200 [02:03<05:40,  2.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  28%|██▊       | 55/200 [02:04<04:43,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  28%|██▊       | 56/200 [02:08<05:36,  2.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  28%|██▊       | 57/200 [02:11<06:12,  2.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  29%|██▉       | 58/200 [02:14<06:17,  2.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  30%|██▉       | 59/200 [02:17<06:38,  2.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  30%|███       | 60/200 [02:19<05:59,  2.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  30%|███       | 61/200 [02:22<06:23,  2.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  31%|███       | 62/200 [02:24<05:51,  2.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  32%|███▏      | 63/200 [02:27<06:11,  2.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  32%|███▏      | 64/200 [02:30<06:07,  2.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  32%|███▎      | 65/200 [02:33<06:27,  2.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  33%|███▎      | 66/200 [02:36<06:39,  2.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  34%|███▎      | 67/200 [02:39<06:46,  3.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  34%|███▍      | 68/200 [02:41<05:37,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  34%|███▍      | 69/200 [02:43<05:35,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  35%|███▌      | 70/200 [02:47<05:59,  2.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  36%|███▌      | 71/200 [02:48<04:59,  2.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  36%|███▌      | 72/200 [02:51<05:32,  2.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  36%|███▋      | 73/200 [02:54<05:53,  2.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  37%|███▋      | 74/200 [02:57<05:35,  2.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  38%|███▊      | 75/200 [03:00<05:54,  2.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  38%|███▊      | 76/200 [03:03<06:05,  2.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  38%|███▊      | 77/200 [03:06<06:12,  3.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  39%|███▉      | 78/200 [03:10<06:17,  3.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  40%|███▉      | 79/200 [03:13<06:20,  3.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  40%|████      | 80/200 [03:16<06:19,  3.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  40%|████      | 81/200 [03:19<06:19,  3.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  41%|████      | 82/200 [03:23<06:17,  3.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  42%|████▏     | 83/200 [03:26<06:14,  3.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  42%|████▏     | 84/200 [03:28<05:19,  2.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  42%|████▎     | 85/200 [03:30<04:52,  2.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  43%|████▎     | 86/200 [03:31<03:52,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  44%|████▎     | 87/200 [03:34<04:30,  2.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  44%|████▍     | 88/200 [03:37<04:56,  2.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  44%|████▍     | 89/200 [03:40<05:13,  2.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  45%|████▌     | 90/200 [03:42<04:35,  2.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  46%|████▌     | 91/200 [03:45<04:56,  2.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  46%|████▌     | 92/200 [03:47<04:14,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  46%|████▋     | 93/200 [03:48<03:44,  2.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  47%|████▋     | 94/200 [03:50<03:30,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  48%|████▊     | 95/200 [03:52<03:20,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  48%|████▊     | 96/200 [03:54<03:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  48%|████▊     | 97/200 [03:58<04:16,  2.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  49%|████▉     | 98/200 [04:00<04:22,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  50%|████▉     | 99/200 [04:02<03:57,  2.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  50%|█████     | 100/200 [04:04<03:49,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  50%|█████     | 101/200 [04:06<03:30,  2.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  51%|█████     | 102/200 [04:08<03:19,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  52%|█████▏    | 103/200 [04:10<03:08,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  52%|█████▏    | 104/200 [04:13<03:43,  2.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  52%|█████▎    | 105/200 [04:16<04:07,  2.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  53%|█████▎    | 106/200 [04:19<04:22,  2.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  54%|█████▎    | 107/200 [04:21<03:40,  2.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  54%|█████▍    | 108/200 [04:22<03:14,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  55%|█████▍    | 109/200 [04:26<03:42,  2.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  55%|█████▌    | 110/200 [04:29<04:01,  2.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  56%|█████▌    | 111/200 [04:32<04:14,  2.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  56%|█████▌    | 112/200 [04:35<04:21,  2.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  56%|█████▋    | 113/200 [04:37<03:45,  2.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  57%|█████▋    | 114/200 [04:39<03:31,  2.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  57%|█████▊    | 115/200 [04:41<03:21,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  58%|█████▊    | 116/200 [04:43<02:57,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  58%|█████▊    | 117/200 [04:44<02:34,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  59%|█████▉    | 118/200 [04:47<03:06,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  60%|█████▉    | 119/200 [04:51<03:27,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  60%|██████    | 120/200 [04:54<03:40,  2.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  60%|██████    | 121/200 [04:57<03:48,  2.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  61%|██████    | 122/200 [05:00<03:53,  2.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  62%|██████▏   | 123/200 [05:03<03:45,  2.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  62%|██████▏   | 124/200 [05:04<02:55,  2.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  62%|██████▎   | 125/200 [05:06<02:40,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  63%|██████▎   | 126/200 [05:07<02:23,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  64%|██████▎   | 127/200 [05:08<02:03,  1.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  64%|██████▍   | 128/200 [05:10<01:57,  1.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  64%|██████▍   | 129/200 [05:11<01:57,  1.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  65%|██████▌   | 130/200 [05:15<02:28,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  66%|██████▌   | 131/200 [05:16<02:14,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  66%|██████▌   | 132/200 [05:17<01:50,  1.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  66%|██████▋   | 133/200 [05:18<01:46,  1.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  67%|██████▋   | 134/200 [05:20<01:43,  1.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  68%|██████▊   | 135/200 [05:23<02:13,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  68%|██████▊   | 136/200 [05:25<02:07,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  68%|██████▊   | 137/200 [05:27<02:00,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  69%|██████▉   | 138/200 [05:28<01:53,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  70%|██████▉   | 139/200 [05:31<02:07,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  70%|███████   | 140/200 [05:34<02:25,  2.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  70%|███████   | 141/200 [05:36<02:14,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  71%|███████   | 142/200 [05:39<02:28,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  72%|███████▏  | 143/200 [05:43<02:37,  2.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  72%|███████▏  | 144/200 [05:45<02:24,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  72%|███████▎  | 145/200 [05:47<02:11,  2.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  73%|███████▎  | 146/200 [05:49<02:12,  2.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  74%|███████▎  | 147/200 [05:51<01:53,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  74%|███████▍  | 148/200 [05:54<02:07,  2.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  74%|███████▍  | 149/200 [05:57<02:17,  2.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  75%|███████▌  | 150/200 [05:59<01:53,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  76%|███████▌  | 151/200 [06:01<01:52,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  76%|███████▌  | 152/200 [06:04<02:04,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  76%|███████▋  | 153/200 [06:05<01:43,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  77%|███████▋  | 154/200 [06:06<01:25,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  78%|███████▊  | 155/200 [06:08<01:20,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  78%|███████▊  | 156/200 [06:11<01:37,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  78%|███████▊  | 157/200 [06:15<01:48,  2.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  79%|███████▉  | 158/200 [06:18<01:54,  2.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  80%|███████▉  | 159/200 [06:20<01:39,  2.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  80%|████████  | 160/200 [06:23<01:44,  2.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  80%|████████  | 161/200 [06:25<01:37,  2.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  81%|████████  | 162/200 [06:26<01:21,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  82%|████████▏ | 163/200 [06:28<01:18,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  82%|████████▏ | 164/200 [06:30<01:11,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  82%|████████▎ | 165/200 [06:33<01:22,  2.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  83%|████████▎ | 166/200 [06:35<01:12,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  84%|████████▎ | 167/200 [06:38<01:21,  2.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  84%|████████▍ | 168/200 [06:39<01:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  84%|████████▍ | 169/200 [06:43<01:17,  2.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  85%|████████▌ | 170/200 [06:45<01:11,  2.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  86%|████████▌ | 171/200 [06:48<01:16,  2.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  86%|████████▌ | 172/200 [06:51<01:18,  2.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  86%|████████▋ | 173/200 [06:54<01:13,  2.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  87%|████████▋ | 174/200 [06:57<01:14,  2.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  88%|████████▊ | 175/200 [07:00<01:14,  2.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  88%|████████▊ | 176/200 [07:03<01:13,  3.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  88%|████████▊ | 177/200 [07:07<01:11,  3.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  89%|████████▉ | 178/200 [07:10<01:09,  3.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  90%|████████▉ | 179/200 [07:13<01:06,  3.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  90%|█████████ | 180/200 [07:16<01:03,  3.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  90%|█████████ | 181/200 [07:18<00:49,  2.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  91%|█████████ | 182/200 [07:20<00:46,  2.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  92%|█████████▏| 183/200 [07:21<00:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  92%|█████████▏| 184/200 [07:23<00:34,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  92%|█████████▎| 185/200 [07:26<00:33,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  93%|█████████▎| 186/200 [07:29<00:35,  2.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  94%|█████████▎| 187/200 [07:30<00:27,  2.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  94%|█████████▍| 188/200 [07:31<00:22,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  94%|█████████▍| 189/200 [07:35<00:24,  2.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  95%|█████████▌| 190/200 [07:36<00:21,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  96%|█████████▌| 191/200 [07:40<00:22,  2.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  96%|█████████▌| 192/200 [07:41<00:18,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  96%|█████████▋| 193/200 [07:45<00:18,  2.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  97%|█████████▋| 194/200 [07:48<00:16,  2.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  98%|█████████▊| 195/200 [07:50<00:12,  2.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  98%|█████████▊| 196/200 [07:53<00:10,  2.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  98%|█████████▊| 197/200 [07:56<00:08,  2.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24):  99%|█████████▉| 198/200 [07:59<00:05,  2.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24): 100%|█████████▉| 199/200 [08:03<00:03,  3.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=24): 100%|██████████| 200/200 [08:05<00:00,  2.90s/it]Evaluating (remove=24): 100%|██████████| 200/200 [08:05<00:00,  2.43s/it]
Epoch 4 - Accuracy: 0.1650
Epoch 5/10 - Removing 32 tokens
Training (remove=32):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=32):   2%|▏         | 13/700 [00:00<00:16, 40.49it/s]Training (remove=32):   3%|▎         | 18/700 [00:01<01:11,  9.59it/s]Training (remove=32):   3%|▎         | 23/700 [00:01<01:01, 11.06it/s]Training (remove=32):   4%|▎         | 25/700 [00:02<01:08,  9.91it/s]Training (remove=32):   4%|▍         | 29/700 [00:02<01:03, 10.64it/s]Training (remove=32):   4%|▍         | 31/700 [00:02<01:10,  9.50it/s]Training (remove=32):   5%|▌         | 36/700 [00:03<00:58, 11.29it/s]Training (remove=32):   7%|▋         | 48/700 [00:03<00:34, 18.86it/s]Training (remove=32):   7%|▋         | 51/700 [00:03<00:40, 16.16it/s]Training (remove=32):   8%|▊         | 58/700 [00:04<00:35, 17.93it/s]Training (remove=32):   9%|▊         | 60/700 [00:04<00:56, 11.30it/s]Training (remove=32):   9%|▉         | 62/700 [00:05<01:03, 10.11it/s]Training (remove=32):   9%|▉         | 66/700 [00:05<00:58, 10.79it/s]Training (remove=32):  10%|▉         | 68/700 [00:05<01:05,  9.60it/s]Training (remove=32):  10%|█         | 71/700 [00:05<01:05,  9.59it/s]Training (remove=32):  11%|█         | 76/700 [00:06<00:54, 11.38it/s]Training (remove=32):  11%|█▏        | 80/700 [00:06<00:52, 11.76it/s]Training (remove=32):  12%|█▏        | 82/700 [00:06<01:00, 10.19it/s]Training (remove=32):  12%|█▏        | 84/700 [00:07<01:07,  9.08it/s]Training (remove=32):  13%|█▎        | 90/700 [00:07<00:50, 12.06it/s]Training (remove=32):  13%|█▎        | 93/700 [00:07<00:53, 11.34it/s]Training (remove=32):  14%|█▎        | 95/700 [00:08<01:19,  7.61it/s]Training (remove=32):  14%|█▎        | 96/700 [00:08<01:32,  6.52it/s]Training (remove=32):  14%|█▍        | 97/700 [00:09<01:46,  5.66it/s]Training (remove=32):  14%|█▍        | 99/700 [00:09<01:42,  5.86it/s]Training (remove=32):  14%|█▍        | 100/700 [00:09<01:57,  5.12it/s]Training (remove=32):  16%|█▌        | 110/700 [00:10<00:46, 12.71it/s]Training (remove=32):  17%|█▋        | 116/700 [00:10<00:40, 14.53it/s]Training (remove=32):  17%|█▋        | 118/700 [00:10<00:47, 12.15it/s]Training (remove=32):  17%|█▋        | 121/700 [00:10<00:50, 11.39it/s]Training (remove=32):  19%|█▊        | 130/700 [00:11<00:34, 16.41it/s]Training (remove=32):  19%|█▉        | 132/700 [00:11<00:42, 13.47it/s]Training (remove=32):  19%|█▉        | 135/700 [00:11<00:45, 12.36it/s]Training (remove=32):  21%|██        | 144/700 [00:12<00:32, 17.22it/s]Training (remove=32):  21%|██        | 146/700 [00:12<00:39, 14.02it/s]Training (remove=32):  21%|██▏       | 149/700 [00:12<00:43, 12.72it/s]Training (remove=32):  22%|██▏       | 153/700 [00:13<00:42, 12.75it/s]Training (remove=32):  22%|██▏       | 155/700 [00:13<00:50, 10.84it/s]Training (remove=32):  23%|██▎       | 159/700 [00:13<00:47, 11.40it/s]Training (remove=32):  24%|██▍       | 170/700 [00:14<00:28, 18.38it/s]Training (remove=32):  25%|██▍       | 172/700 [00:14<00:35, 14.80it/s]Training (remove=32):  26%|██▌       | 183/700 [00:14<00:24, 20.73it/s]Training (remove=32):  27%|██▋       | 186/700 [00:15<00:29, 17.39it/s]Training (remove=32):  27%|██▋       | 191/700 [00:15<00:30, 16.93it/s]Training (remove=32):  28%|██▊       | 194/700 [00:15<00:34, 14.72it/s]Training (remove=32):  28%|██▊       | 196/700 [00:16<00:41, 12.24it/s]Training (remove=32):  29%|██▉       | 203/700 [00:16<00:32, 15.20it/s]Training (remove=32):  31%|███       | 215/700 [00:16<00:22, 21.90it/s]Training (remove=32):  31%|███       | 218/700 [00:16<00:26, 18.24it/s]Training (remove=32):  32%|███▏      | 223/700 [00:17<00:27, 17.57it/s]Training (remove=32):  32%|███▏      | 226/700 [00:17<00:31, 15.22it/s]Training (remove=32):  34%|███▍      | 237/700 [00:17<00:21, 21.06it/s]Training (remove=32):  34%|███▍      | 240/700 [00:18<00:26, 17.62it/s]Training (remove=32):  35%|███▍      | 242/700 [00:18<00:41, 11.02it/s]Training (remove=32):  35%|███▌      | 248/700 [00:19<00:34, 13.00it/s]Training (remove=32):  36%|███▌      | 250/700 [00:19<00:39, 11.28it/s]Training (remove=32):  36%|███▌      | 253/700 [00:19<00:41, 10.81it/s]Training (remove=32):  36%|███▋      | 255/700 [00:20<00:59,  7.51it/s]Training (remove=32):  37%|███▋      | 256/700 [00:20<01:08,  6.50it/s]Training (remove=32):  37%|███▋      | 258/700 [00:21<01:08,  6.48it/s]Training (remove=32):  37%|███▋      | 261/700 [00:21<01:00,  7.31it/s]Training (remove=32):  38%|███▊      | 264/700 [00:21<00:54,  7.93it/s]Training (remove=32):  38%|███▊      | 266/700 [00:21<00:57,  7.51it/s]Training (remove=32):  38%|███▊      | 268/700 [00:22<00:59,  7.21it/s]Training (remove=32):  39%|███▊      | 270/700 [00:22<01:01,  6.97it/s]Training (remove=32):  39%|███▉      | 273/700 [00:22<00:55,  7.73it/s]Training (remove=32):  39%|███▉      | 275/700 [00:23<00:57,  7.33it/s]Training (remove=32):  40%|████      | 283/700 [00:23<00:32, 12.67it/s]Training (remove=32):  41%|████      | 286/700 [00:23<00:35, 11.77it/s]Training (remove=32):  41%|████▏     | 289/700 [00:24<00:36, 11.12it/s]Training (remove=32):  42%|████▏     | 292/700 [00:24<00:38, 10.67it/s]Training (remove=32):  42%|████▏     | 297/700 [00:24<00:32, 12.23it/s]Training (remove=32):  43%|████▎     | 299/700 [00:25<00:38, 10.49it/s]Training (remove=32):  43%|████▎     | 301/700 [00:25<00:42,  9.29it/s]Training (remove=32):  44%|████▍     | 307/700 [00:25<00:32, 12.21it/s]Training (remove=32):  45%|████▌     | 318/700 [00:26<00:20, 18.91it/s]Training (remove=32):  46%|████▌     | 320/700 [00:26<00:25, 15.19it/s]Training (remove=32):  46%|████▌     | 322/700 [00:26<00:30, 12.56it/s]Training (remove=32):  47%|████▋     | 329/700 [00:26<00:24, 15.42it/s]Training (remove=32):  47%|████▋     | 332/700 [00:27<00:26, 13.70it/s]Training (remove=32):  48%|████▊     | 334/700 [00:27<00:31, 11.52it/s]Training (remove=32):  48%|████▊     | 336/700 [00:27<00:36, 10.00it/s]Training (remove=32):  48%|████▊     | 338/700 [00:28<00:40,  8.94it/s]Training (remove=32):  49%|████▉     | 344/700 [00:28<00:29, 12.01it/s]Training (remove=32):  50%|████▉     | 349/700 [00:28<00:26, 13.17it/s]Training (remove=32):  50%|█████     | 352/700 [00:29<00:28, 12.10it/s]Training (remove=32):  51%|█████     | 355/700 [00:29<00:30, 11.34it/s]Training (remove=32):  51%|█████     | 357/700 [00:29<00:34,  9.85it/s]Training (remove=32):  52%|█████▏    | 363/700 [00:30<00:26, 12.63it/s]Training (remove=32):  52%|█████▏    | 365/700 [00:30<00:31, 10.79it/s]Training (remove=32):  53%|█████▎    | 374/700 [00:30<00:20, 16.12it/s]Training (remove=32):  54%|█████▎    | 376/700 [00:31<00:24, 13.22it/s]Training (remove=32):  54%|█████▍    | 381/700 [00:31<00:22, 14.00it/s]Training (remove=32):  55%|█████▌    | 387/700 [00:31<00:20, 15.48it/s]Training (remove=32):  56%|█████▌    | 389/700 [00:31<00:24, 12.80it/s]Training (remove=32):  56%|█████▌    | 391/700 [00:32<00:28, 10.88it/s]Training (remove=32):  56%|█████▋    | 395/700 [00:32<00:26, 11.43it/s]Training (remove=32):  57%|█████▋    | 397/700 [00:32<00:30,  9.92it/s]Training (remove=32):  57%|█████▋    | 398/700 [00:33<00:38,  7.92it/s]Training (remove=32):  57%|█████▋    | 400/700 [00:33<00:40,  7.47it/s]Training (remove=32):  58%|█████▊    | 407/700 [00:33<00:24, 11.90it/s]Training (remove=32):  59%|█████▉    | 413/700 [00:34<00:20, 14.02it/s]Training (remove=32):  59%|█████▉    | 415/700 [00:34<00:24, 11.74it/s]Training (remove=32):  60%|█████▉    | 417/700 [00:34<00:27, 10.16it/s]Training (remove=32):  60%|█████▉    | 419/700 [00:35<00:31,  9.03it/s]Training (remove=32):  60%|██████    | 422/700 [00:35<00:30,  9.22it/s]Training (remove=32):  61%|██████    | 424/700 [00:35<00:32,  8.37it/s]Training (remove=32):  61%|██████    | 426/700 [00:36<00:35,  7.79it/s]Training (remove=32):  61%|██████▏   | 429/700 [00:36<00:32,  8.33it/s]Training (remove=32):  62%|██████▏   | 431/700 [00:36<00:34,  7.76it/s]Training (remove=32):  62%|██████▏   | 433/700 [00:37<00:36,  7.35it/s]Training (remove=32):  62%|██████▏   | 434/700 [00:37<00:43,  6.12it/s]Training (remove=32):  62%|██████▏   | 436/700 [00:37<00:42,  6.21it/s]Training (remove=32):  63%|██████▎   | 438/700 [00:37<00:41,  6.26it/s]Training (remove=32):  63%|██████▎   | 439/700 [00:38<00:48,  5.35it/s]Training (remove=32):  63%|██████▎   | 440/700 [00:38<00:55,  4.72it/s]Training (remove=32):  63%|██████▎   | 444/700 [00:38<00:35,  7.14it/s]Training (remove=32):  64%|██████▎   | 445/700 [00:39<00:42,  5.96it/s]Training (remove=32):  64%|██████▍   | 448/700 [00:39<00:35,  7.06it/s]Training (remove=32):  64%|██████▍   | 449/700 [00:39<00:42,  5.90it/s]Training (remove=32):  64%|██████▍   | 450/700 [00:40<00:49,  5.09it/s]Training (remove=32):  65%|██████▌   | 456/700 [00:40<00:26,  9.32it/s]Training (remove=32):  65%|██████▌   | 458/700 [00:40<00:28,  8.44it/s]Training (remove=32):  66%|██████▌   | 459/700 [00:41<00:35,  6.86it/s]Training (remove=32):  66%|██████▌   | 460/700 [00:41<00:41,  5.77it/s]Training (remove=32):  66%|██████▌   | 461/700 [00:41<00:47,  5.02it/s]Training (remove=32):  66%|██████▌   | 462/700 [00:41<00:53,  4.48it/s]Training (remove=32):  67%|██████▋   | 469/700 [00:42<00:23,  9.81it/s]Training (remove=32):  67%|██████▋   | 471/700 [00:42<00:26,  8.79it/s]Training (remove=32):  68%|██████▊   | 473/700 [00:42<00:28,  8.07it/s]Training (remove=32):  68%|██████▊   | 474/700 [00:43<00:38,  5.86it/s]Training (remove=32):  68%|██████▊   | 478/700 [00:43<00:28,  7.76it/s]Training (remove=32):  69%|██████▉   | 483/700 [00:44<00:21, 10.06it/s]Training (remove=32):  69%|██████▉   | 485/700 [00:44<00:23,  9.01it/s]Training (remove=32):  70%|███████   | 490/700 [00:44<00:19, 11.01it/s]Training (remove=32):  70%|███████   | 492/700 [00:44<00:21,  9.67it/s]Training (remove=32):  70%|███████   | 493/700 [00:45<00:26,  7.78it/s]Training (remove=32):  71%|███████   | 497/700 [00:45<00:21,  9.25it/s]Training (remove=32):  71%|███████▏  | 499/700 [00:45<00:23,  8.40it/s]Training (remove=32):  72%|███████▏  | 502/700 [00:46<00:22,  8.74it/s]Training (remove=32):  72%|███████▏  | 504/700 [00:46<00:24,  8.05it/s]Training (remove=32):  72%|███████▏  | 506/700 [00:46<00:25,  7.56it/s]Training (remove=32):  73%|███████▎  | 508/700 [00:47<00:26,  7.22it/s]Training (remove=32):  73%|███████▎  | 512/700 [00:47<00:21,  8.88it/s]Training (remove=32):  74%|███████▎  | 515/700 [00:47<00:20,  9.08it/s]Training (remove=32):  74%|███████▎  | 516/700 [00:48<00:25,  7.33it/s]Training (remove=32):  74%|███████▍  | 521/700 [00:48<00:18,  9.90it/s]Training (remove=32):  75%|███████▌  | 527/700 [00:48<00:13, 12.63it/s]Training (remove=32):  76%|███████▌  | 529/700 [00:49<00:15, 10.77it/s]Training (remove=32):  76%|███████▌  | 531/700 [00:49<00:17,  9.46it/s]Training (remove=32):  76%|███████▌  | 533/700 [00:49<00:19,  8.54it/s]Training (remove=32):  77%|███████▋  | 537/700 [00:49<00:16,  9.79it/s]Training (remove=32):  77%|███████▋  | 540/700 [00:50<00:16,  9.72it/s]Training (remove=32):  78%|███████▊  | 545/700 [00:50<00:13, 11.57it/s]Training (remove=32):  80%|████████  | 560/700 [00:50<00:06, 22.18it/s]Training (remove=32):  81%|████████  | 567/700 [00:51<00:05, 22.18it/s]Training (remove=32):  81%|████████▏ | 570/700 [00:51<00:07, 18.42it/s]Training (remove=32):  82%|████████▏ | 576/700 [00:51<00:06, 18.58it/s]Training (remove=32):  83%|████████▎ | 579/700 [00:52<00:07, 15.89it/s]Training (remove=32):  83%|████████▎ | 584/700 [00:52<00:07, 15.90it/s]Training (remove=32):  84%|████████▎ | 586/700 [00:53<00:11, 10.08it/s]Training (remove=32):  85%|████████▌ | 597/700 [00:53<00:06, 16.19it/s]Training (remove=32):  86%|████████▌ | 599/700 [00:53<00:07, 13.64it/s]Training (remove=32):  86%|████████▌ | 601/700 [00:54<00:08, 11.67it/s]Training (remove=32):  86%|████████▋ | 605/700 [00:54<00:07, 11.97it/s]Training (remove=32):  87%|████████▋ | 607/700 [00:54<00:08, 10.39it/s]Training (remove=32):  87%|████████▋ | 611/700 [00:55<00:08, 11.07it/s]Training (remove=32):  88%|████████▊ | 617/700 [00:55<00:06, 13.39it/s]Training (remove=32):  88%|████████▊ | 619/700 [00:55<00:09,  8.78it/s]Training (remove=32):  90%|████████▉ | 627/700 [00:56<00:05, 12.86it/s]Training (remove=32):  90%|█████████ | 633/700 [00:56<00:04, 14.45it/s]Training (remove=32):  91%|█████████ | 636/700 [00:56<00:04, 13.13it/s]Training (remove=32):  92%|█████████▏| 646/700 [00:57<00:02, 18.25it/s]Training (remove=32):  93%|█████████▎| 650/700 [00:57<00:02, 16.68it/s]Training (remove=32):  94%|█████████▎| 656/700 [00:57<00:02, 17.35it/s]Training (remove=32):  94%|█████████▍| 658/700 [00:58<00:02, 14.17it/s]Training (remove=32):  94%|█████████▍| 660/700 [00:58<00:03, 11.90it/s]Training (remove=32):  95%|█████████▍| 662/700 [00:58<00:03, 10.27it/s]Training (remove=32):  95%|█████████▍| 664/700 [00:59<00:03,  9.15it/s]Training (remove=32):  95%|█████████▌| 665/700 [00:59<00:04,  7.38it/s]Training (remove=32):  95%|█████████▌| 667/700 [00:59<00:04,  7.10it/s]Training (remove=32):  96%|█████████▌| 670/700 [01:00<00:03,  7.86it/s]Training (remove=32):  97%|█████████▋| 679/700 [01:00<00:01, 14.04it/s]Training (remove=32):  98%|█████████▊| 685/700 [01:00<00:00, 15.55it/s]Training (remove=32):  98%|█████████▊| 687/700 [01:00<00:01, 12.81it/s]Training (remove=32):  98%|█████████▊| 689/700 [01:01<00:01, 10.89it/s]Training (remove=32):  99%|█████████▊| 691/700 [01:01<00:00,  9.54it/s]Training (remove=32):  99%|█████████▉| 693/700 [01:01<00:00,  8.60it/s]Training (remove=32):  99%|█████████▉| 694/700 [01:02<00:00,  7.00it/s]Training (remove=32):  99%|█████████▉| 695/700 [01:02<00:00,  5.87it/s]Training (remove=32): 100%|██████████| 700/700 [01:02<00:00, 11.19it/s]
Step 100 - Loss: 0.0908
Epoch 5 - Average Loss: 0.1075
Evaluating (remove=32):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   1%|          | 2/200 [00:03<05:19,  1.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   2%|▏         | 3/200 [00:06<07:32,  2.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   2%|▎         | 5/200 [00:09<06:15,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   5%|▌         | 10/200 [00:12<03:25,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   8%|▊         | 15/200 [00:15<02:25,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   8%|▊         | 16/200 [00:17<03:04,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):   9%|▉         | 18/200 [00:21<03:31,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  12%|█▏        | 24/200 [00:24<02:26,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  14%|█▍        | 28/200 [00:27<02:22,  1.20it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  16%|█▋        | 33/200 [00:30<02:07,  1.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  19%|█▉        | 38/200 [00:34<01:56,  1.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  22%|██▏       | 44/200 [00:36<01:31,  1.71it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  23%|██▎       | 46/200 [00:39<01:53,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  24%|██▍       | 49/200 [00:42<02:03,  1.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  25%|██▌       | 50/200 [00:45<02:39,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  26%|██▌       | 51/200 [00:48<03:01,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  26%|██▌       | 52/200 [00:50<03:21,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  26%|██▋       | 53/200 [00:53<04:08,  1.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  28%|██▊       | 57/200 [00:56<02:54,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  30%|██▉       | 59/200 [00:59<03:06,  1.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  30%|███       | 60/200 [01:02<03:37,  1.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  31%|███       | 62/200 [01:05<03:36,  1.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  32%|███▏      | 63/200 [01:07<03:53,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  32%|███▏      | 64/200 [01:11<04:34,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  32%|███▎      | 65/200 [01:14<05:08,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  33%|███▎      | 66/200 [01:17<05:35,  2.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  34%|███▍      | 69/200 [01:19<03:25,  1.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  36%|███▌      | 72/200 [01:21<02:23,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  37%|███▋      | 74/200 [01:23<02:17,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  38%|███▊      | 77/200 [01:24<01:46,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  40%|███▉      | 79/200 [01:27<02:08,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  40%|████      | 81/200 [01:30<02:23,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  41%|████      | 82/200 [01:34<03:00,  1.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  42%|████▏     | 83/200 [01:37<03:35,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  42%|████▎     | 85/200 [01:40<03:22,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  44%|████▎     | 87/200 [01:42<02:40,  1.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  44%|████▍     | 88/200 [01:43<02:45,  1.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  44%|████▍     | 89/200 [01:46<03:24,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  46%|████▌     | 91/200 [01:49<03:06,  1.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  48%|████▊     | 96/200 [01:53<01:53,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  48%|████▊     | 97/200 [01:55<02:17,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  50%|████▉     | 99/200 [01:58<02:08,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  50%|█████     | 100/200 [02:01<02:38,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  52%|█████▏    | 104/200 [02:04<01:54,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  55%|█████▍    | 109/200 [02:07<01:25,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  56%|█████▌    | 112/200 [02:10<01:25,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  57%|█████▋    | 114/200 [02:13<01:35,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  58%|█████▊    | 116/200 [02:16<01:34,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  58%|█████▊    | 117/200 [02:18<01:42,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  60%|██████    | 121/200 [02:21<01:21,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  61%|██████    | 122/200 [02:24<01:44,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  62%|██████▏   | 123/200 [02:27<02:06,  1.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  65%|██████▌   | 130/200 [02:29<00:55,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  68%|██████▊   | 135/200 [02:33<00:47,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  68%|██████▊   | 136/200 [02:36<01:03,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  69%|██████▉   | 138/200 [02:37<00:56,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  70%|██████▉   | 139/200 [02:39<01:05,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  70%|███████   | 140/200 [02:42<01:25,  1.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  72%|███████▏  | 143/200 [02:46<01:12,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  72%|███████▏  | 144/200 [02:49<01:28,  1.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  72%|███████▎  | 145/200 [02:50<01:26,  1.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  73%|███████▎  | 146/200 [02:51<01:21,  1.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  75%|███████▌  | 150/200 [02:53<00:44,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  76%|███████▌  | 151/200 [02:55<00:48,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  76%|███████▌  | 152/200 [02:57<01:02,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  80%|███████▉  | 159/200 [02:59<00:24,  1.65it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  84%|████████▍ | 168/200 [03:01<00:12,  2.64it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  84%|████████▍ | 169/200 [03:04<00:18,  1.66it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  85%|████████▌ | 170/200 [03:05<00:20,  1.49it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  86%|████████▌ | 172/200 [03:08<00:24,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  86%|████████▋ | 173/200 [03:11<00:29,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  88%|████████▊ | 176/200 [03:12<00:21,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  88%|████████▊ | 177/200 [03:15<00:28,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  89%|████████▉ | 178/200 [03:17<00:27,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  90%|████████▉ | 179/200 [03:20<00:34,  1.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  91%|█████████ | 182/200 [03:23<00:24,  1.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  92%|█████████▎| 185/200 [03:26<00:18,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  96%|█████████▋| 193/200 [03:29<00:05,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  98%|█████████▊| 195/200 [03:33<00:04,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=32):  99%|█████████▉| 198/200 [03:34<00:01,  1.25it/s]Evaluating (remove=32): 100%|██████████| 200/200 [03:34<00:00,  1.07s/it]
Epoch 5 - Accuracy: 0.0200
Epoch 6/10 - Removing 40 tokens
Training (remove=40):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=40):  15%|█▌        | 105/700 [00:00<00:00, 1043.34it/s]Training (remove=40):  30%|███       | 210/700 [00:00<00:01, 374.89it/s] Training (remove=40):  38%|███▊      | 269/700 [00:01<00:02, 183.52it/s]Training (remove=40):  44%|████▎     | 305/700 [00:01<00:02, 157.91it/s]Training (remove=40):  47%|████▋     | 331/700 [00:01<00:02, 133.09it/s]Training (remove=40):  57%|█████▋    | 400/700 [00:02<00:01, 150.78it/s]Training (remove=40):  62%|██████▏   | 434/700 [00:02<00:01, 135.48it/s]Training (remove=40):  69%|██████▉   | 483/700 [00:02<00:01, 136.65it/s]Training (remove=40):  71%|███████▏  | 499/700 [00:03<00:02, 87.40it/s] Training (remove=40):  73%|███████▎  | 511/700 [00:03<00:02, 75.39it/s]Training (remove=40):  87%|████████▋ | 606/700 [00:04<00:00, 124.75it/s]Training (remove=40):  89%|████████▊ | 620/700 [00:04<00:00, 103.79it/s]Training (remove=40):  95%|█████████▍| 664/700 [00:04<00:00, 110.10it/s]Training (remove=40):  97%|█████████▋| 679/700 [00:05<00:00, 92.71it/s] Training (remove=40):  98%|█████████▊| 689/700 [00:05<00:00, 59.76it/s]Training (remove=40): 100%|██████████| 700/700 [00:05<00:00, 119.02it/s]
Epoch 6 - Average Loss: 0.1486
Evaluating (remove=40):   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  16%|█▋        | 33/200 [00:01<00:06, 25.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  30%|██▉       | 59/200 [00:04<00:11, 11.93it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  32%|███▏      | 63/200 [00:05<00:14,  9.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  33%|███▎      | 66/200 [00:08<00:23,  5.80it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  40%|███▉      | 79/200 [00:10<00:21,  5.69it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  57%|█████▋    | 114/200 [00:11<00:07, 10.92it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Evaluating (remove=40):  91%|█████████ | 182/200 [00:14<00:01, 15.50it/s]Evaluating (remove=40): 100%|██████████| 200/200 [00:14<00:00, 13.44it/s]
Epoch 6 - Accuracy: 0.0000
Epoch 7/10 - Removing 48 tokens
Training (remove=48):   0%|          | 0/700 [00:00<?, ?it/s]Training (remove=48):  15%|█▌        | 106/700 [00:00<00:00, 1049.66it/s]Training (remove=48):  30%|███       | 213/700 [00:00<00:00, 1056.13it/s]Training (remove=48):  46%|████▌     | 319/700 [00:00<00:00, 1057.19it/s]Training (remove=48):  61%|██████    | 426/700 [00:00<00:00, 1059.75it/s]Training (remove=48):  76%|███████▌  | 532/700 [00:00<00:00, 1057.63it/s]Training (remove=48):  91%|█████████▏| 639/700 [00:00<00:00, 1061.73it/s]Training (remove=48): 100%|██████████| 700/700 [00:00<00:00, 1059.43it/s]
Training completed. Best accuracy: 0.7950
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.47s/it]
Running Implicit CoT inference:   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   0%|          | 1/200 [00:00<03:12,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   1%|          | 2/200 [00:02<03:59,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 3/200 [00:03<03:47,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 4/200 [00:04<03:39,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▎         | 5/200 [00:05<03:34,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   3%|▎         | 6/200 [00:07<03:58,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▎         | 7/200 [00:08<03:46,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 8/200 [00:09<03:38,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 9/200 [00:10<03:52,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   5%|▌         | 10/200 [00:12<04:31,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 11/200 [00:13<03:56,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 12/200 [00:14<04:02,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▋         | 13/200 [00:16<04:06,  1.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   7%|▋         | 14/200 [00:16<03:39,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 15/200 [00:17<03:19,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 16/200 [00:19<03:29,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 17/200 [00:19<03:12,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   9%|▉         | 18/200 [00:21<03:23,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|▉         | 19/200 [00:22<03:19,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 20/200 [00:23<03:10,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 21/200 [00:24<02:58,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  11%|█         | 22/200 [00:25<02:55,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 23/200 [00:25<02:47,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 24/200 [00:27<03:03,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▎        | 25/200 [00:28<03:03,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  13%|█▎        | 26/200 [00:28<02:46,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▎        | 27/200 [00:30<02:51,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 28/200 [00:31<03:38,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 29/200 [00:33<03:26,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  15%|█▌        | 30/200 [00:33<03:07,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 31/200 [00:34<02:53,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 32/200 [00:35<02:43,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▋        | 33/200 [00:36<02:57,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  17%|█▋        | 34/200 [00:37<02:56,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 35/200 [00:38<02:44,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 36/200 [00:39<02:36,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 37/200 [00:40<02:25,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  19%|█▉        | 38/200 [00:41<02:37,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|█▉        | 39/200 [00:42<02:56,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 40/200 [00:43<02:43,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 41/200 [00:44<02:44,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  21%|██        | 42/200 [00:45<02:44,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 43/200 [00:46<02:34,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 44/200 [00:47<02:47,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▎       | 45/200 [00:48<02:40,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  23%|██▎       | 46/200 [00:50<02:42,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▎       | 47/200 [00:51<02:41,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 48/200 [00:52<02:36,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 49/200 [00:53<03:05,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  25%|██▌       | 50/200 [00:54<02:56,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 51/200 [00:55<02:51,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 52/200 [00:57<02:50,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▋       | 53/200 [00:58<02:59,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  27%|██▋       | 54/200 [00:59<02:42,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 55/200 [01:00<02:29,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 56/200 [01:01<02:34,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 57/200 [01:02<02:46,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  29%|██▉       | 58/200 [01:03<02:31,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|██▉       | 59/200 [01:05<02:47,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 60/200 [01:05<02:32,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 61/200 [01:07<02:39,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  31%|███       | 62/200 [01:08<02:34,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 63/200 [01:09<02:39,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 64/200 [01:10<02:34,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▎      | 65/200 [01:11<02:35,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  33%|███▎      | 66/200 [01:12<02:39,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▎      | 67/200 [01:14<02:32,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 68/200 [01:15<02:28,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 69/200 [01:16<02:24,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  35%|███▌      | 70/200 [01:17<02:21,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 71/200 [01:18<02:11,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 72/200 [01:19<02:12,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▋      | 73/200 [01:20<02:12,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  37%|███▋      | 74/200 [01:21<02:28,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 75/200 [01:22<02:31,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 76/200 [01:23<02:16,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 77/200 [01:24<02:02,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  39%|███▉      | 78/200 [01:25<02:11,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|███▉      | 79/200 [01:27<02:17,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 80/200 [01:28<02:28,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 81/200 [01:29<02:28,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  41%|████      | 82/200 [01:30<02:21,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 83/200 [01:32<02:15,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 84/200 [01:33<02:10,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▎     | 85/200 [01:34<02:29,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  43%|████▎     | 86/200 [01:35<02:09,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▎     | 87/200 [01:36<01:54,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 88/200 [01:37<02:06,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 89/200 [01:39<02:17,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  45%|████▌     | 90/200 [01:40<02:11,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 91/200 [01:41<02:09,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 92/200 [01:42<02:00,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▋     | 93/200 [01:43<01:47,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  47%|████▋     | 94/200 [01:43<01:41,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 95/200 [01:45<01:54,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 96/200 [01:46<02:05,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 97/200 [01:48<02:03,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  49%|████▉     | 98/200 [01:49<01:57,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|████▉     | 99/200 [01:50<01:53,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 100/200 [01:50<01:44,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 101/200 [01:51<01:37,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  51%|█████     | 102/200 [01:52<01:35,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 103/200 [01:53<01:34,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 104/200 [01:56<02:18,  1.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▎    | 105/200 [01:57<02:09,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  53%|█████▎    | 106/200 [01:58<01:59,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▎    | 107/200 [01:59<02:01,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▍    | 108/200 [02:00<01:50,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▍    | 109/200 [02:02<01:51,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▌    | 110/200 [02:03<01:51,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 111/200 [02:04<01:51,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 112/200 [02:05<01:50,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▋    | 113/200 [02:06<01:38,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▋    | 114/200 [02:08<01:49,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▊    | 115/200 [02:09<01:45,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 116/200 [02:10<01:34,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 117/200 [02:11<01:26,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  59%|█████▉    | 118/200 [02:12<01:31,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|█████▉    | 119/200 [02:13<01:36,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 120/200 [02:15<01:37,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 121/200 [02:16<01:29,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  61%|██████    | 122/200 [02:17<01:31,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 123/200 [02:18<01:37,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 124/200 [02:19<01:24,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▎   | 125/200 [02:20<01:22,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  63%|██████▎   | 126/200 [02:21<01:13,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▎   | 127/200 [02:22<01:09,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 128/200 [02:23<01:06,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 129/200 [02:24<01:03,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  65%|██████▌   | 130/200 [02:24<01:01,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 131/200 [02:25<01:02,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 132/200 [02:26<00:58,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▋   | 133/200 [02:27<00:57,  1.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  67%|██████▋   | 134/200 [02:28<00:54,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 135/200 [02:29<01:00,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 136/200 [02:30<01:01,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 137/200 [02:31<01:00,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  69%|██████▉   | 138/200 [02:32<00:55,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|██████▉   | 139/200 [02:33<00:57,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 140/200 [02:34<01:10,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 141/200 [02:35<01:03,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  71%|███████   | 142/200 [02:37<01:17,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 143/200 [02:38<01:13,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 144/200 [02:39<01:06,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▎  | 145/200 [02:40<00:57,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  73%|███████▎  | 146/200 [02:41<00:57,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▎  | 147/200 [02:42<00:56,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 148/200 [02:44<01:06,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 149/200 [02:45<01:05,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  75%|███████▌  | 150/200 [02:47<01:05,  1.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 151/200 [02:47<00:55,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 152/200 [02:49<01:05,  1.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▋  | 153/200 [02:50<00:55,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  77%|███████▋  | 154/200 [02:51<00:49,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 155/200 [02:52<00:52,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 156/200 [02:54<00:55,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 157/200 [02:55<00:56,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  79%|███████▉  | 158/200 [02:56<00:51,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|███████▉  | 159/200 [02:57<00:45,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 160/200 [02:59<00:50,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 161/200 [03:00<00:46,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  81%|████████  | 162/200 [03:01<00:44,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 163/200 [03:02<00:41,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 164/200 [03:03<00:38,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▎ | 165/200 [03:04<00:44,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  83%|████████▎ | 166/200 [03:06<00:41,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▎ | 167/200 [03:07<00:40,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 168/200 [03:08<00:34,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 169/200 [03:09<00:36,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  85%|████████▌ | 170/200 [03:10<00:31,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 171/200 [03:11<00:34,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 172/200 [03:12<00:31,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▋ | 173/200 [03:13<00:27,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  87%|████████▋ | 174/200 [03:14<00:27,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 175/200 [03:15<00:27,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 176/200 [03:16<00:24,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 177/200 [03:18<00:26,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  89%|████████▉ | 178/200 [03:19<00:26,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|████████▉ | 179/200 [03:20<00:25,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 180/200 [03:22<00:26,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 181/200 [03:23<00:22,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  91%|█████████ | 182/200 [03:24<00:19,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 183/200 [03:25<00:18,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 184/200 [03:26<00:17,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▎| 185/200 [03:27<00:15,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  93%|█████████▎| 186/200 [03:28<00:14,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▎| 187/200 [03:29<00:12,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 188/200 [03:29<00:11,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 189/200 [03:30<00:10,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  95%|█████████▌| 190/200 [03:31<00:09,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 191/200 [03:33<00:10,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 192/200 [03:34<00:09,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▋| 193/200 [03:35<00:08,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  97%|█████████▋| 194/200 [03:37<00:07,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 195/200 [03:38<00:05,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 196/200 [03:39<00:04,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 197/200 [03:40<00:03,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  99%|█████████▉| 198/200 [03:41<00:02,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|█████████▉| 199/200 [03:42<00:01,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|██████████| 200/200 [03:44<00:00,  1.13s/it]Running Implicit CoT inference: 100%|██████████| 200/200 [03:44<00:00,  1.12s/it]
Running Implicit CoT inference:   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   0%|          | 1/200 [00:00<03:12,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   1%|          | 2/200 [00:02<03:59,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 3/200 [00:03<04:14,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 4/200 [00:04<03:55,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▎         | 5/200 [00:05<03:44,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   3%|▎         | 6/200 [00:07<03:58,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▎         | 7/200 [00:08<03:47,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 8/200 [00:09<03:38,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 9/200 [00:10<03:45,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   5%|▌         | 10/200 [00:12<04:27,  1.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 11/200 [00:13<03:54,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 12/200 [00:14<04:01,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▋         | 13/200 [00:16<04:05,  1.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   7%|▋         | 14/200 [00:17<03:38,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 15/200 [00:17<03:19,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 16/200 [00:19<03:28,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 17/200 [00:20<03:11,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   9%|▉         | 18/200 [00:21<03:22,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|▉         | 19/200 [00:22<03:18,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 20/200 [00:23<03:10,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 21/200 [00:24<02:58,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  11%|█         | 22/200 [00:25<02:55,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 23/200 [00:25<02:47,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 24/200 [00:27<03:03,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▎        | 25/200 [00:28<03:03,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  13%|█▎        | 26/200 [00:29<02:46,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▎        | 27/200 [00:30<02:51,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 28/200 [00:32<03:37,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 29/200 [00:33<03:26,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  15%|█▌        | 30/200 [00:33<03:07,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 31/200 [00:34<02:53,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 32/200 [00:35<02:43,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▋        | 33/200 [00:36<02:52,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  17%|█▋        | 34/200 [00:37<02:52,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 35/200 [00:38<02:42,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 36/200 [00:39<02:40,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 37/200 [00:40<02:27,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  19%|█▉        | 38/200 [00:41<02:39,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|█▉        | 39/200 [00:42<02:42,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 40/200 [00:43<02:34,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 41/200 [00:44<02:37,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  21%|██        | 42/200 [00:45<02:40,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 43/200 [00:46<02:31,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 44/200 [00:47<02:49,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▎       | 45/200 [00:48<02:47,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  23%|██▎       | 46/200 [00:50<02:45,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▎       | 47/200 [00:51<02:44,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 48/200 [00:52<02:37,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 49/200 [00:53<03:06,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  25%|██▌       | 50/200 [00:54<02:43,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 51/200 [00:55<02:41,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 52/200 [00:56<02:43,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▋       | 53/200 [00:58<02:54,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  27%|██▋       | 54/200 [00:58<02:38,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 55/200 [00:59<02:22,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 56/200 [01:00<02:25,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 57/200 [01:01<02:26,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  29%|██▉       | 58/200 [01:02<02:18,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|██▉       | 59/200 [01:04<02:38,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 60/200 [01:04<02:26,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 61/200 [01:06<02:34,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  31%|███       | 62/200 [01:07<02:49,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 63/200 [01:09<02:49,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 64/200 [01:10<02:41,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▎      | 65/200 [01:11<02:40,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  33%|███▎      | 66/200 [01:12<02:43,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▎      | 67/200 [01:13<02:35,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 68/200 [01:14<02:30,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 69/200 [01:15<02:22,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  35%|███▌      | 70/200 [01:16<02:20,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 71/200 [01:17<02:10,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 72/200 [01:18<02:15,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▋      | 73/200 [01:19<02:14,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  37%|███▋      | 74/200 [01:21<02:29,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 75/200 [01:22<02:32,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 76/200 [01:23<02:17,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 77/200 [01:24<02:02,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  39%|███▉      | 78/200 [01:25<02:12,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|███▉      | 79/200 [01:26<02:02,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 80/200 [01:27<02:18,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 81/200 [01:29<02:21,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  41%|████      | 82/200 [01:30<02:12,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 83/200 [01:31<02:09,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 84/200 [01:32<02:06,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▎     | 85/200 [01:33<02:26,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  43%|████▎     | 86/200 [01:34<02:07,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▎     | 87/200 [01:35<01:53,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 88/200 [01:36<02:05,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 89/200 [01:37<02:09,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  45%|████▌     | 90/200 [01:39<02:05,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 91/200 [01:40<02:08,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 92/200 [01:41<02:13,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▋     | 93/200 [01:42<02:03,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  47%|████▋     | 94/200 [01:43<01:52,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 95/200 [01:44<02:01,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 96/200 [01:46<02:10,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 97/200 [01:47<02:06,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  49%|████▉     | 98/200 [01:48<02:00,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|████▉     | 99/200 [01:49<01:55,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 100/200 [01:50<01:45,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 101/200 [01:51<01:38,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  51%|█████     | 102/200 [01:52<01:36,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 103/200 [01:53<01:37,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 104/200 [01:55<02:20,  1.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▎    | 105/200 [01:57<02:10,  1.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  53%|█████▎    | 106/200 [01:58<02:00,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▎    | 107/200 [01:59<01:53,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▍    | 108/200 [02:00<01:50,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▍    | 109/200 [02:01<01:51,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▌    | 110/200 [02:02<01:51,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 111/200 [02:03<01:42,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 112/200 [02:05<01:44,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▋    | 113/200 [02:06<01:34,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▋    | 114/200 [02:07<01:46,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▊    | 115/200 [02:08<01:43,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 116/200 [02:09<01:33,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 117/200 [02:10<01:25,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  59%|█████▉    | 118/200 [02:11<01:30,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|█████▉    | 119/200 [02:13<01:36,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 120/200 [02:14<01:37,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 121/200 [02:15<01:32,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  61%|██████    | 122/200 [02:16<01:23,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 123/200 [02:17<01:32,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 124/200 [02:18<01:23,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▎   | 125/200 [02:20<01:28,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  63%|██████▎   | 126/200 [02:20<01:17,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▎   | 127/200 [02:21<01:12,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 128/200 [02:22<01:08,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 129/200 [02:23<01:05,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  65%|██████▌   | 130/200 [02:24<01:02,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 131/200 [02:25<01:03,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 132/200 [02:26<01:01,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▋   | 133/200 [02:26<00:59,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  67%|██████▋   | 134/200 [02:27<00:55,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 135/200 [02:28<01:01,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 136/200 [02:29<01:02,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 137/200 [02:30<01:01,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  69%|██████▉   | 138/200 [02:31<00:56,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|██████▉   | 139/200 [02:32<00:58,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 140/200 [02:34<01:08,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 141/200 [02:34<01:00,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  71%|███████   | 142/200 [02:36<01:14,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 143/200 [02:38<01:11,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 144/200 [02:39<01:05,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▎  | 145/200 [02:39<00:57,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  73%|███████▎  | 146/200 [02:40<00:56,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▎  | 147/200 [02:41<00:55,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 148/200 [02:43<01:01,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 149/200 [02:44<01:01,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  75%|███████▌  | 150/200 [02:46<01:03,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 151/200 [02:46<00:54,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 152/200 [02:48<01:04,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▋  | 153/200 [02:49<00:54,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  77%|███████▋  | 154/200 [02:50<00:47,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 155/200 [02:51<00:47,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 156/200 [02:52<00:52,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 157/200 [02:54<00:53,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  79%|███████▉  | 158/200 [02:55<00:49,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|███████▉  | 159/200 [02:56<00:44,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 160/200 [02:57<00:49,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 161/200 [02:58<00:43,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  81%|████████  | 162/200 [02:59<00:40,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 163/200 [03:00<00:39,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 164/200 [03:01<00:37,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▎ | 165/200 [03:03<00:43,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  83%|████████▎ | 166/200 [03:04<00:40,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▎ | 167/200 [03:05<00:40,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 168/200 [03:06<00:34,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 169/200 [03:07<00:36,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  85%|████████▌ | 170/200 [03:08<00:31,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 171/200 [03:09<00:34,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 172/200 [03:10<00:31,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▋ | 173/200 [03:11<00:27,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  87%|████████▋ | 174/200 [03:12<00:27,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 175/200 [03:14<00:27,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 176/200 [03:15<00:27,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 177/200 [03:16<00:26,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  89%|████████▉ | 178/200 [03:17<00:25,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|████████▉ | 179/200 [03:18<00:25,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 180/200 [03:20<00:28,  1.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 181/200 [03:21<00:24,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  91%|█████████ | 182/200 [03:22<00:20,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 183/200 [03:23<00:19,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 184/200 [03:24<00:18,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▎| 185/200 [03:25<00:15,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  93%|█████████▎| 186/200 [03:26<00:14,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▎| 187/200 [03:27<00:12,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 188/200 [03:28<00:11,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 189/200 [03:29<00:11,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  95%|█████████▌| 190/200 [03:30<00:10,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 191/200 [03:32<00:11,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 192/200 [03:33<00:10,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▋| 193/200 [03:35<00:08,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  97%|█████████▋| 194/200 [03:36<00:08,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 195/200 [03:37<00:06,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 196/200 [03:38<00:04,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 197/200 [03:39<00:03,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  99%|█████████▉| 198/200 [03:40<00:02,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|█████████▉| 199/200 [03:41<00:01,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|██████████| 200/200 [03:42<00:00,  1.10s/it]Running Implicit CoT inference: 100%|██████████| 200/200 [03:42<00:00,  1.11s/it]
Running Implicit CoT inference:   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   0%|          | 1/200 [00:00<03:13,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   1%|          | 2/200 [00:02<04:00,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 3/200 [00:03<04:15,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 4/200 [00:04<03:55,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▎         | 5/200 [00:05<03:44,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   3%|▎         | 6/200 [00:07<04:04,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▎         | 7/200 [00:08<03:50,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 8/200 [00:09<03:40,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 9/200 [00:10<03:46,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   5%|▌         | 10/200 [00:12<04:21,  1.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 11/200 [00:13<04:08,  1.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 12/200 [00:15<04:10,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▋         | 13/200 [00:16<04:12,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   7%|▋         | 14/200 [00:17<03:42,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 15/200 [00:18<03:22,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 16/200 [00:19<03:31,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 17/200 [00:20<03:13,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   9%|▉         | 18/200 [00:21<03:24,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|▉         | 19/200 [00:22<03:20,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 20/200 [00:23<03:11,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 21/200 [00:24<02:58,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  11%|█         | 22/200 [00:25<02:55,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 23/200 [00:26<02:47,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 24/200 [00:27<03:04,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▎        | 25/200 [00:29<03:26,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  13%|█▎        | 26/200 [00:29<03:13,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▎        | 27/200 [00:31<03:09,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 28/200 [00:32<03:50,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 29/200 [00:34<03:35,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  15%|█▌        | 30/200 [00:34<03:13,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 31/200 [00:35<02:57,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 32/200 [00:36<02:51,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▋        | 33/200 [00:37<02:58,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  17%|█▋        | 34/200 [00:38<02:57,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 35/200 [00:39<02:45,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 36/200 [00:40<02:46,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 37/200 [00:41<02:32,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  19%|█▉        | 38/200 [00:42<02:42,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|█▉        | 39/200 [00:43<02:44,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 40/200 [00:44<02:35,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 41/200 [00:45<02:38,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  21%|██        | 42/200 [00:46<02:40,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 43/200 [00:47<02:31,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 44/200 [00:48<02:35,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▎       | 45/200 [00:49<02:37,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  23%|██▎       | 46/200 [00:50<02:39,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▎       | 47/200 [00:51<02:39,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 48/200 [00:52<02:34,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 49/200 [00:54<02:44,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  25%|██▌       | 50/200 [00:55<02:42,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 51/200 [00:56<02:40,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 52/200 [00:57<02:57,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▋       | 53/200 [00:58<02:50,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  27%|██▋       | 54/200 [00:59<02:35,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 55/200 [01:00<02:25,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 56/200 [01:01<02:31,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 57/200 [01:03<02:44,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  29%|██▉       | 58/200 [01:03<02:30,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|██▉       | 59/200 [01:05<02:47,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 60/200 [01:06<02:32,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 61/200 [01:07<02:39,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  31%|███       | 62/200 [01:08<02:38,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 63/200 [01:09<02:34,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 64/200 [01:10<02:30,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▎      | 65/200 [01:11<02:32,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  33%|███▎      | 66/200 [01:13<02:36,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▎      | 67/200 [01:14<02:26,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 68/200 [01:15<02:24,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 69/200 [01:16<02:22,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  35%|███▌      | 70/200 [01:17<02:20,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 71/200 [01:18<02:14,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 72/200 [01:19<02:18,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▋      | 73/200 [01:20<02:16,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  37%|███▋      | 74/200 [01:21<02:23,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 75/200 [01:23<02:27,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 76/200 [01:23<02:13,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 77/200 [01:24<02:04,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  39%|███▉      | 78/200 [01:26<02:13,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|███▉      | 79/200 [01:26<02:03,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 80/200 [01:28<02:18,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 81/200 [01:30<02:44,  1.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  41%|████      | 82/200 [01:31<02:31,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 83/200 [01:32<02:22,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 84/200 [01:33<02:15,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▎     | 85/200 [01:35<02:32,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  43%|████▎     | 86/200 [01:36<02:18,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▎     | 87/200 [01:36<02:01,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 88/200 [01:38<02:07,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 89/200 [01:39<02:14,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  45%|████▌     | 90/200 [01:40<02:08,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 91/200 [01:41<02:11,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 92/200 [01:43<02:15,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▋     | 93/200 [01:44<02:01,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  47%|████▋     | 94/200 [01:45<01:57,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 95/200 [01:46<02:04,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 96/200 [01:48<02:12,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 97/200 [01:49<02:21,  1.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  49%|████▉     | 98/200 [01:50<02:10,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|████▉     | 99/200 [01:51<02:02,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 100/200 [01:52<01:50,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 101/200 [01:53<01:41,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  51%|█████     | 102/200 [01:54<01:38,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 103/200 [01:55<01:36,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 104/200 [01:57<02:19,  1.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▎    | 105/200 [01:59<02:10,  1.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  53%|█████▎    | 106/200 [02:00<02:00,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▎    | 107/200 [02:01<01:47,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▍    | 108/200 [02:02<01:46,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▍    | 109/200 [02:04<02:05,  1.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▌    | 110/200 [02:05<02:01,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 111/200 [02:06<02:01,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 112/200 [02:08<01:57,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▋    | 113/200 [02:08<01:43,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▋    | 114/200 [02:10<01:41,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▊    | 115/200 [02:11<01:40,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 116/200 [02:12<01:33,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 117/200 [02:13<01:25,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  59%|█████▉    | 118/200 [02:14<01:30,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|█████▉    | 119/200 [02:15<01:36,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 120/200 [02:16<01:37,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 121/200 [02:18<01:34,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  61%|██████    | 122/200 [02:19<01:32,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 123/200 [02:20<01:33,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 124/200 [02:21<01:21,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▎   | 125/200 [02:22<01:20,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  63%|██████▎   | 126/200 [02:23<01:12,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▎   | 127/200 [02:24<01:08,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 128/200 [02:24<01:05,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 129/200 [02:25<01:08,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  65%|██████▌   | 130/200 [02:26<01:04,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 131/200 [02:27<01:04,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 132/200 [02:28<01:01,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▋   | 133/200 [02:29<00:59,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  67%|██████▋   | 134/200 [02:30<00:56,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 135/200 [02:31<01:01,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 136/200 [02:32<01:02,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 137/200 [02:33<00:59,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  69%|██████▉   | 138/200 [02:34<00:56,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|██████▉   | 139/200 [02:35<00:58,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 140/200 [02:36<01:09,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 141/200 [02:37<01:02,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  71%|███████   | 142/200 [02:38<01:01,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 143/200 [02:39<00:58,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 144/200 [02:40<00:54,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▎  | 145/200 [02:41<00:49,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  73%|███████▎  | 146/200 [02:42<00:51,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▎  | 147/200 [02:43<00:52,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 148/200 [02:45<01:04,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 149/200 [02:46<01:03,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  75%|███████▌  | 150/200 [02:47<01:02,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 151/200 [02:48<00:54,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 152/200 [02:50<01:04,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▋  | 153/200 [02:51<00:57,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  77%|███████▋  | 154/200 [02:52<00:51,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 155/200 [02:53<00:49,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 156/200 [02:54<00:53,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 157/200 [02:56<00:54,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  79%|███████▉  | 158/200 [02:57<01:00,  1.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|███████▉  | 159/200 [02:58<00:51,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 160/200 [02:59<00:46,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 161/200 [03:00<00:45,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  81%|████████  | 162/200 [03:02<00:43,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 163/200 [03:03<00:42,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 164/200 [03:04<00:39,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▎ | 165/200 [03:06<00:46,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  83%|████████▎ | 166/200 [03:07<00:42,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▎ | 167/200 [03:08<00:41,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 168/200 [03:09<00:36,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 169/200 [03:10<00:37,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  85%|████████▌ | 170/200 [03:11<00:33,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 171/200 [03:13<00:36,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 172/200 [03:14<00:33,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▋ | 173/200 [03:15<00:29,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  87%|████████▋ | 174/200 [03:16<00:28,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 175/200 [03:17<00:28,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 176/200 [03:18<00:27,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 177/200 [03:19<00:26,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  89%|████████▉ | 178/200 [03:20<00:24,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|████████▉ | 179/200 [03:22<00:24,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 180/200 [03:23<00:25,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 181/200 [03:24<00:22,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  91%|█████████ | 182/200 [03:25<00:21,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 183/200 [03:26<00:19,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 184/200 [03:27<00:17,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▎| 185/200 [03:29<00:20,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  93%|█████████▎| 186/200 [03:30<00:17,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▎| 187/200 [03:31<00:14,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 188/200 [03:32<00:14,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 189/200 [03:34<00:13,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  95%|█████████▌| 190/200 [03:35<00:11,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 191/200 [03:37<00:12,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 192/200 [03:38<00:10,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▋| 193/200 [03:39<00:08,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  97%|█████████▋| 194/200 [03:40<00:07,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 195/200 [03:41<00:05,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 196/200 [03:42<00:04,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 197/200 [03:43<00:03,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  99%|█████████▉| 198/200 [03:44<00:02,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|█████████▉| 199/200 [03:45<00:01,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|██████████| 200/200 [03:46<00:00,  1.03s/it]Running Implicit CoT inference: 100%|██████████| 200/200 [03:46<00:00,  1.13s/it]
Running Implicit CoT inference:   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   0%|          | 1/200 [00:00<02:51,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   1%|          | 2/200 [00:02<03:27,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 3/200 [00:03<03:56,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 4/200 [00:04<03:45,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▎         | 5/200 [00:05<03:38,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   3%|▎         | 6/200 [00:06<03:34,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▎         | 7/200 [00:07<03:30,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 8/200 [00:08<03:15,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 9/200 [00:09<03:36,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   5%|▌         | 10/200 [00:11<04:14,  1.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 11/200 [00:12<04:03,  1.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 12/200 [00:13<03:49,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▋         | 13/200 [00:14<03:33,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   7%|▋         | 14/200 [00:15<03:22,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 15/200 [00:16<03:08,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 16/200 [00:18<03:27,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 17/200 [00:19<03:11,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   9%|▉         | 18/200 [00:20<03:17,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|▉         | 19/200 [00:21<03:15,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 20/200 [00:22<03:07,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 21/200 [00:23<02:56,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  11%|█         | 22/200 [00:23<02:36,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 23/200 [00:24<02:34,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 24/200 [00:25<02:54,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▎        | 25/200 [00:27<03:14,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  13%|█▎        | 26/200 [00:28<02:59,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▎        | 27/200 [00:29<03:00,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 28/200 [00:31<03:44,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 29/200 [00:32<03:30,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  15%|█▌        | 30/200 [00:32<03:10,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 31/200 [00:33<02:55,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 32/200 [00:34<02:50,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▋        | 33/200 [00:36<03:07,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  17%|█▋        | 34/200 [00:37<03:08,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 35/200 [00:38<02:53,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 36/200 [00:39<02:47,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 37/200 [00:39<02:38,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  19%|█▉        | 38/200 [00:40<02:36,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|█▉        | 39/200 [00:41<02:19,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 40/200 [00:42<02:02,  1.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 41/200 [00:43<02:26,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  21%|██        | 42/200 [00:44<02:27,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 43/200 [00:45<02:22,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 44/200 [00:46<02:28,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▎       | 45/200 [00:47<02:28,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  23%|██▎       | 46/200 [00:47<02:13,  1.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▎       | 47/200 [00:48<02:21,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 48/200 [00:49<02:17,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 49/200 [00:51<02:47,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  25%|██▌       | 50/200 [00:52<02:44,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 51/200 [00:53<02:42,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 52/200 [00:54<02:35,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▋       | 53/200 [00:55<02:25,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  27%|██▋       | 54/200 [00:56<02:18,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 55/200 [00:57<02:13,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 56/200 [00:57<02:14,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 57/200 [00:59<02:28,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  29%|██▉       | 58/200 [01:00<02:23,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|██▉       | 59/200 [01:01<02:42,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 60/200 [01:02<02:11,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 61/200 [01:03<02:24,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  31%|███       | 62/200 [01:04<02:24,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 63/200 [01:05<02:28,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 64/200 [01:06<02:26,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▎      | 65/200 [01:07<02:25,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  33%|███▎      | 66/200 [01:09<02:32,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▎      | 67/200 [01:10<02:24,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 68/200 [01:11<02:22,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 69/200 [01:12<02:20,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  35%|███▌      | 70/200 [01:13<02:19,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 71/200 [01:14<02:09,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 72/200 [01:15<02:07,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▋      | 73/200 [01:16<02:08,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  37%|███▋      | 74/200 [01:17<02:13,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 75/200 [01:18<02:01,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 76/200 [01:18<01:44,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 77/200 [01:19<01:43,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  39%|███▉      | 78/200 [01:20<01:58,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|███▉      | 79/200 [01:21<01:53,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 80/200 [01:23<02:12,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 81/200 [01:24<02:06,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  41%|████      | 82/200 [01:24<02:01,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 83/200 [01:26<02:01,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 84/200 [01:27<02:01,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▎     | 85/200 [01:28<02:22,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  43%|████▎     | 86/200 [01:29<02:08,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▎     | 87/200 [01:30<01:57,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 88/200 [01:31<02:08,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 89/200 [01:33<02:22,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  45%|████▌     | 90/200 [01:34<02:14,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 91/200 [01:35<02:11,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 92/200 [01:36<02:02,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▋     | 93/200 [01:37<01:52,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  47%|████▋     | 94/200 [01:38<01:44,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 95/200 [01:39<01:56,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 96/200 [01:41<02:06,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 97/200 [01:42<02:00,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  49%|████▉     | 98/200 [01:43<01:52,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|████▉     | 99/200 [01:44<02:00,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 100/200 [01:45<01:48,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 101/200 [01:46<01:50,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  51%|█████     | 102/200 [01:47<01:44,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 103/200 [01:48<01:40,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 104/200 [01:51<02:22,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▎    | 105/200 [01:52<02:09,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  53%|█████▎    | 106/200 [01:53<01:59,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▎    | 107/200 [01:54<01:46,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▍    | 108/200 [01:55<01:46,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▍    | 109/200 [01:56<01:56,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▌    | 110/200 [01:57<01:43,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 111/200 [01:58<01:37,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 112/200 [01:59<01:35,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▋    | 113/200 [02:00<01:28,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▋    | 114/200 [02:01<01:31,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▊    | 115/200 [02:02<01:30,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 116/200 [02:03<01:29,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 117/200 [02:04<01:28,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  59%|█████▉    | 118/200 [02:05<01:21,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|█████▉    | 119/200 [02:07<01:30,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 120/200 [02:08<01:35,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 121/200 [02:09<01:28,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  61%|██████    | 122/200 [02:10<01:28,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 123/200 [02:11<01:28,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 124/200 [02:12<01:20,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▎   | 125/200 [02:13<01:16,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  63%|██████▎   | 126/200 [02:14<01:09,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▎   | 127/200 [02:15<01:11,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 128/200 [02:16<01:07,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 129/200 [02:17<01:04,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  65%|██████▌   | 130/200 [02:18<01:02,  1.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 131/200 [02:18<00:54,  1.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 132/200 [02:19<00:52,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▋   | 133/200 [02:20<00:53,  1.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  67%|██████▋   | 134/200 [02:20<00:53,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 135/200 [02:22<00:59,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 136/200 [02:23<01:01,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 137/200 [02:24<01:00,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  69%|██████▉   | 138/200 [02:25<00:57,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|██████▉   | 139/200 [02:25<00:57,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 140/200 [02:27<01:06,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 141/200 [02:28<01:00,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  71%|███████   | 142/200 [02:29<00:56,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 143/200 [02:30<00:58,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 144/200 [02:31<00:58,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▎  | 145/200 [02:32<00:57,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  73%|███████▎  | 146/200 [02:33<00:56,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▎  | 147/200 [02:34<00:55,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 148/200 [02:35<00:59,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 149/200 [02:36<00:54,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  75%|███████▌  | 150/200 [02:38<00:57,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 151/200 [02:38<00:50,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 152/200 [02:40<01:02,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▋  | 153/200 [02:41<00:53,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  77%|███████▋  | 154/200 [02:42<00:51,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 155/200 [02:43<00:49,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 156/200 [02:45<00:52,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 157/200 [02:46<00:53,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  79%|███████▉  | 158/200 [02:48<00:57,  1.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|███████▉  | 159/200 [02:49<00:51,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 160/200 [02:50<00:47,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 161/200 [02:51<00:45,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  81%|████████  | 162/200 [02:52<00:42,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 163/200 [02:53<00:42,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 164/200 [02:54<00:39,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▎ | 165/200 [02:56<00:44,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  83%|████████▎ | 166/200 [02:57<00:42,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▎ | 167/200 [02:58<00:41,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 168/200 [02:59<00:35,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 169/200 [03:00<00:36,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  85%|████████▌ | 170/200 [03:01<00:31,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 171/200 [03:03<00:35,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 172/200 [03:04<00:31,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▋ | 173/200 [03:04<00:28,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  87%|████████▋ | 174/200 [03:06<00:27,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 175/200 [03:07<00:28,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 176/200 [03:08<00:27,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 177/200 [03:09<00:26,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  89%|████████▉ | 178/200 [03:10<00:25,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|████████▉ | 179/200 [03:11<00:22,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 180/200 [03:13<00:24,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 181/200 [03:14<00:21,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  91%|█████████ | 182/200 [03:15<00:20,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 183/200 [03:16<00:18,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 184/200 [03:17<00:17,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▎| 185/200 [03:18<00:15,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  93%|█████████▎| 186/200 [03:19<00:14,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▎| 187/200 [03:20<00:12,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 188/200 [03:20<00:11,  1.07it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 189/200 [03:21<00:10,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  95%|█████████▌| 190/200 [03:22<00:09,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 191/200 [03:24<00:11,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 192/200 [03:25<00:08,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▋| 193/200 [03:26<00:07,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  97%|█████████▋| 194/200 [03:27<00:06,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 195/200 [03:28<00:05,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 196/200 [03:30<00:04,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 197/200 [03:30<00:03,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  99%|█████████▉| 198/200 [03:31<00:02,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|█████████▉| 199/200 [03:33<00:01,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|██████████| 200/200 [03:33<00:00,  1.01s/it]Running Implicit CoT inference: 100%|██████████| 200/200 [03:33<00:00,  1.07s/it]
Running Implicit CoT inference:   0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   0%|          | 1/200 [00:01<03:55,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   1%|          | 2/200 [00:02<03:15,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 3/200 [00:03<03:22,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▏         | 4/200 [00:04<03:15,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   2%|▎         | 5/200 [00:05<03:18,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   3%|▎         | 6/200 [00:06<03:48,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▎         | 7/200 [00:07<03:40,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 8/200 [00:08<03:27,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   4%|▍         | 9/200 [00:09<03:38,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   5%|▌         | 10/200 [00:12<04:59,  1.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 11/200 [00:13<04:15,  1.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▌         | 12/200 [00:14<03:57,  1.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   6%|▋         | 13/200 [00:15<04:02,  1.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   7%|▋         | 14/200 [00:16<03:36,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 15/200 [00:17<03:17,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 16/200 [00:18<03:28,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   8%|▊         | 17/200 [00:19<03:11,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:   9%|▉         | 18/200 [00:20<03:11,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|▉         | 19/200 [00:21<02:59,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 20/200 [00:22<02:56,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  10%|█         | 21/200 [00:23<02:48,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  11%|█         | 22/200 [00:24<02:47,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 23/200 [00:25<02:41,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▏        | 24/200 [00:26<02:59,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  12%|█▎        | 25/200 [00:27<03:00,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  13%|█▎        | 26/200 [00:28<02:44,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▎        | 27/200 [00:29<02:54,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 28/200 [00:31<03:34,  1.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  14%|█▍        | 29/200 [00:32<03:24,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  15%|█▌        | 30/200 [00:32<03:00,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 31/200 [00:33<02:48,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▌        | 32/200 [00:34<02:40,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  16%|█▋        | 33/200 [00:35<03:00,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  17%|█▋        | 34/200 [00:37<03:03,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 35/200 [00:37<02:44,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 36/200 [00:38<02:41,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  18%|█▊        | 37/200 [00:39<02:34,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  19%|█▉        | 38/200 [00:40<02:38,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|█▉        | 39/200 [00:42<02:57,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 40/200 [00:43<02:44,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  20%|██        | 41/200 [00:44<02:44,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  21%|██        | 42/200 [00:45<03:00,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 43/200 [00:45<02:30,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▏       | 44/200 [00:47<02:49,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  22%|██▎       | 45/200 [00:48<02:47,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  23%|██▎       | 46/200 [00:49<02:46,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▎       | 47/200 [00:50<02:45,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 48/200 [00:51<02:38,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  24%|██▍       | 49/200 [00:53<03:02,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  25%|██▌       | 50/200 [00:54<02:54,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 51/200 [00:55<02:54,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▌       | 52/200 [00:56<02:53,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  26%|██▋       | 53/200 [00:57<02:56,  1.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  27%|██▋       | 54/200 [00:58<02:40,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 55/200 [00:59<02:23,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 56/200 [01:00<02:16,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  28%|██▊       | 57/200 [01:00<01:53,  1.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  29%|██▉       | 58/200 [01:01<01:46,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|██▉       | 59/200 [01:02<02:16,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 60/200 [01:03<01:57,  1.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  30%|███       | 61/200 [01:04<01:52,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  31%|███       | 62/200 [01:05<02:02,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 63/200 [01:06<02:04,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▏      | 64/200 [01:07<02:09,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  32%|███▎      | 65/200 [01:08<02:17,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  33%|███▎      | 66/200 [01:09<02:27,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▎      | 67/200 [01:10<02:20,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 68/200 [01:11<02:19,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  34%|███▍      | 69/200 [01:12<02:18,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  35%|███▌      | 70/200 [01:13<02:17,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 71/200 [01:14<02:08,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▌      | 72/200 [01:15<02:10,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  36%|███▋      | 73/200 [01:16<02:11,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  37%|███▋      | 74/200 [01:17<02:11,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 75/200 [01:19<02:15,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 76/200 [01:20<02:13,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  38%|███▊      | 77/200 [01:20<02:04,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  39%|███▉      | 78/200 [01:22<02:12,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|███▉      | 79/200 [01:23<02:03,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 80/200 [01:24<02:18,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  40%|████      | 81/200 [01:25<02:10,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  41%|████      | 82/200 [01:26<02:00,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 83/200 [01:27<01:57,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▏     | 84/200 [01:28<01:51,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  42%|████▎     | 85/200 [01:29<01:57,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  43%|████▎     | 86/200 [01:30<01:54,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▎     | 87/200 [01:31<01:44,  1.08it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 88/200 [01:32<01:48,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  44%|████▍     | 89/200 [01:33<02:04,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  45%|████▌     | 90/200 [01:34<01:47,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 91/200 [01:34<01:39,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▌     | 92/200 [01:36<01:43,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  46%|████▋     | 93/200 [01:37<01:42,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  47%|████▋     | 94/200 [01:38<01:55,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 95/200 [01:39<01:53,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 96/200 [01:40<01:45,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  48%|████▊     | 97/200 [01:41<01:45,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  49%|████▉     | 98/200 [01:42<01:45,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|████▉     | 99/200 [01:43<01:45,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 100/200 [01:44<01:57,  1.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  50%|█████     | 101/200 [01:45<01:37,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  51%|█████     | 102/200 [01:46<01:44,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 103/200 [01:47<01:40,  1.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▏    | 104/200 [01:50<02:22,  1.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  52%|█████▎    | 105/200 [01:51<02:09,  1.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  53%|█████▎    | 106/200 [01:52<01:59,  1.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▎    | 107/200 [01:53<01:46,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  54%|█████▍    | 108/200 [01:53<01:31,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▍    | 109/200 [01:55<01:38,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  55%|█████▌    | 110/200 [01:56<01:42,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 111/200 [01:57<01:47,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▌    | 112/200 [01:58<01:42,  1.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  56%|█████▋    | 113/200 [01:59<01:33,  1.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▋    | 114/200 [02:00<01:23,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  57%|█████▊    | 115/200 [02:01<01:25,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 116/200 [02:02<01:20,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  58%|█████▊    | 117/200 [02:03<01:11,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  59%|█████▉    | 118/200 [02:04<01:20,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|█████▉    | 119/200 [02:05<01:19,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 120/200 [02:06<01:27,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  60%|██████    | 121/200 [02:07<01:23,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  61%|██████    | 122/200 [02:08<01:17,  1.00it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 123/200 [02:09<01:28,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▏   | 124/200 [02:10<01:20,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  62%|██████▎   | 125/200 [02:11<01:14,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  63%|██████▎   | 126/200 [02:12<01:07,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▎   | 127/200 [02:13<01:05,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 128/200 [02:14<01:03,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  64%|██████▍   | 129/200 [02:14<01:02,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  65%|██████▌   | 130/200 [02:15<01:02,  1.11it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 131/200 [02:16<01:01,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▌   | 132/200 [02:17<00:59,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  66%|██████▋   | 133/200 [02:18<00:57,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  67%|██████▋   | 134/200 [02:19<00:56,  1.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 135/200 [02:20<01:03,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 136/200 [02:21<01:04,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  68%|██████▊   | 137/200 [02:22<01:02,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  69%|██████▉   | 138/200 [02:23<00:58,  1.05it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|██████▉   | 139/200 [02:24<00:59,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 140/200 [02:25<01:06,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  70%|███████   | 141/200 [02:26<01:00,  1.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  71%|███████   | 142/200 [02:28<01:16,  1.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 143/200 [02:29<01:10,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▏  | 144/200 [02:30<01:03,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  72%|███████▎  | 145/200 [02:31<01:00,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  73%|███████▎  | 146/200 [02:32<00:54,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▎  | 147/200 [02:33<00:50,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 148/200 [02:34<00:58,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  74%|███████▍  | 149/200 [02:36<00:57,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  75%|███████▌  | 150/200 [02:36<00:54,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 151/200 [02:37<00:49,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▌  | 152/200 [02:39<01:01,  1.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  76%|███████▋  | 153/200 [02:40<00:54,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  77%|███████▋  | 154/200 [02:41<00:48,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 155/200 [02:42<00:47,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 156/200 [02:43<00:51,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  78%|███████▊  | 157/200 [02:45<00:52,  1.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  79%|███████▉  | 158/200 [02:46<00:56,  1.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|███████▉  | 159/200 [02:47<00:48,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 160/200 [02:49<00:48,  1.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  80%|████████  | 161/200 [02:49<00:44,  1.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  81%|████████  | 162/200 [02:50<00:39,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 163/200 [02:51<00:36,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▏ | 164/200 [02:52<00:35,  1.02it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  82%|████████▎ | 165/200 [02:53<00:35,  1.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  83%|████████▎ | 166/200 [02:54<00:36,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▎ | 167/200 [02:56<00:37,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 168/200 [02:57<00:33,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  84%|████████▍ | 169/200 [02:58<00:34,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  85%|████████▌ | 170/200 [02:59<00:30,  1.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 171/200 [03:00<00:33,  1.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▌ | 172/200 [03:01<00:30,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  86%|████████▋ | 173/200 [03:02<00:28,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  87%|████████▋ | 174/200 [03:03<00:27,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 175/200 [03:04<00:28,  1.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 176/200 [03:05<00:26,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  88%|████████▊ | 177/200 [03:06<00:24,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  89%|████████▉ | 178/200 [03:07<00:21,  1.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|████████▉ | 179/200 [03:08<00:22,  1.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 180/200 [03:10<00:24,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  90%|█████████ | 181/200 [03:11<00:21,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  91%|█████████ | 182/200 [03:12<00:21,  1.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 183/200 [03:13<00:18,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▏| 184/200 [03:14<00:16,  1.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  92%|█████████▎| 185/200 [03:15<00:14,  1.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  93%|█████████▎| 186/200 [03:15<00:12,  1.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▎| 187/200 [03:16<00:11,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 188/200 [03:18<00:12,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  94%|█████████▍| 189/200 [03:19<00:12,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  95%|█████████▌| 190/200 [03:20<00:10,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 191/200 [03:22<00:11,  1.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▌| 192/200 [03:23<00:09,  1.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  96%|█████████▋| 193/200 [03:24<00:07,  1.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  97%|█████████▋| 194/200 [03:25<00:06,  1.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 195/200 [03:26<00:05,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 196/200 [03:27<00:04,  1.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  98%|█████████▊| 197/200 [03:28<00:03,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference:  99%|█████████▉| 198/200 [03:29<00:02,  1.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|█████████▉| 199/200 [03:30<00:01,  1.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.
`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.
Running Implicit CoT inference: 100%|██████████| 200/200 [03:31<00:00,  1.00it/s]Running Implicit CoT inference: 100%|██████████| 200/200 [03:31<00:00,  1.06s/it]
Baseline icot_si results: {'numerical_accuracy': 0.335, 'close_match_rate': 0.345, 'mean_relative_error': 1.5477006201146557, 'median_relative_error': 0.3315018315018315, 'exp_num': 0, 'dataset': 'svamp', 'eval_temp': 0.1, 'eval_max_contemp_tokens': 1, 'ave_sample_time': 1.1193982660770416}
Baseline icot_si results: {'numerical_accuracy': 0.35, 'close_match_rate': 0.36, 'mean_relative_error': 1.6351404355211698, 'median_relative_error': 0.3138461538461539, 'exp_num': 0, 'dataset': 'svamp', 'eval_temp': 0.3, 'eval_max_contemp_tokens': 1, 'ave_sample_time': 1.114000337123871}
Baseline icot_si results: {'numerical_accuracy': 0.25, 'close_match_rate': 0.255, 'mean_relative_error': 2.0479446736607474, 'median_relative_error': 0.3977777777777778, 'exp_num': 0, 'dataset': 'svamp', 'eval_temp': 0.5, 'eval_max_contemp_tokens': 1, 'ave_sample_time': 1.132476944923401}
Baseline icot_si results: {'numerical_accuracy': 0.29, 'close_match_rate': 0.3, 'mean_relative_error': 1.2910913930995984, 'median_relative_error': 0.45555555555555555, 'exp_num': 0, 'dataset': 'svamp', 'eval_temp': 0.7, 'eval_max_contemp_tokens': 1, 'ave_sample_time': 1.0691150045394897}
Baseline icot_si results: {'numerical_accuracy': 0.27, 'close_match_rate': 0.28, 'mean_relative_error': 1.5138951994443117, 'median_relative_error': 0.48484848484848486, 'exp_num': 0, 'dataset': 'svamp', 'eval_temp': 0.9, 'eval_max_contemp_tokens': 1, 'ave_sample_time': 1.0568724858760834}
