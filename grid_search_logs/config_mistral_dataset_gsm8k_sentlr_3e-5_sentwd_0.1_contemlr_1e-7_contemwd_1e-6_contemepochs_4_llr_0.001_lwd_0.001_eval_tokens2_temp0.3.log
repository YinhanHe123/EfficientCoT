Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.54it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]
Running inference:   0%|          | 0/100 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Running inference:   1%|          | 1/100 [00:01<02:23,  1.45s/it]Running inference:   2%|▏         | 2/100 [00:02<01:46,  1.08s/it]Running inference:   3%|▎         | 3/100 [00:03<01:35,  1.02it/s]Running inference:   4%|▍         | 4/100 [00:04<01:30,  1.06it/s]Running inference:   5%|▌         | 5/100 [00:04<01:29,  1.06it/s]Running inference:   6%|▌         | 6/100 [00:05<01:26,  1.09it/s]Running inference:   7%|▋         | 7/100 [00:06<01:23,  1.11it/s]Running inference:   8%|▊         | 8/100 [00:07<01:12,  1.28it/s]Running inference:   9%|▉         | 9/100 [00:08<01:16,  1.19it/s]Running inference:  10%|█         | 10/100 [00:09<01:16,  1.18it/s]Running inference:  11%|█         | 11/100 [00:09<01:16,  1.17it/s]Running inference:  12%|█▏        | 12/100 [00:10<01:16,  1.16it/s]Running inference:  13%|█▎        | 13/100 [00:11<01:15,  1.15it/s]Running inference:  14%|█▍        | 14/100 [00:12<01:15,  1.14it/s]Running inference:  15%|█▌        | 15/100 [00:13<01:14,  1.14it/s]Running inference:  16%|█▌        | 16/100 [00:14<01:15,  1.12it/s]Running inference:  17%|█▋        | 17/100 [00:14<01:00,  1.37it/s]Running inference:  18%|█▊        | 18/100 [00:15<01:03,  1.30it/s]Running inference:  19%|█▉        | 19/100 [00:16<01:03,  1.27it/s]Running inference:  20%|██        | 20/100 [00:17<01:05,  1.23it/s]Running inference:  21%|██        | 21/100 [00:18<01:06,  1.19it/s]Running inference:  22%|██▏       | 22/100 [00:18<00:57,  1.35it/s]Running inference:  23%|██▎       | 23/100 [00:19<00:59,  1.29it/s]Running inference:  24%|██▍       | 24/100 [00:20<01:00,  1.25it/s]Running inference:  25%|██▌       | 25/100 [00:21<01:01,  1.22it/s]Running inference:  26%|██▌       | 26/100 [00:22<01:05,  1.13it/s]Running inference:  27%|██▋       | 27/100 [00:23<01:10,  1.04it/s]Running inference:  28%|██▊       | 28/100 [00:24<01:15,  1.04s/it]Running inference:  29%|██▉       | 29/100 [00:25<01:11,  1.01s/it]Running inference:  30%|███       | 30/100 [00:26<01:16,  1.09s/it]Running inference:  31%|███       | 31/100 [00:28<01:18,  1.13s/it]Running inference:  32%|███▏      | 32/100 [00:29<01:19,  1.16s/it]Running inference:  33%|███▎      | 33/100 [00:30<01:19,  1.19s/it]Running inference:  34%|███▍      | 34/100 [00:31<01:18,  1.19s/it]Running inference:  35%|███▌      | 35/100 [00:33<01:17,  1.19s/it]Running inference:  36%|███▌      | 36/100 [00:34<01:17,  1.21s/it]Running inference:  37%|███▋      | 37/100 [00:35<01:12,  1.15s/it]Running inference:  38%|███▊      | 38/100 [00:36<01:02,  1.02s/it]Running inference:  39%|███▉      | 39/100 [00:37<01:05,  1.08s/it]Running inference:  40%|████      | 40/100 [00:38<01:07,  1.13s/it]Running inference:  41%|████      | 41/100 [00:39<01:09,  1.17s/it]Running inference:  42%|████▏     | 42/100 [00:41<01:11,  1.23s/it]Running inference:  43%|████▎     | 43/100 [00:41<01:01,  1.08s/it]Running inference:  44%|████▍     | 44/100 [00:42<00:54,  1.03it/s]Running inference:  45%|████▌     | 45/100 [00:43<00:58,  1.06s/it]Running inference:  46%|████▌     | 46/100 [00:45<01:01,  1.14s/it]Running inference:  47%|████▋     | 47/100 [00:46<01:04,  1.21s/it]Running inference:  48%|████▊     | 48/100 [00:47<01:03,  1.23s/it]Running inference:  49%|████▉     | 49/100 [00:49<01:04,  1.27s/it]Running inference:  50%|█████     | 50/100 [00:50<01:05,  1.30s/it]Running inference:  51%|█████     | 51/100 [00:51<01:03,  1.30s/it]Running inference:  52%|█████▏    | 52/100 [00:53<01:01,  1.29s/it]Running inference:  53%|█████▎    | 53/100 [00:54<01:01,  1.30s/it]Running inference:  54%|█████▍    | 54/100 [00:55<00:57,  1.25s/it]Running inference:  55%|█████▌    | 55/100 [00:57<00:58,  1.30s/it]Running inference:  56%|█████▌    | 56/100 [00:58<00:57,  1.31s/it]Running inference:  57%|█████▋    | 57/100 [00:59<00:57,  1.33s/it]Running inference:  58%|█████▊    | 58/100 [01:01<00:57,  1.37s/it]Running inference:  59%|█████▉    | 59/100 [01:02<00:56,  1.38s/it]Running inference:  60%|██████    | 60/100 [01:03<00:55,  1.39s/it]Running inference:  61%|██████    | 61/100 [01:05<00:53,  1.38s/it]Running inference:  62%|██████▏   | 62/100 [01:06<00:51,  1.37s/it]Running inference:  63%|██████▎   | 63/100 [01:08<00:51,  1.39s/it]Running inference:  64%|██████▍   | 64/100 [01:09<00:50,  1.39s/it]Running inference:  65%|██████▌   | 65/100 [01:10<00:48,  1.40s/it]Running inference:  66%|██████▌   | 66/100 [01:12<00:47,  1.39s/it]Running inference:  67%|██████▋   | 67/100 [01:13<00:45,  1.39s/it]Running inference:  68%|██████▊   | 68/100 [01:14<00:43,  1.35s/it]Running inference:  69%|██████▉   | 69/100 [01:16<00:40,  1.32s/it]Running inference:  70%|███████   | 70/100 [01:17<00:38,  1.30s/it]Running inference:  71%|███████   | 71/100 [01:18<00:37,  1.28s/it]Running inference:  72%|███████▏  | 72/100 [01:19<00:29,  1.06s/it]Running inference:  73%|███████▎  | 73/100 [01:20<00:30,  1.12s/it]Running inference:  74%|███████▍  | 74/100 [01:21<00:30,  1.16s/it]Running inference:  75%|███████▌  | 75/100 [01:23<00:30,  1.23s/it]Running inference:  76%|███████▌  | 76/100 [01:24<00:29,  1.24s/it]Running inference:  77%|███████▋  | 77/100 [01:25<00:26,  1.16s/it]Running inference:  78%|███████▊  | 78/100 [01:26<00:25,  1.18s/it]Running inference:  79%|███████▉  | 79/100 [01:27<00:25,  1.20s/it]Running inference:  80%|████████  | 80/100 [01:29<00:24,  1.21s/it]Running inference:  81%|████████  | 81/100 [01:30<00:23,  1.22s/it]Running inference:  82%|████████▏ | 82/100 [01:31<00:22,  1.24s/it]Running inference:  83%|████████▎ | 83/100 [01:32<00:21,  1.24s/it]Running inference:  84%|████████▍ | 84/100 [01:34<00:19,  1.25s/it]Running inference:  85%|████████▌ | 85/100 [01:35<00:18,  1.22s/it]Running inference:  86%|████████▌ | 86/100 [01:36<00:17,  1.23s/it]Running inference:  87%|████████▋ | 87/100 [01:37<00:16,  1.24s/it]Running inference:  88%|████████▊ | 88/100 [01:39<00:15,  1.25s/it]Running inference:  89%|████████▉ | 89/100 [01:40<00:13,  1.25s/it]Running inference:  90%|█████████ | 90/100 [01:41<00:12,  1.24s/it]Running inference:  91%|█████████ | 91/100 [01:42<00:11,  1.27s/it]Running inference:  92%|█████████▏| 92/100 [01:44<00:10,  1.26s/it]Running inference:  93%|█████████▎| 93/100 [01:45<00:08,  1.25s/it]Running inference:  94%|█████████▍| 94/100 [01:46<00:07,  1.27s/it]Running inference:  95%|█████████▌| 95/100 [01:47<00:06,  1.27s/it]Running inference:  96%|█████████▌| 96/100 [01:48<00:04,  1.18s/it]Running inference:  97%|█████████▋| 97/100 [01:49<00:03,  1.06s/it]Running inference:  98%|█████████▊| 98/100 [01:50<00:01,  1.06it/s]Running inference:  99%|█████████▉| 99/100 [01:51<00:00,  1.07it/s]Running inference: 100%|██████████| 100/100 [01:52<00:00,  1.09it/s]Running inference: 100%|██████████| 100/100 [01:52<00:00,  1.12s/it]
Average time taken for each sample: 1.109990050792694, Average time taken for contemplation: 0.02206071376800537
Evaluation results: {'numerical_accuracy': 0.09, 'close_match_rate': 0.09, 'mean_relative_error': np.float64(0.6530876868481027), 'median_relative_error': np.float64(0.3333333333333333), 'dataset': 'gsm8k', 'student': 'optimum/mistral-1.1b-testing', 'teacher': 'mistralai/Mistral-7B-Instruct-v0.2', 'sent_trans_lr': 1e-05, 'sent_trans_weight_decay': 0.01, 'sent_trans_epochs': 15, 'contemp_gen_lr': 1e-07, 'contemp_gen_epochs': 2, 'contemp_gen_lin_layer_lr': 0.001, 'contemp_gen_lin_layer_epochs': 10, 'contemp_gen_lin_layer_weight_decay': 0.001, 'contemp_gen_weight_decay': 1e-05, 'eval_temp': 0.3, 'train_max_contemp_tokens': 5, 'eval_max_contemp_tokens': 2}
