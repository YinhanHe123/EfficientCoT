{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "res_dir = \"/home/nee7ne/EfficientCoT/results_final \"\n",
    "methods = ['coconut', 'codi', 'icot_si', 'pause', 'softcot', 'effi_cot']\n",
    "datasets = [\"coin_flip\", \"commonsense_qa\", \"gsm8k\", \"multiarith\", \"svamp\"]\n",
    "models = [\"small\", \"mistral\"]\n",
    "res = {}\n",
    "\n",
    "for mo in models:\n",
    "    res[mo] = {}\n",
    "    for me in methods:\n",
    "        res[mo][me] = {}\n",
    "        for d in datasets:\n",
    "            res[mo][me][d] = {}\n",
    "            file = f\"{res_dir}/{me}/{mo}/{d}/evaluation_results.jsonl\"\n",
    "            if me == \"effi_cot\":\n",
    "                file = f\"{res_dir}/{me}/vanilla/{mo}/{d}/evaluation_results.jsonl\"\n",
    "            if not os.path.exists(file):\n",
    "                continue\n",
    "            with open(file) as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [json.loads(l) for l in lines[:15] if l != \"\\n\"]\n",
    "            summary = {}\n",
    "            for l in lines:\n",
    "                if l['eval_temp'] not in summary:\n",
    "                    summary[l['eval_temp']] = {'acc': [], 'time': []}\n",
    "                summary[l['eval_temp']]['acc'].append(l['numerical_accuracy'] * 100)\n",
    "                summary[l['eval_temp']]['time'].append(l['ave_sample_time'])\n",
    "            best_temp, max_acc = 0, -1\n",
    "            for temp in summary:\n",
    "                if np.mean(summary[temp]['acc']) > max_acc:\n",
    "                    best_temp = temp\n",
    "                    max_acc = np.mean(summary[temp]['acc'])\n",
    "            res[mo][me][d] = {'acc': summary[best_temp]['acc'], 'time': summary[best_temp]['time'], \"temp\":best_temp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.67 \\scriptsize{± 1.93}\t66.33 \\scriptsize{± 11.05}\t25.33 \\scriptsize{± 0.85}\t50.50 \\scriptsize{± 0.00}\t73.17 \\scriptsize{± 1.25}\t90.00 \\scriptsize{± 9.91}\t\n",
      "1.99 \\scriptsize{± 0.12}\t4.08 \\scriptsize{± 0.12}\t2.22 \\scriptsize{± 0.01}\t3.14 \\scriptsize{± 0.00}\t1.31 \\scriptsize{± 0.00}\t1.32 \\scriptsize{± 0.00}\t\n",
      "13.00 \\scriptsize{± 0.41}\t74.50 \\scriptsize{± 12.29}\t20.00 \\scriptsize{± 1.41}\t50.00 \\scriptsize{± 0.00}\t63.50 \\scriptsize{± 0.41}\t76.83 \\scriptsize{± 10.02}\t\n",
      "1.62 \\scriptsize{± 0.01}\t3.89 \\scriptsize{± 0.01}\t2.24 \\scriptsize{± 0.00}\t2.67 \\scriptsize{± 0.01}\t1.27 \\scriptsize{± 0.07}\t1.26 \\scriptsize{± 0.02}\t\n",
      "6.50 \\scriptsize{± 1.22}\t8.17 \\scriptsize{± 5.07}\t9.83 \\scriptsize{± 0.24}\t4.67 \\scriptsize{± 0.62}\t2.17 \\scriptsize{± 0.47}\t11.00 \\scriptsize{± 6.72}\t\n",
      "1.58 \\scriptsize{± 0.01}\t2.82 \\scriptsize{± 1.61}\t1.93 \\scriptsize{± 0.23}\t3.40 \\scriptsize{± 0.03}\t1.35 \\scriptsize{± 0.01}\t1.31 \\scriptsize{± 0.00}\t\n",
      "2.23 \\scriptsize{± 0.45}\t8.17 \\scriptsize{± 7.34}\t2.80 \\scriptsize{± 0.90}\t0.57 \\scriptsize{± 0.45}\t4.43 \\scriptsize{± 1.20}\t10.73 \\scriptsize{± 0.52}\t\n",
      "1.57 \\scriptsize{± 0.01}\t4.15 \\scriptsize{± 0.37}\t2.26 \\scriptsize{± 0.00}\t3.56 \\scriptsize{± 0.11}\t1.43 \\scriptsize{± 0.06}\t1.28 \\scriptsize{± 0.03}\t\n",
      "8.50 \\scriptsize{± 1.22}\t11.33 \\scriptsize{± 4.52}\t19.67 \\scriptsize{± 5.57}\t16.17 \\scriptsize{± 4.73}\t6.17 \\scriptsize{± 0.94}\t43.67 \\scriptsize{± 2.09}\t\n",
      "1.58 \\scriptsize{± 0.01}\t3.19 \\scriptsize{± 0.53}\t0.43 \\scriptsize{± 0.04}\t3.32 \\scriptsize{± 0.04}\t1.31 \\scriptsize{± 0.00}\t1.30 \\scriptsize{± 0.02}\t\n",
      "2.17 \\scriptsize{± 1.25}\t87.17 \\scriptsize{± 18.15}\t33.83 \\scriptsize{± 2.87}\t50.00 \\scriptsize{± 0.00}\t41.00 \\scriptsize{± 2.55}\t87.83 \\scriptsize{± 6.54}\t\n",
      "1.68 \\scriptsize{± 0.00}\t4.32 \\scriptsize{± 0.04}\t2.30 \\scriptsize{± 0.00}\t3.74 \\scriptsize{± 0.02}\t1.39 \\scriptsize{± 0.00}\t1.37 \\scriptsize{± 0.01}\t\n",
      "14.50 \\scriptsize{± 0.00}\t80.17 \\scriptsize{± 16.41}\t21.17 \\scriptsize{± 2.05}\t63.50 \\scriptsize{± 0.00}\t62.67 \\scriptsize{± 1.18}\t81.67 \\scriptsize{± 2.78}\t\n",
      "1.67 \\scriptsize{± 0.00}\t4.14 \\scriptsize{± 0.00}\t2.29 \\scriptsize{± 0.00}\t3.71 \\scriptsize{± 0.03}\t1.37 \\scriptsize{± 0.00}\t1.35 \\scriptsize{± 0.03}\t\n",
      "9.67 \\scriptsize{± 0.24}\t4.33 \\scriptsize{± 3.47}\t14.67 \\scriptsize{± 2.09}\t2.33 \\scriptsize{± 1.65}\t2.50 \\scriptsize{± 0.41}\t14.33 \\scriptsize{± 0.62}\t\n",
      "1.68 \\scriptsize{± 0.01}\t4.96 \\scriptsize{± 0.03}\t1.72 \\scriptsize{± 0.08}\t3.46 \\scriptsize{± 0.02}\t1.39 \\scriptsize{± 0.00}\t1.39 \\scriptsize{± 0.00}\t\n",
      "2.43 \\scriptsize{± 0.52}\t19.47 \\scriptsize{± 9.32}\t3.67 \\scriptsize{± 0.52}\t1.47 \\scriptsize{± 1.04}\t3.33 \\scriptsize{± 0.45}\t19.07 \\scriptsize{± 2.23}\t\n",
      "1.68 \\scriptsize{± 0.01}\t4.45 \\scriptsize{± 0.62}\t2.32 \\scriptsize{± 0.01}\t3.64 \\scriptsize{± 0.13}\t1.37 \\scriptsize{± 0.00}\t1.50 \\scriptsize{± 0.16}\t\n",
      "34.00 \\scriptsize{± 0.82}\t14.83 \\scriptsize{± 9.10}\t32.50 \\scriptsize{± 3.54}\t7.50 \\scriptsize{± 5.31}\t10.67 \\scriptsize{± 1.03}\t46.17 \\scriptsize{± 1.25}\t\n",
      "1.69 \\scriptsize{± 0.00}\t4.08 \\scriptsize{± 0.03}\t0.90 \\scriptsize{± 0.19}\t3.44 \\scriptsize{± 0.01}\t1.38 \\scriptsize{± 0.00}\t1.37 \\scriptsize{± 0.01}\t\n"
     ]
    }
   ],
   "source": [
    "for mo in models:\n",
    "    for d in sorted(datasets):\n",
    "        acc_line = \"\"\n",
    "        time_line = \"\"\n",
    "        m = \"\"\n",
    "        for me in methods:\n",
    "            m += me + \"\\t\"\n",
    "            cur_acc = \"N/A\\t\"\n",
    "            cur_time = \"N/A\\t\"\n",
    "            if len(res[mo][me][d]) > 0:\n",
    "                cur_acc = f\"{np.mean(res[mo][me][d]['acc']):.2f} \\scriptsize\"+\"{± \"+f\"{np.std(res[mo][me][d]['acc']):.2f}\"+\"}\\t\"\n",
    "                cur_time = f\"{np.mean(res[mo][me][d]['time']):.2f} \\scriptsize\"+\"{± \"+f\"{np.std(res[mo][me][d]['time']):.2f}\"+\"}\\t\"\n",
    "            acc_line += cur_acc\n",
    "            time_line += cur_time\n",
    "        print(acc_line)\n",
    "        print(time_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.67 ± 2.09\t\n",
      "1.30 ± 0.02\t\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "lines = \"\"\"\n",
    "{\"numerical_accuracy\": 0.43, \"close_match_rate\": 0.45, \"mean_relative_error\": 0.8347282617080535, \"median_relative_error\": 0.04339995352079944, \"exp_num\": 0, \"dataset\": \"svamp\", \"eval_temp\": 0.1, \"ave_sample_time\": 1.3277779865264892, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.42, \"close_match_rate\": 0.435, \"mean_relative_error\": 1.133639945357705, \"median_relative_error\": 0.0857843137254902, \"exp_num\": 0, \"dataset\": \"svamp\", \"eval_temp\": 0.3, \"ave_sample_time\": 1.3098631191253662, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.415, \"close_match_rate\": 0.435, \"mean_relative_error\": 0.7132307012366528, \"median_relative_error\": 0.08333333333333334, \"exp_num\": 0, \"dataset\": \"svamp\", \"eval_temp\": 0.5, \"ave_sample_time\": 1.2989231753349304, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.405, \"close_match_rate\": 0.44, \"mean_relative_error\": 1.5853724209651472, \"median_relative_error\": 0.07275132275132275, \"exp_num\": 0, \"dataset\": \"svamp\", \"eval_temp\": 0.7, \"ave_sample_time\": 1.2883724343776704, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.385, \"close_match_rate\": 0.405, \"mean_relative_error\": 0.78657116327356, \"median_relative_error\": 0.07671568627450981, \"exp_num\": 0, \"dataset\": \"svamp\", \"eval_temp\": 0.9, \"ave_sample_time\": 1.294522762298584, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.415, \"close_match_rate\": 0.425, \"mean_relative_error\": 0.6827791824832995, \"median_relative_error\": 0.0784313725490196, \"exp_num\": 1, \"dataset\": \"svamp\", \"eval_temp\": 0.1, \"ave_sample_time\": 1.3032299590110779, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.41, \"close_match_rate\": 0.42, \"mean_relative_error\": 0.623756740435207, \"median_relative_error\": 0.0784313725490196, \"exp_num\": 1, \"dataset\": \"svamp\", \"eval_temp\": 0.3, \"ave_sample_time\": 1.296975346803665, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.42, \"close_match_rate\": 0.44, \"mean_relative_error\": 0.5329078921214886, \"median_relative_error\": 0.05823249447848944, \"exp_num\": 1, \"dataset\": \"svamp\", \"eval_temp\": 0.5, \"ave_sample_time\": 1.2840074217319488, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.395, \"close_match_rate\": 0.41, \"mean_relative_error\": 0.7726723976203438, \"median_relative_error\": 0.12434750186428038, \"exp_num\": 1, \"dataset\": \"svamp\", \"eval_temp\": 0.7, \"ave_sample_time\": 1.2730780780315398, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.395, \"close_match_rate\": 0.405, \"mean_relative_error\": 1.032121964643419, \"median_relative_error\": 0.10743801652892562, \"exp_num\": 1, \"dataset\": \"svamp\", \"eval_temp\": 0.9, \"ave_sample_time\": 1.2838754749298096, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.465, \"close_match_rate\": 0.48, \"mean_relative_error\": 0.60495249288651, \"median_relative_error\": 0.030940009447331128, \"exp_num\": 2, \"dataset\": \"svamp\", \"eval_temp\": 0.1, \"ave_sample_time\": 1.2835328423976897, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.455, \"close_match_rate\": 0.47, \"mean_relative_error\": 0.5336702361338369, \"median_relative_error\": 0.038098693759071114, \"exp_num\": 2, \"dataset\": \"svamp\", \"eval_temp\": 0.3, \"ave_sample_time\": 1.2913209044933318, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.44, \"close_match_rate\": 0.455, \"mean_relative_error\": 0.6662466363779771, \"median_relative_error\": 0.040883408945420134, \"exp_num\": 2, \"dataset\": \"svamp\", \"eval_temp\": 0.5, \"ave_sample_time\": 1.2849030780792237, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.42, \"close_match_rate\": 0.435, \"mean_relative_error\": 0.763867277281309, \"median_relative_error\": 0.08088235294117646, \"exp_num\": 2, \"dataset\": \"svamp\", \"eval_temp\": 0.7, \"ave_sample_time\": 1.2854688930511475, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "{\"numerical_accuracy\": 0.44, \"close_match_rate\": 0.46, \"mean_relative_error\": 0.5904118060251882, \"median_relative_error\": 0.038461538461538464, \"exp_num\": 2, \"dataset\": \"svamp\", \"eval_temp\": 0.9, \"ave_sample_time\": 1.2886021506786347, \"student\": \"princeton-nlp/Sheared-LLaMA-1.3B\", \"teacher\": \"meta-llama/Llama-2-7b-chat-hf\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.001, \"st_linear_epochs\": 5, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 1e-05, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.0001, \"cg_linear_wd\": 0.001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 1e-05, \"cg_llm_epochs\": 2, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "\"\"\"\n",
    "lines = lines.split(\"\\n\")[1:-1]\n",
    "idx = [i for i, l in enumerate(lines) if l == \"\\n\"]\n",
    "if len(idx) == 0:\n",
    "    idx = 0\n",
    "elif idx[-1] == len(lines) - 1:\n",
    "    idx = 0\n",
    "else:\n",
    "    idx = idx[-1] + 1\n",
    "lines = [json.loads(l) for l in lines[idx:] if l != \"\\n\"]\n",
    "summary = {}\n",
    "for l in lines:\n",
    "    if l['eval_temp'] not in summary:\n",
    "        summary[l['eval_temp']] = {'acc': [], 'time': []}\n",
    "    summary[l['eval_temp']]['acc'].append(l['numerical_accuracy'] * 100)\n",
    "    summary[l['eval_temp']]['time'].append(l['ave_sample_time'])\n",
    "best_temp, max_acc = 0, -1\n",
    "for temp in summary:\n",
    "    if np.mean(summary[temp]['acc']) > max_acc:\n",
    "        best_temp = temp\n",
    "        max_acc = np.mean(summary[temp]['acc'])\n",
    "        \n",
    "print(f\"{np.mean(summary[best_temp]['acc']):.2f} ± {np.std(summary[best_temp]['acc']):.2f}\\t\")\n",
    "print(f\"{np.mean(summary[best_temp]['time']):.2f} ± {np.std(summary[best_temp]['time']):.2f}\\t\")\n",
    "print(best_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "res_path = \"/home/nee7ne/EfficientCoT/results/effi_cot/vanilla/mistral/multiarith/evaluation_results.jsonl\"\n",
    "cur_res = {}\n",
    "with open(res_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    idx = 0\n",
    "    while idx < len(lines):\n",
    "        if lines[idx].strip() == \"\":\n",
    "            idx +=1\n",
    "            continue\n",
    "        elif json.loads(lines[idx])[\"exp_num\"] != 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "        acc = []\n",
    "        for temp in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "            cur_line = json.loads(lines[idx])\n",
    "            if cur_line['eval_temp'] != temp:\n",
    "                break\n",
    "            acc.append(cur_line['numerical_accuracy'])\n",
    "            idx += 1\n",
    "        cur_params = (cur_line['st_linear_lr'], cur_line['st_linear_wd'], cur_line['st_linear_epochs'], cur_line['st_llm_lr'], cur_line['st_llm_wd'], cur_line['st_llm_epochs'], cur_line['cg_linear_lr'], cur_line['cg_linear_wd'], cur_line['cg_linear_epochs'], cur_line['cg_llm_lr'], cur_line['cg_llm_wd'], cur_line['cg_llm_epochs'])\n",
    "        cur_res[cur_params] = max(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.0001, 0.001, 3, 1e-05, 0.001, 2, 0.0001, 0.01, 3, 1e-05, 0.001, 1),\n",
       "  0.189),\n",
       " ((0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.01, 0.0001, 5, 1e-05, 0.001, 1), 0.189),\n",
       " ((0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.01, 0.01, 5, 1e-07, 0.001, 1), 0.189),\n",
       " ((0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.01, 0.0001, 5, 1e-07, 0.001, 2), 0.189),\n",
       " ((0.01, 0.001, 1, 1e-05, 1e-05, 1, 0.0001, 0.001, 1, 1e-07, 0.001, 2), 0.189),\n",
       " ((0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.01, 0.01, 3, 1e-07, 1e-05, 1), 0.2),\n",
       " ((0.001, 0.0001, 3, 1e-07, 1e-05, 1, 0.01, 0.001, 5, 1e-05, 0.001, 1), 0.2),\n",
       " ((0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.001, 0.0001, 1, 1e-05, 0.001, 2),\n",
       "  0.217)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k, v in cur_res.items() if v >= 0.185], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, 0.01, 1, 1e-07, 0.001, 2, 0.001, 0.0001, 5, 1e-07, 0.001, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_line ={\"numerical_accuracy\": 0.211, \"close_match_rate\": 0.211, \"mean_relative_error\": 0.4133522429329931, \"median_relative_error\": 0.2, \"exp_num\": 0, \"dataset\": \"multiarith\", \"eval_temp\": 0.9, \"ave_sample_time\": 1.3804727421866523, \"student\": \"optimum/mistral-1.1b-testing\", \"teacher\": \"mistralai/Mistral-7B-Instruct-v0.2\", \"st_linear_lr\": 0.0001, \"st_linear_wd\": 0.01, \"st_linear_epochs\": 1, \"st_llm_lr\": 1e-07, \"st_llm_wd\": 0.001, \"st_llm_epochs\": 2, \"cg_linear_lr\": 0.001, \"cg_linear_wd\": 0.0001, \"cg_linear_epochs\": 5, \"cg_llm_lr\": 1e-07, \"cg_llm_wd\": 0.001, \"cg_llm_epochs\": 1, \"train_max_contemp_tokens\": 5, \"eval_max_contemp_tokens\": 1}\n",
    "\n",
    "(cur_line['st_linear_lr'], cur_line['st_linear_wd'], cur_line['st_linear_epochs'], cur_line['st_llm_lr'], cur_line['st_llm_wd'], cur_line['st_llm_epochs'], cur_line['cg_linear_lr'], cur_line['cg_linear_wd'], cur_line['cg_linear_epochs'], cur_line['cg_llm_lr'], cur_line['cg_llm_wd'], cur_line['cg_llm_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python main.py --config mistral --mode effi_cot --dataset multiarith --device 3 --variation vanilla -stllr 0.0001 -stlwd 0.01 -stle 1 -stllmlr 1e-07 -stllmwd 0.001 -stllme 2 -cgllr 0.001 -cglwd 0.0001 -cgle 5 -cgllmlr 1e-07 -cgllmwd 0.001 -cgllme 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"python main.py --config {'small' if 'llama' in cur_line['teacher'] else 'mistral'} --mode effi_cot --dataset {cur_line['dataset']} --device 3 --variation vanilla -stllr {cur_line['st_linear_lr']} -stlwd {cur_line['st_linear_wd']} -stle {cur_line['st_linear_epochs']} -stllmlr {cur_line['st_llm_lr']} -stllmwd {cur_line['st_llm_wd']} -stllme {cur_line['st_llm_epochs']} -cgllr {cur_line['cg_linear_lr']} -cglwd {cur_line['cg_linear_wd']} -cgle {cur_line['cg_linear_epochs']} -cgllmlr {cur_line['cg_llm_lr']} -cgllmwd {cur_line['cg_llm_wd']} -cgllme {cur_line['cg_llm_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1663213852.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python main.py --config mistral --mode effi_cot --dataset gsm8k --device 3 --variation vanilla -stllr 0.0001 -stlwd 0.001 -stle 3 -stllmlr 1e-07 -stllmwd 1e-05 -stllme 1 -cgllr 0.01 -cglwd 0.0001 -cgle 1 -cgllmlr 1e-07 -cgllmwd 1e-05 -cgllme 2\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python main.py --config mistral --mode effi_cot --dataset multiarith --device 1 --variation vanilla -stllr 0.0001 -stlwd 0.01 -stle 1 -stllmlr 1e-07 -stllmwd 0.001 -stllme 2 -cgllr 0.001 -cglwd 0.0001 -cgle 5 -cgllmlr 1e-07 -cgllmwd 0.001 -cgllme 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --config mistral --mode effi_cot --dataset multiarith --device 2 --variation vanilla -stllr 0.0001 -stlwd 0.001 -stle 3 -stllmlr 1e-05 -stllmwd 0.001 -stllme 2 -cgllr 0.0001 -cglwd 0.01 -cgle 3 -cgllmlr 1e-05 -cgllmwd 0.001 -cgllme 1 && python main.py --config mistral --mode effi_cot --dataset multiarith --device 2 --variation vanilla -stllr 0.0001 -stlwd 0.01 -stle 1 -stllmlr 1e-07 -stllmwd 0.001 -stllme 2 -cgllr 0.01 -cglwd 0.0001 -cgle 5 -cgllmlr 1e-05 -cgllmwd 0.001 -cgllme 1 && python main.py --config mistral --mode effi_cot --dataset multiarith --device 2 --variation vanilla -stllr 0.0001 -stlwd 0.01 -stle 1 -stllmlr 1e-07 -stllmwd 0.001 -stllme 2 -cgllr 0.01 -cglwd 0.0001 -cgle 5 -cgllmlr 1e-07 -cgllmwd 0.001 -cgllme 2 && python main.py --config mistral --mode effi_cot --dataset multiarith --device 2 --variation vanilla -stllr 0.0001 -stlwd 0.01 -stle 1 -stllmlr 1e-07 -stllmwd 0.001 -stllme 2 -cgllr 0.01 -cglwd 0.01 -cgle 5 -cgllmlr 1e-07 -cgllmwd 0.001 -cgllme 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_temps = {model: {method: {d:res[model][method][d][\"temp\"] for d in res[model][method]} for method in res[model]} for model in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os \n",
    "root = \"/data/nee7ne/effi_cot2/saved_models/coconut\"\n",
    "for model in os.listdir(root):\n",
    "    for dataset in os.listdir(f\"{root}/{model}\"):\n",
    "        path = f\"{root}/{model}/{dataset}/\"\n",
    "        while \"model\" not in os.listdir(path)[0]:\n",
    "            path += os.listdir(path)[0] + \"/\"\n",
    "        shutil.move(f\"{path}/{os.listdir(path)[0]}\", f\"{root}/{model}/{dataset}/{os.listdir(path)[0]}\")\n",
    "        shutil.rmtree(f\"{root}/{model}/{dataset}/coconut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in os.listdir(root):\n",
    "    for dataset in os.listdir(f\"{root}/{model}\"):\n",
    "        if os.path.exists(f\"{root}/{model}/{dataset}/softcot\"):\n",
    "            shutil.rmtree(f\"{root}/{model}/{dataset}/softcot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
